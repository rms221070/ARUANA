from fastapi import FastAPI, APIRouter, UploadFile, File, HTTPException, Query, Request
from fastapi.responses import StreamingResponse
from dotenv import load_dotenv
from starlette.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
import os
import logging
from pathlib import Path
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Optional, Dict, Any
import uuid
from datetime import datetime, timezone
import base64
import hashlib
import secrets
import jwt
from passlib.context import CryptContext
from datetime import timedelta
from functools import wraps
from emergentintegrations.llm.chat import LlmChat, UserMessage, ImageContent
import io
import cv2
import numpy as np
from PIL import Image
import json
import csv
import asyncio

ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

# MongoDB connection
mongo_url = os.environ['MONGO_URL']
client = AsyncIOMotorClient(mongo_url)
db = client[os.environ['DB_NAME']]

# Create the main app
app = FastAPI()
api_router = APIRouter(prefix="/api")

# Google API Key
GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY', '')

# Authentication settings
SECRET_KEY = os.environ.get('JWT_SECRET_KEY', secrets.token_urlsafe(32))
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30 * 24 * 60  # 30 days

# Password hashing
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# Authentication utilities
def verify_password(plain_password, hashed_password):
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password):
    return pwd_context.hash(password)

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.now(timezone.utc) + expires_delta
    else:
        expire = datetime.now(timezone.utc) + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

def verify_token(token: str):
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: str = payload.get("sub")
        if user_id is None:
            return None
        return user_id
    except jwt.PyJWTError:
        return None

# Authentication middleware
def get_current_user(authorization: str = None):
    if not authorization or not authorization.startswith("Bearer "):
        return None
    
    token = authorization.split("Bearer ")[1]
    user_id = verify_token(token)
    return user_id

def require_auth(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # Get request from args/kwargs (FastAPI dependency injection handles this)
        request = kwargs.get('request') or (args[0] if args else None)
        
        if not request:
            raise HTTPException(status_code=401, detail="Authentication required")
        
        auth_header = request.headers.get("Authorization")
        user_id = get_current_user(auth_header)
        
        if not user_id:
            raise HTTPException(status_code=401, detail="Invalid authentication credentials")
        
        # Add user_id to kwargs
        kwargs['current_user_id'] = user_id
        return await func(*args, **kwargs)
    
    return wrapper

def require_admin(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        request = kwargs.get('request') or (args[0] if args else None)
        
        if not request:
            raise HTTPException(status_code=401, detail="Authentication required")
        
        auth_header = request.headers.get("Authorization")
        user_id = get_current_user(auth_header)
        
        if not user_id:
            raise HTTPException(status_code=401, detail="Invalid authentication credentials")
        
        # Check if user is admin
        user = await db.users.find_one({"id": user_id})
        if not user or user.get("user_type") != "admin":
            raise HTTPException(status_code=403, detail="Admin access required")
        
        kwargs['current_user_id'] = user_id
        return await func(*args, **kwargs)
    
    return wrapper
# Models
class EmotionAnalysis(BaseModel):
    sorrindo: int = 0
    serio: int = 0
    triste: int = 0
    surpreso: int = 0
    zangado: int = 0
    neutro: int = 0

class SentimentAnalysis(BaseModel):
    positivo: int = 0
    neutro: int = 0
    negativo: int = 0

class GeoLocation(BaseModel):
    latitude: Optional[float] = None
    longitude: Optional[float] = None
    accuracy: Optional[float] = None  # in meters
    address: Optional[str] = None  # formatted address
    city: Optional[str] = None
    state: Optional[str] = None
    country: Optional[str] = None
    timestamp: Optional[datetime] = None

class FoodItem(BaseModel):
    name: str
    scientific_name: Optional[str] = None
    preparation_method: Optional[str] = None
    calories_per_100g: float
    estimated_portion_grams: float
    total_calories: float
    macronutrients: Dict[str, float] = Field(default_factory=dict)  # protein, carbs, fat, fiber
    detailed_fats: Dict[str, float] = Field(default_factory=dict)  # saturated, monounsaturated, polyunsaturated, trans
    carb_types: Dict[str, float] = Field(default_factory=dict)  # simple, complex
    glycemic_index: Optional[int] = None
    micronutrients: Dict[str, float] = Field(default_factory=dict)  # vitamins and minerals
    confidence: float = 0.0

class NutritionalAnalysis(BaseModel):
    foods_detected: List[FoodItem] = []
    total_calories: float = 0.0
    total_weight_grams: float = 0.0
    meal_type: Optional[str] = None
    nutritional_summary: Dict[str, float] = Field(default_factory=dict)
    # PhD-level additions
    quality_score: Optional[int] = None  # 0-100
    nutritional_balance: Dict[str, float] = Field(default_factory=dict)  # % protein, % carbs, % fat
    glycemic_load: Optional[float] = None
    nutritional_quality_index: Optional[float] = None
    health_recommendations: List[str] = []
    positive_aspects: List[str] = []
    improvement_areas: List[str] = []
    health_alerts: List[str] = []
    dietary_compatibility: Dict[str, bool] = Field(default_factory=dict)  # vegetarian, low-carb, etc
    ideal_consumption_time: Optional[str] = None
    dri_adequacy: Dict[str, float] = Field(default_factory=dict)  # % of daily recommended intake

class User(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    name: str
    email: str
    password_hash: str
    user_type: str = "user"  # "user" or "admin"
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    last_login: Optional[datetime] = None
    is_active: bool = True
    # Profile fields
    profile_photo: Optional[str] = None  # base64 encoded image
    bio: Optional[str] = None
    phone: Optional[str] = None
    birth_date: Optional[str] = None
    reset_token: Optional[str] = None
    reset_token_expiry: Optional[datetime] = None

class UserLogin(BaseModel):
    email: str
    password: str

class UserRegister(BaseModel):
    name: str
    email: str
    password: str
    user_type: str = "user"

class UserProfileUpdate(BaseModel):
    name: Optional[str] = None
    bio: Optional[str] = None
    phone: Optional[str] = None
    birth_date: Optional[str] = None
    profile_photo: Optional[str] = None

class PasswordResetRequest(BaseModel):
    email: str

class PasswordReset(BaseModel):
    token: str
    new_password: str

class DetectedObject(BaseModel):
    label: str
    confidence: float
    bbox: Optional[List[float]] = None

class Detection(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    source: str  # "webcam" or "upload"
    detection_type: str  # "local", "cloud", "nutrition", "text_reading"
    objects_detected: List[DetectedObject] = []
    description: str = ""
    image_data: Optional[str] = None  # base64 encoded
    alerts_triggered: List[str] = []
    emotion_analysis: Optional[EmotionAnalysis] = None
    sentiment_analysis: Optional[SentimentAnalysis] = None
    nutritional_analysis: Optional[NutritionalAnalysis] = None
    user_id: Optional[str] = None  # ID of the user who created this detection
    # New fields for enhanced functionality
    geo_location: Optional[GeoLocation] = None  # Geographic location
    category: Optional[str] = None  # Auto-categorized: "pessoas", "objetos", "alimentos", "texto", "ambiente", etc
    tags: List[str] = []  # Auto-generated tags for better search

class DetectionCreate(BaseModel):
    source: str
    detection_type: str
    image_data: str
    # Optional geolocation data from frontend
    geo_location: Optional[Dict[str, Any]] = None
def auto_categorize_detection(detection: Detection) -> str:
    """Automatically categorize detection based on content analysis"""
    
    # Category priority system
    if detection.detection_type == "nutrition":
        return "üçΩÔ∏è Alimentos e Nutri√ß√£o"
    
    if detection.detection_type == "text_reading":
        return "üìö Textos e Documentos"
    
    # Analyze description and objects for smart categorization
    description_lower = detection.description.lower()
    objects_labels = [obj.label.lower() for obj in detection.objects_detected]
    all_text = description_lower + " " + " ".join(objects_labels)
    
    # Define category keywords
    categories = {
        "üë• Pessoas e Rostos": [
            "pessoa", "pessoas", "homem", "mulher", "crian√ßa", "rosto", "facial",
            "sorrindo", "express√£o", "emo√ß√£o", "retrato", "grupo", "fam√≠lia"
        ],
        "üè† Ambientes e Lugares": [
            "ambiente", "sala", "quarto", "cozinha", "escrit√≥rio", "rua", "parque",
            "pr√©dio", "casa", "loja", "restaurante", "local", "espa√ßo", "interior", "exterior"
        ],
        "üêæ Animais e Natureza": [
            "animal", "cachorro", "gato", "p√°ssaro", "planta", "√°rvore", "flor",
            "natureza", "jardim", "pet", "bicho"
        ],
        "üöó Ve√≠culos e Transporte": [
            "carro", "√¥nibus", "moto", "bicicleta", "caminh√£o", "ve√≠culo",
            "transporte", "avi√£o", "trem", "barco"
        ],
        "üì± Eletr√¥nicos e Tecnologia": [
            "computador", "notebook", "celular", "telefone", "tablet", "tela",
            "teclado", "mouse", "eletr√¥nico", "tecnologia", "digital", "smartphone"
        ],
        "üëï Roupas e Acess√≥rios": [
            "roupa", "camisa", "cal√ßa", "vestido", "sapato", "t√™nis", "bolsa",
            "acess√≥rio", "√≥culos", "rel√≥gio", "joia", "bijuteria", "moda"
        ],
        "üé® Arte e Cultura": [
            "arte", "pintura", "quadro", "escultura", "cultural", "art√≠stico",
            "museu", "exposi√ß√£o", "obra"
        ],
        "üèÉ Esportes e Atividades": [
            "esporte", "atividade", "exerc√≠cio", "academia", "jogo", "bola",
            "corrida", "treino", "fitness"
        ],
        "üõçÔ∏è Compras e Produtos": [
            "produto", "compra", "mercado", "loja", "shopping", "item",
            "embalagem", "marca", "comercial"
        ],
        "üìã Documentos e Pap√©is": [
            "documento", "papel", "formul√°rio", "carta", "nota", "recibo",
            "certificado", "contrato", "escrito"
        ],
        "üç¥ Utens√≠lios e Objetos": [
            "objeto", "ferramenta", "utens√≠lio", "instrumento", "equipamento",
            "material", "item", "coisa"
        ],
    }
    
    # Score each category
    category_scores = {}
    for category, keywords in categories.items():
        score = sum(1 for keyword in keywords if keyword in all_text)
        if score > 0:
            category_scores[category] = score
    
    # Return highest scoring category or default
    if category_scores:
        return max(category_scores, key=category_scores.get)
    
    return "üîç Outros"

def generate_tags(detection: Detection) -> List[str]:
    """Generate smart tags for detection"""
    tags = []
    
    # Add detection type
    if detection.detection_type == "nutrition":
        tags.append("nutri√ß√£o")
        tags.append("alimentos")
    elif detection.detection_type == "text_reading":
        tags.append("texto")
        tags.append("leitura")
    else:
        tags.append("an√°lise-visual")
    
    # Add source
    tags.append(f"fonte-{detection.source}")
    
    # Extract key objects
    for obj in detection.objects_detected[:5]:  # Top 5 objects
        tags.append(obj.label.lower())
    
    # Add emotion tags if present
    if detection.emotion_analysis:
        emotions = detection.emotion_analysis.model_dump()
        for emotion, count in emotions.items():
            if count > 0:
                tags.append(f"emo√ß√£o-{emotion}")
    
    # Add sentiment tags
    if detection.sentiment_analysis:
        sentiments = detection.sentiment_analysis.model_dump()
        for sentiment, count in sentiments.items():
            if count > 0:
                tags.append(f"sentimento-{sentiment}")
    
    # Add location tag if present
    if detection.geo_location and detection.geo_location.city:
        tags.append(f"local-{detection.geo_location.city.lower()}")
    
    # Remove duplicates and return
    return list(set(tags))

class Alert(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    object_name: str
    enabled: bool = True
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class AlertCreate(BaseModel):
    object_name: str
    enabled: bool = True

class ScientificRecord(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    record_type: str  # "atividade", "trabalho", "artigo", "tcc"
    title: str
    authors: List[str] = []
    description: str
    keywords: List[str] = []
    research_line: str  # 1, 2, 3, ou 4
    status: str = "em_andamento"  # em_andamento, conclu√≠do, publicado
    date: str
    attachments: List[str] = []
    metadata: dict = {}

class ScientificRecordCreate(BaseModel):
    record_type: str
    title: str
    authors: List[str]
    description: str
    keywords: List[str]
    research_line: str
    status: str = "em_andamento"
    date: str
    attachments: List[str] = []
    metadata: dict = {}

class ReportQuery(BaseModel):
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    report_type: str = "general"  # general, emotions, objects, scientific

class ResearcherProfile(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    name: str
    institution: str
    area: str
    bio: str
    research_interests: List[str] = []
    contact_email: str
    avatar_url: Optional[str] = None

class ResearcherProfileCreate(BaseModel):
    name: str
    institution: str
    area: str
    bio: str
    research_interests: List[str]
    contact_email: str
    avatar_url: Optional[str] = None

class Post(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    author_id: str
    author_name: str
    content: str
    tags: List[str] = []
    likes: int = 0
    comments_count: int = 0

class PostCreate(BaseModel):
    author_id: str
    author_name: str
    content: str
    tags: List[str] = []

class Comment(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    post_id: str
    author_id: str
    author_name: str
    content: str

class CommentCreate(BaseModel):
    post_id: str
    author_id: str
    author_name: str
    content: str

# Routes
@api_router.get("/")
async def root():
    return {"message": "Sistema de Detec√ß√£o em Tempo Real"}

@api_router.post("/detect/analyze-frame", response_model=Detection)
async def analyze_frame(input: DetectionCreate, request: Request):
    """Analisa um frame da webcam ou imagem carregada usando Gemini Vision"""
    try:
        # Get authenticated user
        auth_header = request.headers.get("Authorization")
        user_id = get_current_user(auth_header)
        
        if not user_id:
            raise HTTPException(status_code=401, detail="Authentication required")
        
        # Decode base64 image
        image_data = input.image_data.split(',')[1] if ',' in input.image_data else input.image_data
        
        # Create detection object with user_id
        detection = Detection(
            source=input.source,
            detection_type=input.detection_type,
            image_data=input.image_data,
            user_id=user_id
        )
        
        if input.detection_type == "cloud":
            # Use Gemini Vision for detailed analysis with sentiment
            chat = LlmChat(
                api_key=GOOGLE_API_KEY,
                session_id=f"detection_{detection.id}",
                system_message="üáßüá∑ Voc√™ √© um sistema especialista em vis√£o computacional e an√°lise de emo√ß√µes BRASILEIRO. RESPONDA SEMPRE E EXCLUSIVAMENTE EM PORTUGU√äS BRASILEIRO. Analise imagens e forne√ßa descri√ß√µes detalhadas em portugu√™s do Brasil sobre pessoas, objetos, ambientes e estados emocionais. NUNCA responda em ingl√™s ou outro idioma!"
            ).with_model("gemini", "gemini-2.0-flash")
            
            image_content = ImageContent(image_base64=image_data)
            
            prompt = f"""üåç RESPONDA NO IDIOMA: PORTUGU√äS BRASILEIRO üáßüá∑

Voc√™ √© o SISTEMA DE VIS√ÉO MAIS AVAN√áADO DO MUNDO para acessibilidade total de pessoas cegas. Sua an√°lise deve ser T√ÉO DETALHADA que a pessoa cega possa formar uma imagem mental PERFEITA e COMPLETA da cena.

üéØ **N√çVEL DE PRECIS√ÉO: 200% M√ÅXIMO - ULTRARREALISTA - MICROSC√ìPICO**

‚ö†Ô∏è **REGRA FUNDAMENTAL:** Seja ABSURDAMENTE espec√≠fico em TUDO. N√£o use termos gen√©ricos. Cada detalhe deve ser QUANTIFICADO, QUALIFICADO e DESCRITO com precis√£o CIENT√çFICA.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

## üë• AN√ÅLISE DE PESSOAS (CADA PESSOA INDIVIDUALMENTE)

### üß¨ BIOMETRIA E CARACTER√çSTICAS F√çSICAS EXTREMAS:

**IDADE E G√äNERO ULTRAESPEC√çFICOS:**
- Idade: n√£o apenas "jovem" mas "aparenta 23-26 anos baseado em: pele sem rugas profundas, cabelos sem fios brancos, postura ereta, vestu√°rio moderno urbano"
- G√™nero aparente E justificativa: "masculino aparente baseado em: estrutura facial angular com queixo proeminente, ma√ß√£ de Ad√£o vis√≠vel, ombros largos de 45cm aproximadamente, aus√™ncia de maquiagem"
- Etnia/origem aparente: "apar√™ncia de descend√™ncia europeia n√≥rdica baseada em: pele muito clara, cabelos loiros naturais, olhos azuis, estrutura facial caracter√≠stica"

**ANATOMIA FACIAL MILIM√âTRICA:**
- Formato do cr√¢nio: "braquicef√°lico (mais largo que longo na propor√ß√£o 85:100), rosto oval alongado com propor√ß√£o altura:largura de 1.4:1"
- Testa: "ampla ocupando 40% da altura facial, lisa sem rugas horizontais, altura de aproximadamente 7cm da sobrancelha √† linha do cabelo"
- Sobrancelhas: "arqueadas em √¢ngulo de 15¬∞ no ponto mais alto, cor castanho m√©dio dois tons mais escura que o cabelo, espessura m√©dia de 4-5mm, separadas por 3cm, pelos com 8mm de comprimento, formato natural n√£o depilado"
- Olhos ULTRA-DETALHADOS:
  * Cor: "castanhos m√©dios tom mel com varia√ß√µes de dourado pr√≥ximo √† pupila, reflexos √¢mbar sob luz intensa, anel limbal escuro de 1mm na borda da √≠ris"
  * Formato: "amendoados com inclina√ß√£o ascendente de 10¬∞ nos cantos externos, dist√¢ncia interpupilar de 65mm"
  * P√°lpebras: "p√°lpebra superior com prega dupla de 3mm, p√°lpebra inferior com leve bolsa de 2mm"
  * C√≠lios: "superiores com 10mm de comprimento, inferiores com 6mm, curvatura natural para cima de 45¬∞, sem m√°scara"
  * Esclera: "branca sem vermelhid√£o, vasos sangu√≠neos discretos"
  * Pupila: "di√¢metro de 4mm sob ilumina√ß√£o moderada, circular perfeita"
  * Express√£o: "olhar direto para c√¢mera com foco total, sobrancelhas relaxadas, sem tens√£o muscular periocular"
- Nariz MEDIDAS EXATAS: "comprimento de 5cm da raiz at√© ponta, largura da base de 3.5cm, narinas ovaladas com 1.2cm de altura, ponte nasal reta sem curvatura, ponta arredondada n√£o pontiaguda, filtro nasal bem definido com 1.5cm"
- Boca e l√°bios COM PRECIS√ÉO: "l√°bio superior com 8mm de altura no centro (arco de cupido proeminente), l√°bio inferior com 12mm de altura (propor√ß√£o 1:1.5), largura total da boca de 5cm, cor rosa natural m√©dio sem batom, textura hidratada sem rachaduras, cantos da boca neutros sem eleva√ß√£o ou queda"
- Queixo E MAND√çBULA: "queixo proeminente com proje√ß√£o anterior de 1cm, formato quadrado com largura de 8cm, mand√≠bula angular e definida, sem papada, √¢ngulo da mand√≠bula de 110¬∞ (square jaw)"
- Orelhas: "tamanho m√©dio com 6cm de altura, formato standard sem despropor√ß√µes, l√≥bulos soltos com 1.5cm, h√©lix bem formada"
- Pele AN√ÅLISE DERMATOL√ìGICA:
  * Tonalidade: "Fitzpatrick tipo III (moreno claro), hex aproximado #C8997F, subtom quente com base amarelada, uniforme sem manchas evidentes"
  * Textura: "poros vis√≠veis mas refinados com 0.2mm de di√¢metro m√©dio, sem acne ativa, 2 pequenas cicatrizes de acne antiga de 2mm no maxilar esquerdo, 1 marca de nascen√ßa castanha de 5mm no pesco√ßo lado direito"
  * Hidrata√ß√£o: "bem hidratada com brilho natural na zona T (testa, nariz, queixo), sem descama√ß√£o"
  * Linhas de express√£o: "linhas finas de 0.1mm nos cantos externos dos olhos (p√©s de galinha iniciais), linha √∫nica horizontal na testa quando sobrancelhas levantadas"

**CABELOS - AN√ÅLISE CAPILAR PROFISSIONAL:**
- Cor FORMULADA: "castanho n√≠vel 5 com subtons dourados, reflexos de mel nas pontas por exposi√ß√£o solar, 5% de fios grisalhos concentrados nas t√™mporas (20 fios vis√≠veis), raiz virgem sem colora√ß√£o qu√≠mica"
- Comprimento CENT√çMETROS: "m√©dio com 22cm de comprimento da raiz √†s pontas, alcan√ßando 3cm abaixo dos ombros, comprimento uniforme sem camadas"
- Textura TIPO EXATO: "ondulado tipo 2B com ondas soltas em S, di√¢metro do fio de 70 micr√¥metros (m√©dio), densidade capilar alta com 150 fios/cm¬≤, porosidade m√©dia"
- Volume e corpo: "volumoso com 8cm de di√¢metro total na altura da orelha, corpo natural sem produto de volume"
- Penteado ESPEC√çFICO: "solto com reparti√ß√£o lateral esquerda natural a 4cm da linha central, caindo naturalmente sobre ombros, pontas ligeiramente viradas para dentro, franja lateral varrida para direita cobrindo metade da testa"
- Estado e sa√∫de: "saud√°vel com brilho natural indicando cut√≠cula fechada, pontas com 2% de split ends (10 fios com bifurca√ß√£o nas pontas), sem frizz significativo"
- Produtos detect√°veis: "leve aplica√ß√£o de leave-in vis√≠vel pelo brilho controlado, sem gel ou cera, sem spray fixador"
- Acess√≥rios: "1 grampo bobby pin cor prata de 5cm no lado direito mantendo mechas atr√°s da orelha, sem outros acess√≥rios"

**MAQUIAGEM - COSMETIC ANALYSIS:**
- Base: "foundation l√≠quido aplicado uniformemente, cobertura m√©dia, tom matching perfeito #C8997F, acabamento natural matte, sem oxida√ß√£o"
- Olhos: "sombra nude matte no c√¥ncavo, delineador marrom fino de 1mm no c√≠lio superior, 2 camadas de m√°scara volumizadora"
- Sobrancelhas: "preenchidas com l√°pis cor taupe, pelos penteados para cima, fixadas com gel transparente"
- Bochechas: "blush p√™ssego aplicado na ma√ß√£ do rosto, intensidade leve"
- L√°bios: "batom nude rosado #D7A09A, acabamento cremoso, sem gloss"
- Acabamento: "p√≥ transl√∫cido na zona T para controle de oleosidade"

### üëó VESTU√ÅRIO - FASHION FORENSICS ANALYSIS:

**PARTE SUPERIOR COM DETALHES T√äXTEIS:**
- Tipo: "camiseta gola redonda (crew neck) de manga curta com manga terminando 5cm acima do cotovelo"
- Material COMPOSI√á√ÉO: "100% algod√£o penteado 180g/m¬≤ (peso m√©dio), trama Jersey simples com elasticidade moderada de 15%, toque macio levemente amaciado"
- Cor PANTONE: "branco √≥ptico #FFFFFF com leve
   - CORES EXATAS com c√≥digo de cor (vermelho carmesim, azul marinho profundo, verde musgo, amarelo mostarda, rosa millennial, preto √¥nix)
   - PADR√ïES E ESTAMPAS detalhados (listras horizontais azuis e brancas de 2cm, xadrez vichy vermelho, floral vintage com rosas, estampa de on√ßa, tie-dye degrad√™, geom√©trico art d√©co)
   - TECIDOS APARENTES (algod√£o leve, jeans denim pesado, seda fluida, l√£ grossa, poli√©ster acetinado, linho natural, veludo cotel√™)
   - MARCAS VIS√çVEIS: identifique TODOS os logos, tags, escritos, patches em roupas (Nike, Adidas, Gucci, Supreme, logos universit√°rios, bandeiras, frases)
   - Estado da roupa COMPLETO (nova com etiquetas, usada bem cuidada, amarrotada, manchada, rasgada, desbotada, vintage)
   - Estilo ESPEC√çFICO (casual street, formal executivo, esportivo fitness, business casual, bo√™mio, minimalista, vintage retr√¥)
   - Camadas de roupa e sobreposi√ß√µes
   - Detalhes de costura, bot√µes, z√≠peres, fechamentos
   
   **BIJUTERIAS E ACESS√ìRIOS EM DETALHES M√ÅXIMOS:**
   - Brincos: tipo EXATO (argola, bot√£o, chandelier, ear cuff), tamanho em cm, material (ouro 18k, prata 925, a√ßo, bijuteria), brilho ou pedras
   - Colares: comprimento (gargantilha, princesa, √≥pera), tipo de corrente, pingentes (formato, significado), camadas m√∫ltiplas
   - Pulseiras: quantidade exata, posi√ß√£o (pulso direito/esquerdo), estilo (riviera, charm, couro, tecido), fechos
   - An√©is: dedo espec√≠fico (indicador, m√©dio, anelar, m√≠nimo), tipo (solit√°rio, alian√ßa, anel de formatura), pedras identific√°veis
   - Rel√≥gios: marca se vis√≠vel, tipo (anal√≥gico/digital/smartwatch), cor da pulseira, tamanho da caixa, funcionalidades vis√≠veis
   - √ìculos: formato PRECISO (aviador, wayfarer, gatinho, redondo), cor e material da arma√ß√£o, tipo de lente (transparente, escura, espelhada, graduada)
   - Piercings: localiza√ß√£o exata (septo, l√°bio, sobrancelha, l√≠ngua), tipo, material
   - Tatuagens: localiza√ß√£o precisa, tamanho aproximado, estilo (tradicional, realista, aquarela, minimalista), tema ou desenho, cores
   
   **CAL√áADOS ULTRA-DETALHADOS:**
   - Tipo ESPEC√çFICO (t√™nis running, t√™nis casual, oxford, scarpin, sand√°lia gladiadora, chinelo slide, bota cano longo)
   - Marca quando vis√≠vel (Nike, Adidas, Vans, Converse, Havaianas)
   - Modelo quando identific√°vel
   - Cor EXATA e detalhes de design
   - Material (couro leg√≠timo, sint√©tico, lona, borracha, camur√ßa)
   - Estado COMPLETO (novo sem uso, levemente usado, muito usado, manchado, desgastado na sola)
   - Altura do salto se aplic√°vel (rasteiro, salto baixo 2-4cm, m√©dio 5-7cm, alto 8-12cm, plataforma)
   - Cadar√ßos: cor, tipo, como est√£o amarrados
   - Meias ou meia-cal√ßa: cor, transpar√™ncia, padr√£o, altura
   
   **OUTROS ACESS√ìRIOS DETALHADOS:**
   - Bolsas: tipo ESPEC√çFICO (mochila, shoulder bag, clutch, tote, crossbody), tamanho em litros ou cm, cor e texturas, marca se vis√≠vel, estado de conserva√ß√£o, al√ßas/correntes
   - Chap√©us ou bon√©s: estilo EXATO (bon√© aba reta, aba curva, bucket hat, fedora, panama), cor, material, logos ou bordados, ajuste
   - Len√ßos ou echarpes: tamanho, tecido, padr√£o, como est√° amarrado/usado
   - Cintos: largura, cor, material, tipo de fivela (met√°lica, autom√°tica), marcas/logos
   - Mochilas: tamanho, n√∫mero de compartimentos vis√≠veis, marca, estado
   - Luvas: tipo, material, cor, comprimento
   - Qualquer objeto que a pessoa est√° segurando: descri√ß√£o completa (smartphone, garrafa d'√°gua, livro, chaves, etc.)
   
   **POSTURA E LINGUAGEM CORPORAL ULTRA-DETALHADA:**
   - Posi√ß√£o do corpo PRECISA (em p√© ereto, sentado relaxado, deitado de costas, caminhando em dire√ß√£o √† c√¢mera, agachado, inclinado)
   - Distribui√ß√£o de peso corporal
   - Alinhamento postural (ereta, curvada, torta)
   - Dire√ß√£o do olhar E FOCO: para onde EXATAMENTE est√° olhando (c√¢mera, horizonte, ch√£o, outra pessoa, objeto espec√≠fico)
   - Posi√ß√£o dos bra√ßos: EXATA (ao longo do corpo, cruzados no peito, m√£os nos quadris, um bra√ßo levantado)
   - Posi√ß√£o das m√£os: DETALHADA (abertas, fechadas, dedos entrela√ßados, segurando algo, gesticulando)
   - Posi√ß√£o das pernas (cruzadas, abertas, uma √† frente, apoiadas)
   - Express√£o facial COMPLETA (m√∫sculos faciais ativos, linha da boca, rugas vis√≠veis)
   - Gestos espec√≠ficos que est√° fazendo (apontando, acenando, polegar para cima, sinal de paz)
   - Dist√¢ncia aproximada em rela√ß√£o √† c√¢mera
   
   **AN√ÅLISE EMOCIONAL E PSICOL√ìGICA AVAN√áADA:**
   - Express√£o facial MICROSC√ìPICA (sorriso genu√≠no com olhos, sorriso for√ßado, testa franzida, sobrancelhas levantadas, l√°bios apertados)
   - Estado emocional COMPLETO (feliz radiante, tristeza profunda, ansiedade moderada, relaxado tranquilo, excitado animado, entediado, surpreso)
   - Microexpress√µes observ√°veis (piscar frequente, movimentos sutis da boca, tens√£o facial)
   - Linguagem corporal emocional (ombros ca√≠dos=tristeza, peito aberto=confian√ßa, bra√ßos cruzados=defesa)
   - Sinais de estado f√≠sico: cansa√ßo (olhos pesados, postura curvada), energia (movimentos v√≠vidos), estresse (tens√£o vis√≠vel), dor, desconforto
   - N√≠vel de conforto com a situa√ß√£o
   - Sinais de intera√ß√£o social (conectado/desconectado com outros)
   
   **ATIVIDADES E CONTEXTO COMPORTAMENTAL:**
   - O que EXATAMENTE a pessoa est√° fazendo (lendo um livro de capa azul, digitando no notebook, tomando caf√©, conversando ao telefone, exercitando-se)
   - Intera√ß√µes com outras pessoas: DETALHADAS (conversando olhando nos olhos, ignorando, rindo juntos, discutindo, colaborando em tarefa)
   - Intera√ß√£o com objetos: ESPEC√çFICA (segurando smartphone com m√£o direita, apoiado em mesa, sentado em cadeira girat√≥ria)
   - Localiza√ß√£o na cena: PRECISA (canto inferior esquerdo, centro da imagem, ao fundo √† direita, plano principal)
   - Movimento impl√≠cito (parado, andando, correndo, movimento de bra√ßo)

2. **OBJETOS E ELEMENTOS VIS√çVEIS** - Identifique ABSOLUTAMENTE TUDO com detalhes extremos:
   
   **M√ìVEIS E MOBILI√ÅRIO:**
   - Tipo ESPEC√çFICO (sof√° de 3 lugares, cadeira office ergon√¥mica, mesa de jantar retangular, estante modular, rack para TV)
   - Material DETALHADO (madeira maci√ßa de carvalho, MDF laqueado, metal cromado, vime natural, pl√°stico injetado, vidro temperado)
   - Cor EXATA e acabamento (branco brilhante, cinza fosco, madeira natural vernizada, preto matte)
   - Dimens√µes aproximadas (largura x profundidade x altura em cm)
   - Estilo (moderno minimalista, cl√°ssico colonial, industrial, escandinavo, r√∫stico)
   - Condi√ß√£o COMPLETA (novo sem marcas, usado bem conservado, desgastado com arranh√µes, manchado, quebrado)
   - Posi√ß√£o e orienta√ß√£o no espa√ßo
   - Funcionalidade atual (em uso, vazio, coberto com objetos)
   
   **ELETR√îNICOS E TECNOLOGIA:**
   - Dispositivos ESPEC√çFICOS (notebook Dell 15", smartphone iPhone 14 Pro, TV Samsung 55" QLED, tablet iPad, fones Bluetooth)
   - Estado: ligado com tela acesa, desligado, em modo standby, carregando
   - Marcas vis√≠veis e modelos identific√°veis
   - Cabos, carregadores, acess√≥rios conectados
   - Conte√∫do da tela se vis√≠vel
   - Idade aparente do dispositivo
   - Posi√ß√£o e dist√¢ncia de outros objetos
   
   **DECORA√á√ÉO E ARTE:**
   - Quadros: tamanho, tipo de moldura, tema da imagem (paisagem, retrato, abstrato), cores dominantes, estilo art√≠stico
   - Plantas: tipo (suculenta, samambaia, espada-de-s√£o-jorge), tamanho, vaso (material, cor, formato), estado de sa√∫de
   - Ornamentos: descri√ß√£o completa (vaso decorativo, escultura, bibel√¥), material, cor, estilo
   - Cortinas: tecido, cor, padr√£o, estado (abertas, fechadas, semi-abertas)
   - Almofadas: quantidade, cores, padr√µes, disposi√ß√£o
   - Tapetes: tamanho, padr√£o, cores, textura aparente
   
   **UTENS√çLIOS E OBJETOS DO DIA-A-DIA:**
   - Ferramentas: tipo espec√≠fico, marca, estado
   - Livros: t√≠tulos se vis√≠veis, cores das capas, tamanho, posi√ß√£o (aberto, fechado, empilhado)
   - Documentos: tipo (folhas avulsas, caderno, revista), quantidade vis√≠vel
   - Comida: tipo ESPEC√çFICO, quantidade, estado (fresco, meio consumido), apresenta√ß√£o
   - Bebida: tipo (√°gua, caf√©, refrigerante), recipiente, n√≠vel do l√≠quido
   - Utens√≠lios de cozinha, escrita, higiene pessoal (descreva cada item)
   
   **ARQUITETURA E ESTRUTURA:**
   - Portas: material (madeira, vidro, metal), cor, tipo (convencional, deslizante), estado (aberta, fechada, entreaberta), ma√ßanetas
   - Janelas: tamanho, quantidade, tipo (correr, basculante, guilhotina), vidro (transparente, fosco), presen√ßa de grades ou redes
   - Paredes: material aparente (gesso, tijolo aparente, madeira, azulejo), cor, textura, decora√ß√µes/quadros, tomadas e interruptores vis√≠veis
   - Piso: material (madeira, cer√¢mica, porcelanato, carpete, vin√≠lico), cor, padr√£o, estado de conserva√ß√£o, reflexo de luz
   - Teto: altura aproximada, cor, tipo (laje, gesso, madeira), ilumina√ß√£o embutida, ventiladores ou ar-condicionado
   - Rodap√©s, molduras, detalhes arquitet√¥nicos
   - Localiza√ß√£o espacial PRECISA: disposi√ß√£o tridimensional, profundidade, planos (primeiro plano, plano m√©dio, fundo)

3. **AMBIENTE COMPLETO E ATMOSFERA EM DETALHES M√ÅXIMOS**:
   
   **IDENTIFICA√á√ÉO E CLASSIFICA√á√ÉO DO LOCAL:**
   - Tipo ESPEC√çFICO de local (cozinha planejada moderna, sala de estar familiar, escrit√≥rio corporativo, rua comercial urbana, parque p√∫blico, praia, montanha, ambiente interno/externo)
   - Sub-classifica√ß√£o (se cozinha: gourmet, compacta, industrial; se sala: TV, jantar, estar; se escrit√≥rio: home office, corporativo aberto, sala de reuni√£o)
   - Prop√≥sito aparente do espa√ßo
   
   **DIMENS√ïES E LAYOUT ESPACIAL:**
   - Tamanho aproximado do ambiente (pequeno 10-15m¬≤, m√©dio 20-40m¬≤, grande 50m¬≤+)
   - P√©-direito (altura do teto): baixo 2,4m, m√©dio 2,7m, alto 3m+, p√©-direito duplo
   - Formato do espa√ßo (quadrado, retangular, L, aberto integrado)
   - Distribui√ß√£o dos m√≥veis e objetos
   - Circula√ß√£o e espa√ßos vazios
   - Profundidade de campo (primeiro plano, m√©dio, fundo)
   
   **ILUMINA√á√ÉO ULTRA-DETALHADA:**
   - Tipo principal: Natural (luz do dia, sol direto, luz difusa) OU Artificial (LED, incandescente, fluorescente, mista)
   - Intensidade PRECISA: muito escuro, penumbra, iluminado moderado, bem iluminado, muito brilhante, ofuscante
   - Dire√ß√£o da luz: frontal, lateral, superior, contraluz, difusa de v√°rias dire√ß√µes
   - Temperatura de cor: luz fria azulada (6500K+), neutra (4000K), quente amarelada (2700-3000K)
   - Fontes de luz vis√≠veis: janelas (quantidade, tamanho, orienta√ß√£o), lumin√°rias (pendentes, spots, abajures, arandelas), l√¢mpadas expostas
   - Sombras: duras e definidas, suaves e difusas, aus√™ncia de sombras, dire√ß√£o das sombras
   - Reflexos: em superf√≠cies met√°licas, vidros, pisos brilhantes, espelhos
   - Contraste: alto contraste com √°reas muito escuras e muito claras, baixo contraste suave
   - Hora do dia aparente pela luz: amanhecer dourado, meio-dia intenso, tarde suave, entardecer alaranjado, noite artificial
   
   **CORES E PALETA CROM√ÅTICA:**
   - Paleta de cores DOMINANTE: monocrom√°tica, complementar, an√°loga, tri√°dica
   - Cores principais do ambiente com percentuais (70% branco, 20% cinza, 10% azul)
   - Cores de destaque e acentos
   - Satura√ß√£o geral: cores vivas e saturadas, tons past√©is suaves, neutros dessaturados, preto e branco
   - Harmonia crom√°tica: equilibrada, contrastante, ca√≥tica
   - C√≥digos aproximados (branco gelo, cinza chumbo, azul marinho, verde oliva, terracota, bege areia)
   
   **TEXTURAS E MATERIAIS VIS√çVEIS:**
   - Texturas T√ÅTEIS aparentes: liso brilhante (vidro, acr√≠lico), liso fosco (gesso, MDF pintado), √°spero (concreto, pedra), macio (tecidos, carpete), granulado (porcelanato, granito)
   - Superf√≠cies: polidas e reflexivas, foscas e absorventes, rugosas, estriadas
   - Materiais identificados: madeira (tipo se poss√≠vel), metal (inox, ferro, alum√≠nio), vidro, pl√°stico, tecido (algod√£o, linho, veludo), couro, cer√¢mica, pedra natural
   - Acabamentos: verniz, laca, pintura, natural sem tratamento
   
   **CLIMA, ATMOSFERA E SENSA√á√ÉO:**
   - Estilo GERAL: minimalista moderno, cl√°ssico tradicional, r√∫stico aconchegante, industrial urbano, bo√™mio ecl√©tico, luxuoso sofisticado, casual despojado
   - Formalidade: muito formal executivo, semi-formal, casual relaxado, informal bagun√ßado
   - Limpeza e organiza√ß√£o: impec√°vel arrumado, organizado funcional, levemente bagun√ßado, muito desorganizado, sujo
   - Conserva√ß√£o: novo rec√©m-constru√≠do, bem mantido, desgaste leve, necessitando reformas, deteriorado
   - Sensa√ß√£o t√©rmica aparente: ambiente fresco/frio, neutro confort√°vel, quente/abafado (por elementos visuais como ventiladores ligados, pessoas com roupas leves)
   - Ventila√ß√£o: janelas abertas, ar condicionado vis√≠vel, ventiladores, ambiente fechado
   - Umidade aparente: seco, normal, √∫mido (condensa√ß√£o, mofo, plantas)
   
   **SONS IMPL√çCITOS (inferidos pela cena visual):**
   - Sons ambientes prov√°veis: sil√™ncio total, ru√≠do urbano de fundo, tr√¢nsito, conversas distantes, m√∫sica tocando (se h√° caixas de som), TV ligada, natureza (p√°ssaros, vento, √°gua)
   - Sons de atividades: digita√ß√£o, passos, objetos sendo manipulados, m√°quinas funcionando
   - N√≠vel de ru√≠do estimado: ambiente silencioso, moderado, barulhento
   
   **CLIMA METEOROL√ìGICO (se ambiente externo ou vis√≠vel pela janela):**
   - Condi√ß√µes: c√©u claro ensolarado, parcialmente nublado, nublado fechado, chuvoso, tempestade
   - Fen√¥menos: sol forte, sombras longas, neblina, chuva, vento (√°rvores balan√ßando), neve
   - Visibilidade: excelente, boa, reduzida

4. **CONTEXTO, NARRATIVA E HIST√ìRIA DA CENA**:
   
   **A√á√ÉO PRINCIPAL:**
   - O que est√° acontecendo AGORA na cena: descri√ß√£o completa da a√ß√£o central
   - Momento no tempo: antes, durante ou depois de uma a√ß√£o
   - Movimento: est√°tico parado, movimentos lentos, a√ß√£o r√°pida, congelamento de movimento
   
   **HIST√ìRIA E SITUA√á√ÉO:**
   - Poss√≠vel narrativa completa: qual hist√≥ria esta cena conta?
   - Contexto social: reuni√£o de trabalho, encontro familiar, momento solit√°rio, evento p√∫blico, situa√ß√£o casual
   - Prop√≥sito da cena: fotografia posada, momento espont√¢neo, documenta√ß√£o, art√≠stica
   - O que pode ter acontecido antes e o que pode acontecer depois
   
   **RELA√á√ïES E INTERA√á√ïES:**
   - Rela√ß√µes entre pessoas vis√≠veis: familiares, amigos, colegas, estranhos, distantes, pr√≥ximos
   - Din√¢mica social: colaborativa, competitiva, harmoniosa, tensa
   - Rela√ß√µes pessoa-objeto: intera√ß√£o ativa (usando), posse (segurando), proximidade
   - Rela√ß√µes pessoa-ambiente: confort√°vel, deslocada, integrada, dominante na cena
   - Hierarquia visual: quem/o que √© o foco principal, secund√°rio, fundo
   
   **TEMPORALIDADE:**
   - Hora do dia ESPEC√çFICA (inferida pela luz e atividades): 06h-09h manh√£, 09h-12h meio da manh√£, 12h-14h meio-dia, 14h-17h tarde, 17h-20h fim de tarde/noite, 20h+ noite
   - Esta√ß√£o do ano aparente (roupas, decora√ß√£o, luz): primavera, ver√£o, outono, inverno
   - √âpoca: contempor√¢nea, recente, passado (indicadores temporais)
   - Momento do ciclo: in√≠cio (chegando), meio (acontecendo), fim (saindo)
   
   **CONTEXTO CULTURAL E SOCIAL:**
   - Indicadores culturais: bandeiras, s√≠mbolos, idiomas vis√≠veis, objetos t√≠picos
   - Classe social aparente: indicadores de poder aquisitivo
   - Contexto geogr√°fico: urbano/rural, pa√≠s/regi√£o (se identific√°vel)

5. **DETALHES CR√çTICOS DE ACESSIBILIDADE PARA PESSOAS COM DEFICI√äNCIA VISUAL**:
   
   **MOBILIDADE E NAVEGA√á√ÉO:**
   - Obst√°culos f√≠sicos ESPEC√çFICOS: m√≥veis baixos que podem causar trope√ßo, objetos no ch√£o, degraus, desn√≠veis, portas estreitas, passagens bloqueadas
   - Facilidades de mobilidade: corredores amplos (largura em metros), espa√ßo livre para circula√ß√£o, rampas, elevadores, corrim√£os
   - Superf√≠cies do piso: lisa f√°cil de andar, irregular com risco de trope√ßo, escorregadia (molhada, encerada), com textura de alerta
   - Mudan√ßas de n√≠vel: degraus (quantidade, altura), rampas (inclina√ß√£o), eleva√ß√µes
   
   **ELEMENTOS DE SEGURAN√áA:**
   - Sinaliza√ß√µes de seguran√ßa vis√≠veis: sa√≠da de emerg√™ncia, extintor, placas de aten√ß√£o/perigo
   - Ilumina√ß√£o de seguran√ßa: boa visibilidade geral, √°reas escuras perigosas
   - Riscos identificados: objetos pontiagudos, bordas afiadas, superf√≠cies quentes, √°reas de risco de queda
   - Elementos de prote√ß√£o: grades em janelas, prote√ß√µes em escadas, tapetes antiderrapantes
   
   **PONTOS DE REFER√äNCIA IMPORTANTES:**
   - Marcos visuais principais para orienta√ß√£o: porta de entrada (posi√ß√£o), janelas grandes, m√≥veis dominantes, paredes coloridas
   - Elementos fixos que servem de refer√™ncia: colunas, pilares, divis√≥rias, bancadas fixas
   - Caracter√≠sticas √∫nicas do ambiente: qualquer elemento distintivo para ajudar na orienta√ß√£o espacial
   - Sinaliza√ß√£o t√°til se vis√≠vel: piso t√°til, braile, texturas de alerta
   
   **INFORMA√á√ïES TEXTUAIS E VISUAIS:**
   - Texto vis√≠vel: placas, avisos, etiquetas, letreiros (transcrever tudo)
   - S√≠mbolos e √≠cones: banheiro, acessibilidade, proibido, aten√ß√£o (descrever cada um)
   - Cores codificadas: verde=seguro, vermelho=perigo, azul=informa√ß√£o
   
   **CONFORTO E USABILIDADE:**
   - Ergonomia aparente: m√≥veis adaptados, altura acess√≠vel
   - Espa√ßo pessoal: densidade de objetos/pessoas, sensa√ß√£o de aperto ou amplitude
   - Conforto ambiental: temperatura aparente, ventila√ß√£o, n√≠vel de ru√≠do estimado

Forne√ßa uma resposta JSON COMPLETA em portugu√™s com esta estrutura:
{
  "objects": [
    {
      "label": "pessoa/objeto espec√≠fico", 
      "confidence": 0.95, 
      "description": "descri√ß√£o ULTRA-DETALHADA em portugu√™s com todos os detalhes poss√≠veis (m√≠nimo 100 palavras por objeto importante)",
      "position": "localiza√ß√£o exata na cena (canto superior esquerdo, centro, primeiro plano √† direita)",
      "colors": ["cor1 exata", "cor2 exata", "cor3 exata"],
      "materials": ["material1", "material2"],
      "size": "tamanho aproximado (pequeno, m√©dio, grande, dimens√µes se poss√≠vel)",
      "emotions": {
        "expression": "descri√ß√£o microsc√≥pica da express√£o",
        "emotional_state": "estado emocional profundamente detalhado",
        "is_smiling": true/false,
        "sentiment": "an√°lise psicol√≥gica completa do sentimento",
        "energy_level": "n√≠vel de energia com justificativa detalhada",
        "body_language": "linguagem corporal completa"
      }
    }
  ],
  "environment": {
    "type": "tipo espec√≠fico do local",
    "dimensions": "tamanho aproximado do espa√ßo",
    "lighting": {
      "type": "natural/artificial/mista",
      "intensity": "n√≠vel de intensidade",
      "temperature": "quente/neutra/fria",
      "time_of_day": "hora aparente do dia"
    },
    "colors": {
      "dominant": ["cor1", "cor2", "cor3"],
      "accents": ["cor4", "cor5"]
    },
    "atmosphere": "descri√ß√£o completa da atmosfera e sensa√ß√£o",
    "sounds_implied": ["som1 prov√°vel", "som2 prov√°vel"]
  },
  "description": "DESCRI√á√ÉO NARRATIVA ULTRA-RICA, EXTREMAMENTE DETALHADA E COMPLETA da cena em portugu√™s brasileiro. Imagine que voc√™ est√° descrevendo para uma pessoa TOTALMENTE CEGA e precisa transmitir ABSOLUTAMENTE TUDO que voc√™ v√™ com o m√°ximo de detalhes poss√≠vel. Inclua cores exatas, texturas, materiais, posi√ß√µes espaciais, dist√¢ncias, tamanhos, estados emocionais, express√µes faciais, roupas com todos os detalhes, acess√≥rios, ambiente completo, ilumina√ß√£o, atmosfera, o que est√° acontecendo, rela√ß√µes entre elementos. M√≠nimo 300 palavras. Esta descri√ß√£o deve ser t√£o rica que a pessoa cega consiga formar uma imagem mental completa e precisa da cena.",
  "overall_sentiment": "an√°lise psicol√≥gica profunda do sentimento, atmosfera geral, emo√ß√µes transmitidas pela cena completa",
  "accessibility_notes": "informa√ß√µes cr√≠ticas para acessibilidade, navega√ß√£o, seguran√ßa, obst√°culos, pontos de refer√™ncia, texto vis√≠vel transcrito",
  "emotion_analysis": {
    "sorrindo": 0,
    "serio": 0,
    "triste": 0,
    "surpreso": 0,
    "zangado": 0,
    "neutro": 0
  },
  "sentiment_analysis": {
    "positivo": 0,
    "neutro": 0,
    "negativo": 0
  },
  "visual_details": {
    "dominant_colors": ["lista de cores dominantes com nomes exatos"],
    "textures": ["lista de texturas vis√≠veis"],
    "patterns": ["lista de padr√µes identificados"],
    "text_visible": "TODO texto vis√≠vel na imagem transcrito aqui",
    "brands_logos": ["marcas e logos identificados"]
  },
  "spatial_analysis": {
    "depth": "an√°lise de profundidade (primeiro plano, meio, fundo)",
    "perspective": "tipo de perspectiva e √¢ngulo da c√¢mera",
    "distances": "dist√¢ncias aproximadas entre elementos principais"
  }
}

IMPORTANTE: 
- Para emotion_analysis e sentiment_analysis, conte QUANTAS PESSOAS na imagem apresentam cada emo√ß√£o/sentimento. 
- Por exemplo, se h√° 3 pessoas sorrindo, coloque "sorrindo": 3. Se h√° 2 pessoas com sentimento positivo, coloque "positivo": 2.
- A "description" deve ser EXTREMAMENTE detalhada, m√≠nimo 300 palavras, descrevendo TUDO que voc√™ v√™.
- Transcreva TODO texto vis√≠vel em "text_visible".
- Seja incrivelmente espec√≠fico em cores (n√£o apenas "azul", mas "azul marinho profundo"), texturas, materiais, posi√ß√µes.

üáßüá∑ LEMBRE-SE: TODA A DESCRI√á√ÉO DEVE ESTAR EM PORTUGU√äS BRASILEIRO COM M√ÅXIMO DETALHAMENTO! N√ÉO USE INGL√äS! üáßüá∑"""
            
            user_message = UserMessage(
                text=prompt,
                file_contents=[image_content]
            )
            
            # Retry logic for Gemini API
            max_retries = 3
            retry_delay = 2
            response = None
            last_error = None
            
            for attempt in range(max_retries):
                try:
                    response = await chat.send_message(user_message)
                    break  # Success, exit retry loop
                except Exception as e:
                    last_error = e
                    error_msg = str(e).lower()
                    
                    if '503' in error_msg or 'overloaded' in error_msg or 'rate' in error_msg:
                        if attempt < max_retries - 1:
                            logging.warning(f"Gemini API overloaded, retrying in {retry_delay}s... (attempt {attempt + 1}/{max_retries})")
                            import asyncio
                            await asyncio.sleep(retry_delay)
                            retry_delay *= 2
                            continue
                        else:
                            raise HTTPException(
                                status_code=503,
                                detail="O servi√ßo de IA est√° temporariamente sobrecarregado. Por favor, tente novamente em alguns instantes."
                            )
                    else:
                        raise
            
            if response is None:
                raise last_error or Exception("Failed to get response from Gemini")
            
            # Parse response
            try:
                # Try to extract JSON from response
                response_text = response.strip()
                if '```json' in response_text:
                    response_text = response_text.split('```json')[1].split('```')[0].strip()
                elif '```' in response_text:
                    response_text = response_text.split('```')[1].split('```')[0].strip()
                
                result = json.loads(response_text)
                detection.objects_detected = [
                    DetectedObject(**obj) for obj in result.get('objects', [])
                ]
                detection.description = result.get('description', response)
                
                # Process emotion and sentiment analysis
                if 'emotion_analysis' in result:
                    detection.emotion_analysis = EmotionAnalysis(**result['emotion_analysis'])
                if 'sentiment_analysis' in result:
                    detection.sentiment_analysis = SentimentAnalysis(**result['sentiment_analysis'])
            except:
                # If JSON parsing fails, use raw response
                detection.description = response
                detection.objects_detected = []
        
        # Process geolocation if provided
        if input.geo_location:
            detection.geo_location = GeoLocation(**input.geo_location)
        
        # Auto-categorize detection
        detection.category = auto_categorize_detection(detection)
        
        # Generate smart tags
        detection.tags = generate_tags(detection)
        
        # Check for alerts
        alerts = await db.alerts.find({"enabled": True}, {"_id": 0}).to_list(1000)
        for alert_data in alerts:
            alert = Alert(**alert_data)
            for obj in detection.objects_detected:
                if alert.object_name.lower() in obj.label.lower():
                    detection.alerts_triggered.append(alert.object_name)
        
        # Save to database
        doc = detection.model_dump()
        doc['timestamp'] = doc['timestamp'].isoformat()
        if doc.get('geo_location') and doc['geo_location'].get('timestamp'):
            doc['geo_location']['timestamp'] = doc['geo_location']['timestamp'].isoformat()
        await db.detections.insert_one(doc)
        
        return detection
        
    except HTTPException:
        raise  # Re-raise HTTPException as-is (preserves status code)
    except Exception as e:
        logging.error(f"Error analyzing frame: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/detect/analyze-nutrition", response_model=Detection)
async def analyze_nutrition(input: DetectionCreate, request: Request):
    """Analyze food items and calculate nutritional information"""
    try:
        # Get authenticated user
        auth_header = request.headers.get("Authorization")
        user_id = get_current_user(auth_header)
        
        if not user_id:
            raise HTTPException(status_code=401, detail="Authentication required")
        
        detection = Detection(
            source=input.source,
            detection_type="nutrition",
            image_data=input.image_data,
            user_id=user_id
        )
        
        # Extract base64 image data
        image_data = input.image_data.split(',')[1] if ',' in input.image_data else input.image_data
        
        # PhD-Level Nutrition Analysis Prompt
        nutrition_prompt = """
üáßüá∑ RESPONDA EXCLUSIVAMENTE EM PORTUGU√äS BRASILEIRO üáßüá∑

Voc√™ √© um PhD em Nutri√ß√£o com especializa√ß√£o em Nutri√ß√£o Cl√≠nica, Bioqu√≠mica Nutricional e Diet√©tica Aplicada. 
Possui 20 anos de experi√™ncia em an√°lise nutricional, avalia√ß√£o de adequa√ß√£o alimentar e prescri√ß√£o diet√©tica.

IMPORTANTE: TODA A RESPOSTA DEVE SER EM PORTUGU√äS DO BRASIL!

AN√ÅLISE ULTRA-DETALHADA DE COMPOSI√á√ÉO NUTRICIONAL:

Como especialista PhD, realize uma an√°lise COMPLETA e CIENT√çFICA desta refei√ß√£o, incluindo:

1. **IDENTIFICA√á√ÉO PRECISA DOS ALIMENTOS**:
   - Nome cient√≠fico quando aplic√°vel
   - M√©todo de preparo (cru, cozido, frito, grelhado, assado)
   - Presen√ßa de temperos e condimentos vis√≠veis
   - Estado de coc√ß√£o e processamento

2. **AN√ÅLISE QUANTITATIVA PRECISA**:
   - Peso estimado em gramas com margem de erro
   - Densidade cal√≥rica por 100g
   - Volume aparente e convers√£o peso-volume

3. **PERFIL NUTRICIONAL COMPLETO** (por alimento):
   - Macronutrientes: Prote√≠nas (g), Carboidratos (g), Gorduras totais (g), Fibras (g)
   - Gorduras: Saturadas, Monoinsaturadas, Poliinsaturadas, Trans
   - Carboidratos: Simples, Complexos, √çndice Glic√™mico estimado
   - Micronutrientes principais: Vitaminas (A, C, D, E, K, B-complex) e Minerais (Ca, Fe, Mg, Zn, K, Na)
   
4. **AVALIA√á√ÉO NUTRICIONAL PROFISSIONAL**:
   - Adequa√ß√£o em rela√ß√£o √†s DRIs brasileiras
   - Qualidade nutricional da refei√ß√£o (score 0-100)
   - Densidade nutricional vs densidade cal√≥rica
   - Equil√≠brio de macronutrientes (% prote√≠na, % carboidrato, % gordura)

5. **√çNDICES NUTRICIONAIS**:
   - √çndice Glic√™mico estimado da refei√ß√£o
   - Carga Glic√™mica total
   - Rela√ß√£o √îmega-6/√îmega-3 (quando aplic√°vel)
   - √çndice de Qualidade Nutricional (IQN)

6. **RECOMENDA√á√ïES CIENT√çFICAS**:
   - Pontos positivos nutricionais
   - √Åreas de melhoria
   - Sugest√µes de complementa√ß√£o
   - Alertas para grupos espec√≠ficos (diab√©ticos, hipertensos, etc)
   - Poss√≠veis defici√™ncias nutricionais

7. **CONTEXTO DIET√âTICO**:
   - Adequa√ß√£o para diferentes perfis (atletas, sedent√°rios, idosos)
   - Compatibilidade com dietas especiais (vegetariana, low-carb, mediterr√¢nea)
   - Momento ideal de consumo (caf√© da manh√£, pr√©-treino, p√≥s-treino, etc)

RETORNE JSON ESTRUTURADO PhD-LEVEL COMPLETO:
{
  "description": "descri√ß√£o cient√≠fica completa e detalhada da refei√ß√£o",
  "nutritional_analysis": {
    "foods_detected": [
      {
        "name": "nome do alimento",
        "scientific_name": "nome cient√≠fico quando aplic√°vel",
        "preparation_method": "m√©todo de preparo",
        "calories_per_100g": 0.0,
        "estimated_portion_grams": 0.0,
        "total_calories": 0.0,
        "macronutrients": {
          "protein": 0.0,
          "carbohydrates": 0.0,
          "fat": 0.0,
          "fiber": 0.0
        },
        "detailed_fats": {
          "saturated": 0.0,
          "monounsaturated": 0.0,
          "polyunsaturated": 0.0,
          "trans": 0.0
        },
        "carb_types": {
          "simple": 0.0,
          "complex": 0.0
        },
        "glycemic_index": 55,
        "micronutrients": {
          "vitamin_a": 0.0,
          "vitamin_c": 0.0,
          "vitamin_d": 0.0,
          "calcium": 0.0,
          "iron": 0.0,
          "magnesium": 0.0,
          "potassium": 0.0,
          "sodium": 0.0
        },
        "confidence": 0.9
      }
    ],
    "total_calories": 0.0,
    "total_weight_grams": 0.0,
    "meal_type": "caf√© da manh√£/almo√ßo/jantar/lanche/pr√©-treino/p√≥s-treino",
    "nutritional_summary": {
      "total_protein": 0.0,
      "total_carbs": 0.0,
      "total_fat": 0.0,
      "total_fiber": 0.0,
      "total_saturated_fat": 0.0,
      "total_sodium": 0.0
    },
    "quality_score": 75,
    "nutritional_balance": {
      "protein_percent": 20.0,
      "carbs_percent": 50.0,
      "fat_percent": 30.0
    },
    "glycemic_load": 15.5,
    "nutritional_quality_index": 7.8,
    "health_recommendations": [
      "Recomenda√ß√£o 1",
      "Recomenda√ß√£o 2",
      "Recomenda√ß√£o 3"
    ],
    "positive_aspects": [
      "Aspecto positivo 1",
      "Aspecto positivo 2"
    ],
    "improvement_areas": [
      "√Årea de melhoria 1",
      "√Årea de melhoria 2"
    ],
    "health_alerts": [
      "Alerta de sa√∫de se aplic√°vel"
    ],
    "dietary_compatibility": {
      "vegetarian": true/false,
      "vegan": true/false,
      "low_carb": true/false,
      "keto": true/false,
      "mediterranean": true/false,
      "gluten_free": true/false,
      "lactose_free": true/false,
      "diabetic_friendly": true/false
    },
    "ideal_consumption_time": "descri√ß√£o do melhor momento",
    "dri_adequacy": {
      "protein": 35.5,
      "fiber": 20.0,
      "vitamin_c": 45.0,
      "calcium": 15.0,
      "iron": 25.0
    }
  }
}

IMPORTANTE - DIRETRIZES PhD:
- üáßüá∑ RESPONDA TUDO EM PORTUGU√äS BRASILEIRO - OBRIGAT√ìRIO!
- Use SEMPRE valores baseados em TACO (Tabela Brasileira de Composi√ß√£o de Alimentos)
- Considere m√©todo de preparo e impacto nutricional
- Seja PRECISO e CIENT√çFICO nas recomenda√ß√µes
- Identifique riscos nutricionais para grupos vulner√°veis
- Compare com DRIs brasileiras (RDC 269/2005)
- Calcule √≠ndices glic√™micos baseados em literatura cient√≠fica
- Se n√£o houver alimentos, retorne arrays/listas vazios
- TODAS as descri√ß√µes, recomenda√ß√µes e textos devem estar em PORTUGU√äS!

üáßüá∑ LEMBRE-SE: RESPOSTA 100% EM PORTUGU√äS DO BRASIL! üáßüá∑
"""
        
        # Process via Gemini 2.0 Flash with retry logic
        max_retries = 3
        retry_delay = 2
        response = None
        last_error = None
        
        for attempt in range(max_retries):
            try:
                chat = LlmChat(
                    api_key=GOOGLE_API_KEY,
                    session_id=f"nutrition_analysis_{uuid.uuid4()}",
                    system_message="Voc√™ √© um especialista PhD em nutri√ß√£o e an√°lise de alimentos brasileiro. RESPONDA SEMPRE EM PORTUGU√äS BRASILEIRO. Use a Tabela Brasileira de Composi√ß√£o de Alimentos (TACO) e as DRIs brasileiras (RDC 269/2005)."
                ).with_model("gemini", "gemini-2.0-flash")
                
                response = await chat.send_message(
                    UserMessage(
                        text=nutrition_prompt,
                        file_contents=[ImageContent(image_base64=image_data)]
                    )
                )
                
                # If we got here, request succeeded
                break
                
            except Exception as e:
                last_error = e
                error_msg = str(e).lower()
                
                # Check if it's a retryable error (503, overloaded, rate limit)
                if '503' in error_msg or 'overloaded' in error_msg or 'rate' in error_msg:
                    if attempt < max_retries - 1:
                        logging.warning(f"Gemini API overloaded, retrying in {retry_delay}s... (attempt {attempt + 1}/{max_retries})")
                        import asyncio
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2  # Exponential backoff
                        continue
                    else:
                        logging.error("Max retries reached for nutrition analysis")
                        raise HTTPException(
                            status_code=503, 
                            detail="O servi√ßo de IA est√° temporariamente sobrecarregado. Por favor, tente novamente em alguns instantes."
                        )
                else:
                    # Non-retryable error, raise immediately
                    raise
        
        if response is None:
            raise last_error or Exception("Failed to get response from Gemini")
        
        # Parse response
        try:
            # Try to find JSON in response
            response_text = response.strip()
            if '```json' in response_text:
                response_text = response_text.split('```json')[1].split('```')[0].strip()
            elif '```' in response_text:
                response_text = response_text.split('```')[1].split('```')[0].strip()
            
            result = json.loads(response_text)
            detection.description = result.get('description', response_text)
            
            # Process nutritional analysis
            if 'nutritional_analysis' in result:
                nutrition_data = result['nutritional_analysis']
                detection.nutritional_analysis = NutritionalAnalysis(**nutrition_data)
                
        except json.JSONDecodeError as e:
            # If JSON parsing fails, use raw response
            logging.error(f"JSON parsing failed for nutrition analysis: {str(e)}")
            logging.error(f"Raw response: {response_text if 'response_text' in locals() else response}")
            detection.description = response_text if 'response_text' in locals() else str(response)
            detection.nutritional_analysis = NutritionalAnalysis()
        except Exception as e:
            logging.error(f"Error processing nutrition data: {str(e)}")
            detection.description = response_text if 'response_text' in locals() else str(response)
            detection.nutritional_analysis = NutritionalAnalysis()
        
        # Process geolocation if provided
        if input.geo_location:
            detection.geo_location = GeoLocation(**input.geo_location)
        
        # Auto-categorize detection
        detection.category = auto_categorize_detection(detection)
        
        # Generate smart tags
        detection.tags = generate_tags(detection)
        
        # Save to database
        doc = detection.model_dump()
        doc['timestamp'] = doc['timestamp'].isoformat()
        if doc.get('geo_location') and doc['geo_location'].get('timestamp'):
            doc['geo_location']['timestamp'] = doc['geo_location']['timestamp'].isoformat()
        await db.detections.insert_one(doc)
        
        return detection
        
    except HTTPException:
        raise  # Re-raise HTTPException as-is (preserves status code)
    except Exception as e:
        logging.error(f"Error analyzing nutrition: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/detect/read-text", response_model=Detection)
async def read_text_ocr(input: DetectionCreate, request: Request):
    """OCR especializado para leitura de textos - livros, quadros, documentos"""
    try:
        # Get authenticated user
        auth_header = request.headers.get("Authorization")
        user_id = get_current_user(auth_header)
        
        if not user_id:
            raise HTTPException(status_code=401, detail="Authentication required")
        
        detection = Detection(
            source=input.source,
            detection_type="text_reading",  # Novo tipo
            image_data=input.image_data,
            user_id=user_id
        )
        
        # Extract base64 image data
        image_data = input.image_data.split(',')[1] if ',' in input.image_data else input.image_data
        
        # OCR Ultra-Detailed Prompt
        ocr_prompt = """üáßüá∑ RESPONDA EXCLUSIVAMENTE EM PORTUGU√äS BRASILEIRO üáßüá∑

Voc√™ √© um especialista em OCR (Optical Character Recognition) e an√°lise de documentos para ACESSIBILIDADE.
Sua miss√£o √© extrair e descrever TODO O TEXTO vis√≠vel na imagem de forma EXTREMAMENTE DETALHADA.

IMPORTANTE: TODA A RESPOSTA DEVE SER EM PORTUGU√äS DO BRASIL!

**TIPOS DE CONTE√öDO QUE VOC√ä DEVE ANALISAR:**
1. üìñ P√°ginas de livros (cap√≠tulos, par√°grafos, notas de rodap√©)
2. üìù Quadros de aula (anota√ß√µes, diagramas, f√≥rmulas)
3. üìÑ Documentos (contratos, formul√°rios, cartas)
4. üì∞ Jornais e revistas
5. üè∑Ô∏è Placas, avisos e sinaliza√ß√µes
6. üí≥ Cart√µes, tickets e recibos
7. üì± Telas de dispositivos

**AN√ÅLISE COMPLETA E ESTRUTURADA:**

1. **TIPO DE DOCUMENTO/CONTE√öDO:**
   - Identifique o que √© (livro, quadro, placa, etc.)
   - Idioma do texto
   - Estado de conserva√ß√£o
   - Qualidade da imagem

2. **ESTRUTURA DO DOCUMENTO:**
   - T√≠tulo principal (se houver)
   - Subt√≠tulos e se√ß√µes
   - Hierarquia da informa√ß√£o
   - Layout e organiza√ß√£o visual

3. **EXTRA√á√ÉO COMPLETA DO TEXTO:**
   - Transcreva TODO o texto vis√≠vel, palavra por palavra
   - Preserve quebras de linha e par√°grafos
   - Mantenha a ordem de leitura natural
   - Indique formata√ß√£o especial (negrito, it√°lico, sublinhado)
   - Transcreva n√∫meros, f√≥rmulas matem√°ticas, s√≠mbolos

4. **ELEMENTOS VISUAIS:**
   - Diagramas, gr√°ficos, tabelas (descreva estrutura e conte√∫do)
   - Imagens ou ilustra√ß√µes (descreva brevemente)
   - Linhas, setas, destaque visual
   - Cores usadas para destacar informa√ß√£o

5. **ANOTA√á√ïES E MARCA√á√ïES:**
   - Texto manuscrito ou anota√ß√µes √† m√£o
   - Sublinhados, marca√ß√µes, post-its
   - Corre√ß√µes ou rasuras

6. **CONTEXTO ADICIONAL:**
   - N√∫mero de p√°gina (se vis√≠vel)
   - Data ou refer√™ncias temporais
   - Autor ou fonte (se identific√°vel)
   - Qualquer informa√ß√£o contextual relevante

7. **LEGIBILIDADE E QUALIDADE:**
   - Partes do texto ileg√≠veis ou borradas
   - Dificuldades de leitura
   - Sugest√µes para melhor captura

Forne√ßa uma resposta JSON COMPLETA em portugu√™s com esta estrutura:
{
  "document_type": "tipo do documento (livro, quadro, placa, etc.)",
  "language": "idioma do texto",
  "title": "t√≠tulo principal se houver",
  "full_text": "TEXTO COMPLETO extra√≠do preservando formata√ß√£o e ordem",
  "structured_content": {
    "sections": [
      {
        "heading": "t√≠tulo da se√ß√£o",
        "content": "conte√∫do da se√ß√£o",
        "subsections": []
      }
    ],
    "lists": [
      {
        "type": "ordered/unordered",
        "items": ["item 1", "item 2"]
      }
    ],
    "tables": [
      {
        "description": "descri√ß√£o da tabela",
        "rows": 5,
        "columns": 3,
        "content": "conte√∫do textual da tabela"
      }
    ],
    "formulas": [
      {
        "formula": "f√≥rmula matem√°tica",
        "description": "explica√ß√£o da f√≥rmula"
      }
    ]
  },
  "visual_elements": [
    {
      "type": "diagram/image/chart",
      "description": "descri√ß√£o detalhada",
      "position": "localiza√ß√£o na p√°gina"
    }
  ],
  "handwritten_notes": [
    "anota√ß√£o manuscrita 1",
    "anota√ß√£o manuscrita 2"
  ],
  "metadata": {
    "page_number": "n√∫mero da p√°gina se vis√≠vel",
    "author": "autor se identific√°vel",
    "date": "data se presente",
    "quality": "excelente/boa/regular/ruim"
  },
  "accessibility_notes": "informa√ß√µes adicionais para pessoas com defici√™ncia visual",
  "reading_order": "ordem recomendada de leitura do conte√∫do",
  "description": "DESCRI√á√ÉO NARRATIVA COMPLETA: Um resumo de TUDO que foi lido, como se estivesse narrando para uma pessoa cega, incluindo TODO o texto, estrutura, elementos visuais e contexto"
}

**DIRETRIZES CR√çTICAS:**
- üáßüá∑ TODA A RESPOSTA DEVE SER EM PORTUGU√äS BRASILEIRO
- Transcreva TUDO que conseguir ler, n√£o omita nada
- Se uma palavra estiver ileg√≠vel, indique: [palavra ileg√≠vel]
- Se faltar uma se√ß√£o, indique: [conte√∫do n√£o vis√≠vel]
- Seja EXTREMAMENTE detalhado na descri√ß√£o narrativa
- Pense em acessibilidade: uma pessoa cega precisa entender TUDO
- Preserve a estrutura e hierarquia do texto original

üáßüá∑ LEMBRE-SE: RESPOSTA 100% EM PORTUGU√äS DO BRASIL! üáßüá∑"""
        
        # Process via Gemini 2.0 Flash with retry logic
        max_retries = 3
        retry_delay = 2
        response = None
        last_error = None
        
        for attempt in range(max_retries):
            try:
                chat = LlmChat(
                    api_key=GOOGLE_API_KEY,
                    session_id=f"ocr_analysis_{uuid.uuid4()}",
                    system_message="Voc√™ √© um especialista em OCR e an√°lise de documentos para acessibilidade. RESPONDA SEMPRE EM PORTUGU√äS BRASILEIRO. Extraia e descreva TODO o texto vis√≠vel nas imagens com m√°ximo detalhamento."
                ).with_model("gemini", "gemini-2.0-flash")
                
                response = await chat.send_message(
                    UserMessage(
                        text=ocr_prompt,
                        file_contents=[ImageContent(image_base64=image_data)]
                    )
                )
                
                # If we got here, request succeeded
                break
                
            except Exception as e:
                last_error = e
                error_msg = str(e).lower()
                
                # Check if it's a retryable error
                if '503' in error_msg or 'overloaded' in error_msg or 'rate' in error_msg:
                    if attempt < max_retries - 1:
                        logging.warning(f"Gemini API overloaded, retrying in {retry_delay}s... (attempt {attempt + 1}/{max_retries})")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2
                        continue
                    else:
                        raise HTTPException(
                            status_code=503,
                            detail="O servi√ßo de IA est√° temporariamente sobrecarregado. Por favor, tente novamente em alguns instantes."
                        )
                else:
                    raise
        
        if response is None:
            raise last_error or Exception("Failed to get response from Gemini")
        
        # Parse response
        try:
            response_text = response.strip()
            if '```json' in response_text:
                response_text = response_text.split('```json')[1].split('```')[0].strip()
            elif '```' in response_text:
                response_text = response_text.split('```')[1].split('```')[0].strip()
            
            result = json.loads(response_text)
            
            # Store the full OCR result in description
            detection.description = result.get('description', '')
            
            # Store full text and structured content in objects_detected for easier access
            if result.get('full_text'):
                detection.objects_detected = [
                    DetectedObject(
                        label="Texto Completo",
                        confidence=0.95,
                        description=result.get('full_text', '')
                    )
                ]
            
        except json.JSONDecodeError as e:
            logging.error(f"JSON parsing failed for OCR: {str(e)}")
            # Use raw response as description
            detection.description = response_text if 'response_text' in locals() else str(response)
        except Exception as e:
            logging.error(f"Error processing OCR data: {str(e)}")
            detection.description = response_text if 'response_text' in locals() else str(response)
        
        # Process geolocation if provided
        if input.geo_location:
            detection.geo_location = GeoLocation(**input.geo_location)
        
        # Auto-categorize detection
        detection.category = auto_categorize_detection(detection)
        
        # Generate smart tags
        detection.tags = generate_tags(detection)
        
        # Save to database
        doc = detection.model_dump()
        doc['timestamp'] = doc['timestamp'].isoformat()
        if doc.get('geo_location') and doc['geo_location'].get('timestamp'):
            doc['geo_location']['timestamp'] = doc['geo_location']['timestamp'].isoformat()
        await db.detections.insert_one(doc)
        
        return detection
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"Error in OCR text reading: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# Authentication endpoints
@api_router.post("/auth/register")
async def register_user(user_data: UserRegister):
    """Register a new user"""
    try:
        # Check if user already exists
        existing_user = await db.users.find_one({"email": user_data.email})
        if existing_user:
            raise HTTPException(status_code=400, detail="Email already registered")
        
        # Hash password
        password_hash = get_password_hash(user_data.password)
        
        # Determine user type - HARDCODED ADMIN
        # Only aruanasistema@gmail.com gets admin privileges
        user_type = "admin" if user_data.email.lower() == "aruanasistema@gmail.com" else "user"
        
        # Create user
        user = User(
            name=user_data.name,
            email=user_data.email,
            password_hash=password_hash,
            user_type=user_type
        )
        
        # Save to database
        user_dict = user.model_dump()
        user_dict['created_at'] = user_dict['created_at'].isoformat()
        if user_dict.get('last_login'):
            user_dict['last_login'] = user_dict['last_login'].isoformat()
            
        await db.users.insert_one(user_dict)
        
        return {"success": True, "message": "User created successfully"}
        
    except HTTPException:
        raise  # Re-raise HTTPException as-is (preserves status code)
    except Exception as e:
        logging.error(f"Registration error: {str(e)}")
        raise HTTPException(status_code=500, detail="Registration failed")

@api_router.post("/auth/login")
async def login_user(credentials: UserLogin):
    """Login user and return JWT token"""
    try:
        # Find user
        user = await db.users.find_one({"email": credentials.email})
        if not user:
            raise HTTPException(status_code=401, detail="Invalid email or password")
        
        # Verify password
        if not verify_password(credentials.password, user["password_hash"]):
            raise HTTPException(status_code=401, detail="Invalid email or password")
        
        # Check if user is active
        if not user.get("is_active", True):
            raise HTTPException(status_code=401, detail="Account is disabled")
        
        # Update last login
        await db.users.update_one(
            {"id": user["id"]},
            {"$set": {"last_login": datetime.now(timezone.utc).isoformat()}}
        )
        
        # Create access token
        access_token = create_access_token(
            data={"sub": user["id"], "email": user["email"], "user_type": user["user_type"]}
        )
        
        return {
            "success": True,
            "access_token": access_token,
            "token_type": "bearer",
            "user": {
                "id": user["id"],
                "name": user["name"],
                "email": user["email"],
                "user_type": user["user_type"]
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"Login error: {str(e)}")
        raise HTTPException(status_code=500, detail="Login failed")

@api_router.get("/auth/me")
async def get_current_user_info(request: Request):
    """Get current user information"""
    auth_header = request.headers.get("Authorization")
    user_id = get_current_user(auth_header)
    
    if not user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    user = await db.users.find_one({"id": user_id}, {"_id": 0, "password_hash": 0, "reset_token": 0, "reset_token_expiry": 0})
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    return user

@api_router.put("/auth/profile")
async def update_profile(request: Request, profile_data: UserProfileUpdate):
    """Update user profile"""
    auth_header = request.headers.get("Authorization")
    user_id = get_current_user(auth_header)
    
    if not user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    # Build update document
    update_doc = {}
    if profile_data.name:
        update_doc["name"] = profile_data.name
    if profile_data.bio is not None:
        update_doc["bio"] = profile_data.bio
    if profile_data.phone is not None:
        update_doc["phone"] = profile_data.phone
    if profile_data.birth_date is not None:
        update_doc["birth_date"] = profile_data.birth_date
    if profile_data.profile_photo is not None:
        update_doc["profile_photo"] = profile_data.profile_photo
    
    if not update_doc:
        raise HTTPException(status_code=400, detail="No fields to update")
    
    # Update user
    result = await db.users.update_one(
        {"id": user_id},
        {"$set": update_doc}
    )
    
    if result.modified_count == 0:
        raise HTTPException(status_code=404, detail="User not found")
    
    # Return updated user
    updated_user = await db.users.find_one({"id": user_id}, {"_id": 0, "password_hash": 0, "reset_token": 0, "reset_token_expiry": 0})
    return {"success": True, "user": updated_user}

@api_router.post("/auth/forgot-password")
async def forgot_password(request_data: PasswordResetRequest):
    """Request password reset - generates token"""
    try:
        user = await db.users.find_one({"email": request_data.email})
        
        if not user:
            # Don't reveal if email exists for security
            return {"success": True, "message": "If email exists, reset instructions have been sent"}
        
        # Generate reset token
        reset_token = secrets.token_urlsafe(32)
        reset_expiry = datetime.now(timezone.utc) + timedelta(hours=1)  # 1 hour expiry
        
        # Save token to user
        await db.users.update_one(
            {"email": request_data.email},
            {"$set": {
                "reset_token": reset_token,
                "reset_token_expiry": reset_expiry.isoformat()
            }}
        )
        
        # In production, send email with token
        # For now, return token in response (ONLY FOR DEVELOPMENT)
        logging.info(f"Password reset token for {request_data.email}: {reset_token}")
        
        return {
            "success": True, 
            "message": "If email exists, reset instructions have been sent",
            "token": reset_token  # REMOVE IN PRODUCTION - should be sent via email
        }
        
    except Exception as e:
        logging.error(f"Forgot password error: {str(e)}")
        raise HTTPException(status_code=500, detail="Failed to process request")

@api_router.post("/auth/reset-password")
async def reset_password(reset_data: PasswordReset):
    """Reset password with token"""
    try:
        # Find user with valid token
        user = await db.users.find_one({
            "reset_token": reset_data.token
        })
        
        if not user:
            raise HTTPException(status_code=400, detail="Invalid or expired token")
        
        # Check if token expired
        if user.get("reset_token_expiry"):
            expiry = datetime.fromisoformat(user["reset_token_expiry"])
            if expiry < datetime.now(timezone.utc):
                raise HTTPException(status_code=400, detail="Token has expired")
        
        # Hash new password
        new_password_hash = pwd_context.hash(reset_data.new_password)
        
        # Update password and clear token
        await db.users.update_one(
            {"id": user["id"]},
            {"$set": {
                "password_hash": new_password_hash,
                "reset_token": None,
                "reset_token_expiry": None
            }}
        )
        
        return {"success": True, "message": "Password reset successfully"}
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"Reset password error: {str(e)}")
        raise HTTPException(status_code=500, detail="Failed to reset password")

# ==================== ADMIN ENDPOINTS ====================

@api_router.get("/admin/users")
async def get_all_users(request: Request):
    """Admin: Get all users"""
    auth_header = request.headers.get("Authorization")
    user_id = get_current_user(auth_header)
    
    if not user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    # Check if user is admin
    current_user = await db.users.find_one({"id": user_id})
    if not current_user or current_user.get("user_type") != "admin":
        raise HTTPException(status_code=403, detail="Admin access required")
    
    # Get all users
    users = await db.users.find(
        {},
        {"_id": 0, "password_hash": 0, "reset_token": 0, "reset_token_expiry": 0}
    ).to_list(1000)
    
    return users

@api_router.put("/admin/users/{user_id}")
async def update_user(request: Request, user_id: str, update_data: dict):
    """Admin: Update any user"""
    auth_header = request.headers.get("Authorization")
    current_user_id = get_current_user(auth_header)
    
    if not current_user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    # Check if user is admin
    current_user = await db.users.find_one({"id": current_user_id})
    if not current_user or current_user.get("user_type") != "admin":
        raise HTTPException(status_code=403, detail="Admin access required")
    
    # Remove sensitive fields from update
    update_data.pop('password_hash', None)
    update_data.pop('id', None)
    
    # Update user
    result = await db.users.update_one(
        {"id": user_id},
        {"$set": update_data}
    )
    
    if result.modified_count == 0:
        raise HTTPException(status_code=404, detail="User not found")
    
    return {"success": True, "message": "User updated"}

@api_router.delete("/admin/users/{user_id}")
async def delete_user(request: Request, user_id: str):
    """Admin: Delete user"""
    auth_header = request.headers.get("Authorization")
    current_user_id = get_current_user(auth_header)
    
    if not current_user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    # Check if user is admin
    current_user = await db.users.find_one({"id": current_user_id})
    if not current_user or current_user.get("user_type") != "admin":
        raise HTTPException(status_code=403, detail="Admin access required")
    
    # Prevent deleting self
    if user_id == current_user_id:
        raise HTTPException(status_code=400, detail="Cannot delete yourself")
    
    # Delete user
    result = await db.users.delete_one({"id": user_id})
    
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="User not found")
    
    return {"success": True, "message": "User deleted"}

@api_router.get("/admin/stats")
async def get_admin_stats(request: Request):
    """Admin: Get system statistics"""
    auth_header = request.headers.get("Authorization")
    user_id = get_current_user(auth_header)
    
    if not user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    # Check if user is admin
    current_user = await db.users.find_one({"id": user_id})
    if not current_user or current_user.get("user_type") != "admin":
        raise HTTPException(status_code=403, detail="Admin access required")
    
    # Get statistics
    total_users = await db.users.count_documents({})
    total_detections = await db.detections.count_documents({})
    total_alerts = await db.alerts.count_documents({})
    
    return {
        "total_users": total_users,
        "total_detections": total_detections,
        "total_alerts": total_alerts
    }

@api_router.get("/detections", response_model=List[Detection])
async def get_detections(
    request: Request,
    limit: int = Query(50, ge=1, le=100),
    skip: int = Query(0, ge=0)
):
    """Get detection history - filtered by user unless admin"""
    auth_header = request.headers.get("Authorization")
    user_id = get_current_user(auth_header)
    
    if not user_id:
        raise HTTPException(status_code=401, detail="Authentication required")
    
    # Get user to check if admin
    user = await db.users.find_one({"id": user_id})
    if not user:
        raise HTTPException(status_code=401, detail="User not found")
    
    # Filter detections by user unless admin
    filter_query = {}
    if user.get("user_type") != "admin":
        filter_query["user_id"] = user_id
    
    detections = await db.detections.find(
        filter_query, {"_id": 0}
    ).sort("timestamp", -1).skip(skip).limit(limit).to_list(limit)
    
    for det in detections:
        if isinstance(det['timestamp'], str):
            det['timestamp'] = datetime.fromisoformat(det['timestamp'])
    
    return detections

@api_router.delete("/detections/{detection_id}")
async def delete_detection(detection_id: str):
    """Delete a detection"""
    result = await db.detections.delete_one({"id": detection_id})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Detection not found")
    return {"message": "Detection deleted"}

@api_router.post("/alerts", response_model=Alert)
async def create_alert(input: AlertCreate):
    """Create a new alert"""
    alert = Alert(**input.model_dump())
    doc = alert.model_dump()
    doc['created_at'] = doc['created_at'].isoformat()
    await db.alerts.insert_one(doc)
    return alert

@api_router.get("/alerts", response_model=List[Alert])
async def get_alerts():
    """Get all alerts"""
    alerts = await db.alerts.find({}, {"_id": 0}).to_list(1000)
    for alert in alerts:
        if isinstance(alert['created_at'], str):
            alert['created_at'] = datetime.fromisoformat(alert['created_at'])
    return alerts

@api_router.delete("/alerts/{alert_id}")
async def delete_alert(alert_id: str):
    """Delete an alert"""
    result = await db.alerts.delete_one({"id": alert_id})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Alert not found")
    return {"message": "Alert deleted"}

@api_router.patch("/alerts/{alert_id}")
async def toggle_alert(alert_id: str, enabled: bool):
    """Toggle alert enabled status"""
    result = await db.alerts.update_one(
        {"id": alert_id},
        {"$set": {"enabled": enabled}}
    )
    if result.matched_count == 0:
        raise HTTPException(status_code=404, detail="Alert not found")
    return {"message": "Alert updated"}

@api_router.get("/reports/export")
async def export_report(format: str = Query("json", regex="^(json|csv)$")):
    """Export detections report"""
    detections = await db.detections.find({}, {"_id": 0}).sort("timestamp", -1).to_list(1000)
    
    if format == "json":
        return detections
    else:  # csv
        output = io.StringIO()
        if detections:
            fieldnames = ['id', 'timestamp', 'source', 'detection_type', 'description']
            writer = csv.DictWriter(output, fieldnames=fieldnames)
            writer.writeheader()
            for det in detections:
                writer.writerow({
                    'id': det.get('id', ''),
                    'timestamp': det.get('timestamp', ''),
                    'source': det.get('source', ''),
                    'detection_type': det.get('detection_type', ''),
                    'description': det.get('description', '')
                })
        
        output.seek(0)
        return StreamingResponse(
            iter([output.getvalue()]),
            media_type="text/csv",
            headers={"Content-Disposition": "attachment; filename=detections_report.csv"}
        )

# Scientific Records Routes
@api_router.post("/scientific-records", response_model=ScientificRecord)
async def create_scientific_record(input: ScientificRecordCreate):
    """Criar novo registro cient√≠fico"""
    record = ScientificRecord(**input.model_dump())
    doc = record.model_dump()
    doc['created_at'] = doc['created_at'].isoformat()
    await db.scientific_records.insert_one(doc)
    return record

@api_router.get("/scientific-records", response_model=List[ScientificRecord])
async def get_scientific_records(
    record_type: Optional[str] = None,
    research_line: Optional[str] = None,
    limit: int = Query(100, ge=1, le=500)
):
    """Listar registros cient√≠ficos"""
    query = {}
    if record_type:
        query["record_type"] = record_type
    if research_line:
        query["research_line"] = research_line
    
    records = await db.scientific_records.find(query, {"_id": 0}).sort("created_at", -1).limit(limit).to_list(limit)
    
    for rec in records:
        if isinstance(rec['created_at'], str):
            rec['created_at'] = datetime.fromisoformat(rec['created_at'])
    
    return records

@api_router.delete("/scientific-records/{record_id}")
async def delete_scientific_record(record_id: str):
    """Deletar registro cient√≠fico"""
    result = await db.scientific_records.delete_one({"id": record_id})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Record not found")
    return {"message": "Record deleted"}

# Intelligent Reports
@api_router.post("/analyze/sentiment-deep")
async def analyze_sentiment_deep(input: DetectionCreate):
    """An√°lise profunda de sentimentos usando t√©cnica avan√ßada de IA"""
    try:
        # Decode base64 image
        image_data = input.image_data.split(',')[1] if ',' in input.image_data else input.image_data
        
        # Use Gemini Vision with advanced sentiment analysis technique
        chat = LlmChat(
            api_key=GOOGLE_API_KEY,
            session_id=f"sentiment_analysis_{uuid.uuid4()}",
            system_message="""Voc√™ √© um especialista em an√°lise de sentimentos e psicologia comportamental. 
            Use a t√©cnica de 'An√°lise Multimodal de Sentimentos' que combina:
            1. Detec√ß√£o de microexpress√µes faciais (FACS - Facial Action Coding System)
            2. An√°lise de linguagem corporal e postura
            3. Contexto ambiental e situacional
            4. Teoria das emo√ß√µes de Ekman (6 emo√ß√µes b√°sicas + varia√ß√µes)
            5. An√°lise de val√™ncia emocional (positivo/negativo) e arousal (ativa√ß√£o)"""
        ).with_model("gemini", "gemini-2.0-flash")
        
        image_content = ImageContent(image_base64=image_data)
        
        prompt = """Realize uma AN√ÅLISE PROFUNDA DE SENTIMENTOS desta imagem usando a t√©cnica de An√°lise Multimodal:

**M√âTODO CIENT√çFICO:**
1. **FACS (Facial Action Coding System)**: Identifique Action Units (AUs) nas express√µes faciais
2. **Teoria de Ekman**: Classifique emo√ß√µes b√°sicas (alegria, tristeza, raiva, medo, surpresa, nojo)
3. **Val√™ncia e Arousal**: Avalie dimens√µes emocionais (positivo/negativo, alta/baixa ativa√ß√£o)
4. **Linguagem Corporal**: Analise postura, gestos e posicionamento
5. **Contexto**: Considere ambiente, objetos e situa√ß√£o

**PARA CADA PESSOA DETECTADA:**
- **Microexpress√µes**: Detalhe movimentos faciais espec√≠ficos
- **Estado emocional prim√°rio**: Emo√ß√£o dominante
- **Estados secund√°rios**: Emo√ß√µes sutis presentes
- **Intensidade emocional**: Escala 1-10
- **Congru√™ncia**: Alinhamento entre face, corpo e contexto
- **Indicadores fisiol√≥gicos**: Tens√£o muscular, dilata√ß√£o pupilar (se vis√≠vel)
- **Interpreta√ß√£o psicol√≥gica**: O que a pessoa pode estar sentindo/pensando

**AN√ÅLISE DE GRUPO** (se m√∫ltiplas pessoas):
- **Din√¢mica emocional**: Como as emo√ß√µes interagem entre pessoas
- **Cont√°gio emocional**: Influ√™ncia m√∫tua de sentimentos
- **Clima emocional geral**: Atmosfera do grupo

Forne√ßa resposta em JSON em PORTUGU√äS com estrutura detalhada:
{
  "sentiment_analysis": {
    "methodology": "FACS + Ekman + An√°lise Multimodal",
    "people": [{
      "person_id": 1,
      "primary_emotion": "alegria",
      "emotion_intensity": 8.5,
      "secondary_emotions": ["satisfa√ß√£o", "tranquilidade"],
      "facial_action_units": ["AU6 (eleva√ß√£o da bochecha)", "AU12 (sorriso)"],
      "valence": "positivo",
      "arousal": "moderado",
      "body_language": "postura relaxada, bra√ßos abertos",
      "psychological_interpretation": "pessoa demonstra contentamento genu√≠no...",
      "confidence_score": 0.92
    }],
    "group_dynamics": {
      "overall_mood": "positivo e colaborativo",
      "emotional_contagion": "alta",
      "tension_level": "baixo"
    },
    "contextual_factors": ["ambiente bem iluminado", "presen√ßa de objetos positivos"],
    "detailed_description": "descri√ß√£o narrativa completa em portugu√™s"
  }
}"""
        
        user_message = UserMessage(
            text=prompt,
            file_contents=[image_content]
        )
        
        response = await chat.send_message(user_message)
        
        # Parse response
        try:
            response_text = response.strip()
            if '```json' in response_text:
                response_text = response_text.split('```json')[1].split('```')[0].strip()
            elif '```' in response_text:
                response_text = response_text.split('```')[1].split('```')[0].strip()
            
            result = json.loads(response_text)
            return result
        except:
            return {
                "sentiment_analysis": {
                    "methodology": "FACS + Ekman + An√°lise Multimodal",
                    "raw_analysis": response,
                    "status": "partial_parse"
                }
            }
        
    except Exception as e:
        logging.error(f"Error in deep sentiment analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/reports/intelligent")
async def generate_intelligent_report(query: ReportQuery):
    """Gerar relat√≥rio inteligente com an√°lises"""
    # Build query
    db_query = {}
    if query.start_date:
        db_query["timestamp"] = {"$gte": query.start_date}
    if query.end_date:
        if "timestamp" in db_query:
            db_query["timestamp"]["$lte"] = query.end_date
        else:
            db_query["timestamp"] = {"$lte": query.end_date}
    
    detections = await db.detections.find(db_query, {"_id": 0}).to_list(1000)
    
    # Analyze data
    total_detections = len(detections)
    webcam_count = sum(1 for d in detections if d.get('source') == 'webcam')
    upload_count = sum(1 for d in detections if d.get('source') == 'upload')
    
    # Emotion analysis
    emotions_data = {
        "sorrindo": 0,
        "serio": 0,
        "triste": 0,
        "surpreso": 0,
        "zangado": 0,
        "neutro": 0
    }
    
    sentiment_data = {
        "positivo": 0,
        "neutro": 0,
        "negativo": 0
    }
    
    objects_count = {}
    
    for detection in detections:
        # Count objects
        for obj in detection.get('objects_detected', []):
            label = obj.get('label', 'unknown')
            objects_count[label] = objects_count.get(label, 0) + 1
            
        # Extract emotions from detection-level analysis
        if 'emotion_analysis' in detection and detection['emotion_analysis']:
            emotion_data = detection['emotion_analysis']
            for emotion, count in emotion_data.items():
                if emotion in emotions_data and isinstance(count, int):
                    emotions_data[emotion] += count
                    
        # Extract sentiment from detection-level analysis  
        if 'sentiment_analysis' in detection and detection['sentiment_analysis']:
            sentiment_analysis = detection['sentiment_analysis']
            for sentiment, count in sentiment_analysis.items():
                if sentiment in sentiment_data and isinstance(count, int):
                    sentiment_data[sentiment] += count
    
    # Scientific records stats
    scientific_records = await db.scientific_records.find({}, {"_id": 0}).to_list(1000)
    records_by_type = {}
    records_by_line = {}
    
    for rec in scientific_records:
        rec_type = rec.get('record_type', 'unknown')
        records_by_type[rec_type] = records_by_type.get(rec_type, 0) + 1
        
        line = rec.get('research_line', 'unknown')
        records_by_line[line] = records_by_line.get(line, 0) + 1
    
    return {
        "report_type": query.report_type,
        "period": {
            "start": query.start_date,
            "end": query.end_date
        },
        "detections_summary": {
            "total": total_detections,
            "by_source": {
                "webcam": webcam_count,
                "upload": upload_count
            }
        },
        "emotions_analysis": emotions_data,
        "sentiment_analysis": sentiment_data,
        "objects_detected": dict(sorted(objects_count.items(), key=lambda x: x[1], reverse=True)[:10]),
        "scientific_records": {
            "total": len(scientific_records),
            "by_type": records_by_type,
            "by_research_line": records_by_line
        },
        "insights": {
            "most_detected_object": max(objects_count.items(), key=lambda x: x[1])[0] if objects_count else "N/A",
            "dominant_emotion": max(emotions_data.items(), key=lambda x: x[1])[0] if any(emotions_data.values()) else "N/A",
            "overall_sentiment": max(sentiment_data.items(), key=lambda x: x[1])[0] if any(sentiment_data.values()) else "N/A"
        }
    }

# Social Network Routes
@api_router.post("/researchers", response_model=ResearcherProfile)
async def create_researcher_profile(input: ResearcherProfileCreate):
    """Criar perfil de pesquisador"""
    profile = ResearcherProfile(**input.model_dump())
    doc = profile.model_dump()
    doc['created_at'] = doc['created_at'].isoformat()
    await db.researchers.insert_one(doc)
    return profile

@api_router.get("/researchers", response_model=List[ResearcherProfile])
async def get_researchers(limit: int = Query(50, ge=1, le=100)):
    """Listar pesquisadores"""
    researchers = await db.researchers.find({}, {"_id": 0}).sort("created_at", -1).limit(limit).to_list(limit)
    for r in researchers:
        if isinstance(r['created_at'], str):
            r['created_at'] = datetime.fromisoformat(r['created_at'])
    return researchers

@api_router.get("/researchers/{researcher_id}", response_model=ResearcherProfile)
async def get_researcher(researcher_id: str):
    """Obter perfil de pesquisador"""
    researcher = await db.researchers.find_one({"id": researcher_id}, {"_id": 0})
    if not researcher:
        raise HTTPException(status_code=404, detail="Researcher not found")
    if isinstance(researcher['created_at'], str):
        researcher['created_at'] = datetime.fromisoformat(researcher['created_at'])
    return ResearcherProfile(**researcher)

@api_router.delete("/researchers/{researcher_id}")
async def delete_researcher(researcher_id: str):
    """Deletar pesquisador"""
    result = await db.researchers.delete_one({"id": researcher_id})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Researcher not found")
    return {"message": "Researcher deleted"}

@api_router.post("/posts", response_model=Post)
async def create_post(input: PostCreate):
    """Criar post"""
    post = Post(**input.model_dump())
    doc = post.model_dump()
    doc['created_at'] = doc['created_at'].isoformat()
    await db.posts.insert_one(doc)
    return post

@api_router.get("/posts", response_model=List[Post])
async def get_posts(limit: int = Query(50, ge=1, le=100)):
    """Listar posts"""
    posts = await db.posts.find({}, {"_id": 0}).sort("created_at", -1).limit(limit).to_list(limit)
    for p in posts:
        if isinstance(p['created_at'], str):
            p['created_at'] = datetime.fromisoformat(p['created_at'])
    return posts

@api_router.post("/posts/{post_id}/like")
async def like_post(post_id: str):
    """Curtir post"""
    result = await db.posts.update_one(
        {"id": post_id},
        {"$inc": {"likes": 1}}
    )
    if result.matched_count == 0:
        raise HTTPException(status_code=404, detail="Post not found")
    return {"message": "Post liked"}

@api_router.delete("/posts/{post_id}")
async def delete_post(post_id: str):
    """Deletar post"""
    result = await db.posts.delete_one({"id": post_id})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Post not found")
    # Delete associated comments
    await db.comments.delete_many({"post_id": post_id})
    return {"message": "Post deleted"}

@api_router.post("/comments", response_model=Comment)
async def create_comment(input: CommentCreate):
    """Criar coment√°rio"""
    comment = Comment(**input.model_dump())
    doc = comment.model_dump()
    doc['created_at'] = doc['created_at'].isoformat()
    await db.comments.insert_one(doc)
    
    # Increment comments count on post
    await db.posts.update_one(
        {"id": input.post_id},
        {"$inc": {"comments_count": 1}}
    )
    
    return comment

@api_router.get("/comments/{post_id}", response_model=List[Comment])
async def get_comments(post_id: str):
    """Listar coment√°rios de um post"""
    comments = await db.comments.find({"post_id": post_id}, {"_id": 0}).sort("created_at", 1).to_list(1000)
    for c in comments:
        if isinstance(c['created_at'], str):
            c['created_at'] = datetime.fromisoformat(c['created_at'])
    return comments

@api_router.delete("/comments/{comment_id}")
async def delete_comment(comment_id: str):
    """Deletar coment√°rio"""
    comment = await db.comments.find_one({"id": comment_id})
    if not comment:
        raise HTTPException(status_code=404, detail="Comment not found")
    
    await db.comments.delete_one({"id": comment_id})
    
    # Decrement comments count on post
    await db.posts.update_one(
        {"id": comment['post_id']},
        {"$inc": {"comments_count": -1}}
    )
    
    return {"message": "Comment deleted"}

# Include router
app.include_router(api_router)

app.add_middleware(
    CORSMiddleware,
    allow_credentials=True,
    allow_origins=os.environ.get('CORS_ORIGINS', '*').split(','),
    allow_methods=["*"],
    allow_headers=["*"],
)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@app.on_event("startup")
async def create_default_admin():
    """Create default admin user if not exists"""
    try:
        admin_email = "aruanasistema@gmail.com"
        admin_password = "Ricardo@2025"
        
        # Check if admin exists
        existing_admin = await db.users.find_one({"email": admin_email})
        
        if not existing_admin:
            # Create admin user
            password_hash = pwd_context.hash(admin_password)
            admin_user = {
                "id": str(uuid.uuid4()),
                "name": "Administrador ARUAN√É",
                "email": admin_email,
                "password_hash": password_hash,
                "user_type": "admin",
                "created_at": datetime.now(timezone.utc).isoformat(),
                "is_active": True
            }
            await db.users.insert_one(admin_user)
            logging.info(f"‚úÖ Default admin user created: {admin_email}")
        else:
            logging.info(f"‚úÖ Admin user already exists: {admin_email}")
            
    except Exception as e:
        logging.error(f"Error creating default admin: {str(e)}")

@app.on_event("shutdown")
async def shutdown_db_client():
    client.close()