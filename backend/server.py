from fastapi import FastAPI, APIRouter, UploadFile, File, HTTPException, Query, Request
from fastapi.responses import StreamingResponse
from dotenv import load_dotenv
from starlette.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
import os
import logging
from pathlib import Path
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Optional, Dict, Any
import uuid
from datetime import datetime, timezone
import base64
import hashlib
import secrets
import jwt
from passlib.context import CryptContext
from datetime import timedelta
from functools import wraps
from emergentintegrations.llm.chat import LlmChat, UserMessage, ImageContent
import io
import cv2
import numpy as np
from PIL import Image
import json
import csv
import asyncio

ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

# MongoDB connection
mongo_url = os.environ['MONGO_URL']
client = AsyncIOMotorClient(mongo_url)
db = client[os.environ['DB_NAME']]

# Create the main app
app = FastAPI()
api_router = APIRouter(prefix="/api")

# Google API Key
GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY', '')

# Feature Flags - Controle de recursos
ENABLE_AMBIENT_SOUND_INFERENCE = False  # Set to True to re-enable ambient sound classification in descriptions

# Authentication settings
SECRET_KEY = os.environ.get('JWT_SECRET_KEY', secrets.token_urlsafe(32))
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30 * 24 * 60  # 30 days

# Password hashing
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# Authentication utilities
def verify_password(plain_password, hashed_password):
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password):
    return pwd_context.hash(password)

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.now(timezone.utc) + expires_delta
    else:
        expire = datetime.now(timezone.utc) + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

def verify_token(token: str):
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: str = payload.get("sub")
        if user_id is None:
            return None
        return user_id
    except jwt.PyJWTError:
        return None

# Authentication middleware
def get_current_user(authorization: str = None):
    if not authorization or not authorization.startswith("Bearer "):
        return None
    
    token = authorization.split("Bearer ")[1]
    user_id = verify_token(token)
    return user_id

def require_auth(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # Get request from args/kwargs (FastAPI dependency injection handles this)
        request = kwargs.get('request') or (args[0] if args else None)
        
        if not request:
            raise HTTPException(status_code=401, detail="Authentication required")
        
        auth_header = request.headers.get("Authorization")
        user_id = get_current_user(auth_header)
        
        if not user_id:
            raise HTTPException(status_code=401, detail="Invalid authentication credentials")
        
        # Add user_id to kwargs
        kwargs['current_user_id'] = user_id
        return await func(*args, **kwargs)
    
    return wrapper

def require_admin(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        request = kwargs.get('request') or (args[0] if args else None)
        
        if not request:
            raise HTTPException(status_code=401, detail="Authentication required")
        
        auth_header = request.headers.get("Authorization")
        user_id = get_current_user(auth_header)
        
        if not user_id:
            raise HTTPException(status_code=401, detail="Invalid authentication credentials")
        
        # Check if user is admin
        user = await db.users.find_one({"id": user_id})
        if not user or user.get("user_type") != "admin":
            raise HTTPException(status_code=403, detail="Admin access required")
        
        kwargs['current_user_id'] = user_id
        return await func(*args, **kwargs)
    
    return wrapper
# Models
class EmotionAnalysis(BaseModel):
    sorrindo: int = 0
    serio: int = 0
    triste: int = 0
    surpreso: int = 0
    zangado: int = 0
    neutro: int = 0

class SentimentAnalysis(BaseModel):
    positivo: int = 0
    neutro: int = 0
    negativo: int = 0

class GeoLocation(BaseModel):
    latitude: Optional[float] = None
    longitude: Optional[float] = None
    accuracy: Optional[float] = None  # in meters
    address: Optional[str] = None  # formatted address
    city: Optional[str] = None
    state: Optional[str] = None
    country: Optional[str] = None
    timestamp: Optional[datetime] = None

class FoodItem(BaseModel):
    name: str
    scientific_name: Optional[str] = None
    preparation_method: Optional[str] = None
    calories_per_100g: float
    estimated_portion_grams: float
    total_calories: float
    macronutrients: Dict[str, float] = Field(default_factory=dict)  # protein, carbs, fat, fiber
    detailed_fats: Dict[str, float] = Field(default_factory=dict)  # saturated, monounsaturated, polyunsaturated, trans
    carb_types: Dict[str, float] = Field(default_factory=dict)  # simple, complex
    glycemic_index: Optional[int] = None
    micronutrients: Dict[str, float] = Field(default_factory=dict)  # vitamins and minerals
    confidence: float = 0.0

class NutritionalAnalysis(BaseModel):
    foods_detected: List[FoodItem] = []
    total_calories: float = 0.0
    total_weight_grams: float = 0.0
    meal_type: Optional[str] = None
    nutritional_summary: Dict[str, float] = Field(default_factory=dict)
    # PhD-level additions
    quality_score: Optional[int] = None  # 0-100
    nutritional_balance: Dict[str, float] = Field(default_factory=dict)  # % protein, % carbs, % fat
    glycemic_load: Optional[float] = None
    nutritional_quality_index: Optional[float] = None
    health_recommendations: List[str] = []
    positive_aspects: List[str] = []
    improvement_areas: List[str] = []
    health_alerts: List[str] = []
    dietary_compatibility: Dict[str, bool] = Field(default_factory=dict)  # vegetarian, low-carb, etc
    ideal_consumption_time: Optional[str] = None
    dri_adequacy: Dict[str, float] = Field(default_factory=dict)  # % of daily recommended intake

class User(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    name: str
    email: str
    password_hash: str
    user_type: str = "user"  # "user" or "admin"
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    last_login: Optional[datetime] = None
    is_active: bool = True
    # Profile fields
    profile_photo: Optional[str] = None  # base64 encoded image
    bio: Optional[str] = None
    phone: Optional[str] = None
    birth_date: Optional[str] = None
    reset_token: Optional[str] = None
    reset_token_expiry: Optional[datetime] = None

class UserLogin(BaseModel):
    email: str
    password: str

class UserRegister(BaseModel):
    name: str
    email: str
    password: str
    user_type: str = "user"

class UserProfileUpdate(BaseModel):
    name: Optional[str] = None
    bio: Optional[str] = None
    phone: Optional[str] = None
    birth_date: Optional[str] = None
    profile_photo: Optional[str] = None

class PasswordResetRequest(BaseModel):
    email: str

class PasswordReset(BaseModel):
    token: str
    new_password: str

class DetectedObject(BaseModel):
    label: str
    confidence: float
    bbox: Optional[List[float]] = None

class Detection(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    source: str  # "webcam" or "upload"
    detection_type: str  # "local", "cloud", "nutrition", "text_reading"
    objects_detected: List[DetectedObject] = []
    description: str = ""
    image_data: Optional[str] = None  # base64 encoded
    alerts_triggered: List[str] = []
    emotion_analysis: Optional[EmotionAnalysis] = None
    sentiment_analysis: Optional[SentimentAnalysis] = None
    nutritional_analysis: Optional[NutritionalAnalysis] = None
    user_id: Optional[str] = None  # ID of the user who created this detection
    # New fields for enhanced functionality
    geo_location: Optional[GeoLocation] = None  # Geographic location
    category: Optional[str] = None  # Auto-categorized: "pessoas", "objetos", "alimentos", "texto", "ambiente", etc
    tags: List[str] = []  # Auto-generated tags for better search

class DetectionCreate(BaseModel):
    source: str
    detection_type: str
    image_data: str
    # Optional geolocation data from frontend
    geo_location: Optional[Dict[str, Any]] = None
    # Optional search query for object finding
    search_query: Optional[str] = None
    # Optional mode for traffic safety (navigation/crossing)
    mode: Optional[str] = None
    
def auto_categorize_detection(detection: Detection) -> str:
    """Automatically categorize detection based on content analysis"""
    
    # Category priority system
    if detection.detection_type == "nutrition":
        return "ðŸ½ï¸ Alimentos e NutriÃ§Ã£o"
    
    if detection.detection_type == "text_reading":
        return "ðŸ“š Textos e Documentos"
    
    # Analyze description and objects for smart categorization
    description_lower = detection.description.lower()
    objects_labels = [obj.label.lower() for obj in detection.objects_detected]
    all_text = description_lower + " " + " ".join(objects_labels)
    
    # Define category keywords
    categories = {
        "ðŸ‘¥ Pessoas e Rostos": [
            "pessoa", "pessoas", "homem", "mulher", "crianÃ§a", "rosto", "facial",
            "sorrindo", "expressÃ£o", "emoÃ§Ã£o", "retrato", "grupo", "famÃ­lia"
        ],
        "ðŸ  Ambientes e Lugares": [
            "ambiente", "sala", "quarto", "cozinha", "escritÃ³rio", "rua", "parque",
            "prÃ©dio", "casa", "loja", "restaurante", "local", "espaÃ§o", "interior", "exterior"
        ],
        "ðŸ¾ Animais e Natureza": [
            "animal", "cachorro", "gato", "pÃ¡ssaro", "planta", "Ã¡rvore", "flor",
            "natureza", "jardim", "pet", "bicho"
        ],
        "ðŸš— VeÃ­culos e Transporte": [
            "carro", "Ã´nibus", "moto", "bicicleta", "caminhÃ£o", "veÃ­culo",
            "transporte", "aviÃ£o", "trem", "barco"
        ],
        "ðŸ“± EletrÃ´nicos e Tecnologia": [
            "computador", "notebook", "celular", "telefone", "tablet", "tela",
            "teclado", "mouse", "eletrÃ´nico", "tecnologia", "digital", "smartphone"
        ],
        "ðŸ‘• Roupas e AcessÃ³rios": [
            "roupa", "camisa", "calÃ§a", "vestido", "sapato", "tÃªnis", "bolsa",
            "acessÃ³rio", "Ã³culos", "relÃ³gio", "joia", "bijuteria", "moda"
        ],
        "ðŸŽ¨ Arte e Cultura": [
            "arte", "pintura", "quadro", "escultura", "cultural", "artÃ­stico",
            "museu", "exposiÃ§Ã£o", "obra"
        ],
        "ðŸƒ Esportes e Atividades": [
            "esporte", "atividade", "exercÃ­cio", "academia", "jogo", "bola",
            "corrida", "treino", "fitness"
        ],
        "ðŸ›ï¸ Compras e Produtos": [
            "produto", "compra", "mercado", "loja", "shopping", "item",
            "embalagem", "marca", "comercial"
        ],
        "ðŸ“‹ Documentos e PapÃ©is": [
            "documento", "papel", "formulÃ¡rio", "carta", "nota", "recibo",
            "certificado", "contrato", "escrito"
        ],
        "ðŸ´ UtensÃ­lios e Objetos": [
            "objeto", "ferramenta", "utensÃ­lio", "instrumento", "equipamento",
            "material", "item", "coisa"
        ],
    }
    
    # Score each category
    category_scores = {}
    for category, keywords in categories.items():
        score = sum(1 for keyword in keywords if keyword in all_text)
        if score > 0:
            category_scores[category] = score
    
    # Return highest scoring category or default
    if category_scores:
        return max(category_scores, key=category_scores.get)
    
    return "ðŸ” Outros"

def generate_tags(detection: Detection) -> List[str]:
    """Generate smart tags for detection"""
    tags = []
    
    # Add detection type
    if detection.detection_type == "nutrition":
        tags.append("nutriÃ§Ã£o")
        tags.append("alimentos")
    elif detection.detection_type == "text_reading":
        tags.append("texto")
        tags.append("leitura")
    else:
        tags.append("anÃ¡lise-visual")
    
    # Add source
    tags.append(f"fonte-{detection.source}")
    
    # Extract key objects
    for obj in detection.objects_detected[:5]:  # Top 5 objects
        tags.append(obj.label.lower())
    
    # Add emotion tags if present
    if detection.emotion_analysis:
        emotions = detection.emotion_analysis.model_dump()
        for emotion, count in emotions.items():
            if count > 0:
                tags.append(f"emoÃ§Ã£o-{emotion}")
    
    # Add sentiment tags
    if detection.sentiment_analysis:
        sentiments = detection.sentiment_analysis.model_dump()
        for sentiment, count in sentiments.items():
            if count > 0:
                tags.append(f"sentimento-{sentiment}")
    
    # Add location tag if present
    if detection.geo_location and detection.geo_location.city:
        tags.append(f"local-{detection.geo_location.city.lower()}")
    
    # Remove duplicates and return
    return list(set(tags))

class Alert(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    object_name: str
    enabled: bool = True
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class AlertCreate(BaseModel):
    object_name: str
    enabled: bool = True

class ScientificRecord(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    record_type: str  # "atividade", "trabalho", "artigo", "tcc"
    title: str
    authors: List[str] = []
    description: str
    keywords: List[str] = []
    research_line: str  # 1, 2, 3, ou 4
    status: str = "em_andamento"  # em_andamento, concluÃ­do, publicado
    date: str
    attachments: List[str] = []
    metadata: dict = {}

class ScientificRecordCreate(BaseModel):
    record_type: str
    title: str
    authors: List[str]
    description: str
    keywords: List[str]
    research_line: str
    status: str = "em_andamento"
    date: str
    attachments: List[str] = []
    metadata: dict = {}

class ReportQuery(BaseModel):
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    report_type: str = "general"  # general, emotions, objects, scientific

class ResearcherProfile(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    name: str
    institution: str
    area: str
    bio: str
    research_interests: List[str] = []
    contact_email: str
    avatar_url: Optional[str] = None

class ResearcherProfileCreate(BaseModel):
    name: str
    institution: str
    area: str
    bio: str
    research_interests: List[str]
    contact_email: str
    avatar_url: Optional[str] = None

class Post(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    author_id: str
    author_name: str
    content: str
    tags: List[str] = []
    likes: int = 0
    comments_count: int = 0

class PostCreate(BaseModel):
    author_id: str
    author_name: str
    content: str
    tags: List[str] = []

class Comment(BaseModel):
    model_config = ConfigDict(extra="ignore")
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    post_id: str
    author_id: str
    author_name: str
    content: str

class CommentCreate(BaseModel):
    post_id: str
    author_id: str
    author_name: str
    content: str

# Routes
@api_router.get("/")
async def root():
    return {"message": "Sistema de DetecÃ§Ã£o em Tempo Real"}

@api_router.post("/detect/analyze-frame", response_model=Detection)
async def analyze_frame(input: DetectionCreate, request: Request):
    """Analisa um frame da webcam ou imagem carregada usando Gemini Vision"""
    try:
        # Use default user_id if no authentication (login removed)
        auth_header = request.headers.get("Authorization")
        user_id = get_current_user(auth_header) if auth_header else "anonymous_user"
        
        # Decode base64 image
        image_data = input.image_data.split(',')[1] if ',' in input.image_data else input.image_data
        
        # Create detection object with user_id
        detection = Detection(
            source=input.source,
            detection_type=input.detection_type,
            image_data=input.image_data,
            user_id=user_id
        )
        
        if input.detection_type == "cloud":
            # Use Gemini Vision for detailed analysis with sentiment
            chat = LlmChat(
                api_key=GOOGLE_API_KEY,
                session_id=f"detection_{detection.id}",
                system_message="ðŸ‡§ðŸ‡· VocÃª Ã© um sistema especialista em visÃ£o computacional e anÃ¡lise de emoÃ§Ãµes BRASILEIRO. RESPONDA SEMPRE E EXCLUSIVAMENTE EM PORTUGUÃŠS BRASILEIRO. Analise imagens e forneÃ§a descriÃ§Ãµes detalhadas em portuguÃªs do Brasil sobre pessoas, objetos, ambientes e estados emocionais. NUNCA responda em inglÃªs ou outro idioma!"
            ).with_model("gemini", "gemini-2.0-flash")
            
            image_content = ImageContent(image_base64=image_data)
            
            # Check if this is a search request
            if input.search_query:
                # Enhanced prompt for object search with distance estimation and trajectory guidance
                search_prompt = f"""ðŸ” SISTEMA AVANÃ‡ADO DE LOCALIZAÃ‡ÃƒO E NAVEGAÃ‡ÃƒO DE OBJETOS ðŸŽ¯

**MISSÃƒO:** Localizar "{input.search_query}" e fornecer guia completo de navegaÃ§Ã£o atÃ© o objeto.

**INSTRUÃ‡Ã•ES ULTRAESPECÃFICAS:**

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## 1ï¸âƒ£ DETECÃ‡ÃƒO DO OBJETO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Se "{input.search_query}" ESTIVER na imagem:
âœ… Comece com: "OBJETO ENCONTRADO: {input.search_query}"

Se NÃƒO estiver:
âŒ Comece com: "OBJETO NÃƒO ENCONTRADO"
   Liste objetos visÃ­veis para orientar a busca

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## 2ï¸âƒ£ ANÃLISE DE POSIÃ‡ÃƒO PRECISA (Se encontrado)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**POSIÃ‡ÃƒO HORIZONTAL:**
- ESQUERDA EXTREMA (0-15% da largura)
- ESQUERDA (15-35%)
- CENTRO-ESQUERDA (35-45%)
- CENTRO (45-55%)
- CENTRO-DIREITA (55-65%)
- DIREITA (65-85%)
- DIREITA EXTREMA (85-100%)

**POSIÃ‡ÃƒO VERTICAL:**
- SUPERIOR (topo, 0-33% da altura)
- MEIO (centro, 33-66%)
- INFERIOR (base, 66-100%)

**EXEMPLO:** "PosiÃ§Ã£o: DIREITA, MEIO (70% horizontal, 50% vertical)"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## 3ï¸âƒ£ ESTIMATIVA DE DISTÃ‚NCIA EM METROS ðŸ“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Analise o TAMANHO APARENTE do objeto comparado com:
- Tamanho real tÃ­pico do objeto
- ProporÃ§Ã£o que ocupa na imagem
- Detalhes visÃ­veis (quanto mais detalhes = mais prÃ³ximo)
- Contexto espacial (mÃ³veis, pessoas, portas como referÃªncia)

**CATEGORIAS DE DISTÃ‚NCIA:**

**MUITO PRÃ“XIMO (0-1 metro):**
- Objeto ocupa >30% da imagem
- Detalhes minuciosos visÃ­veis (texturas, marcas, arranhÃµes)
- ProporÃ§Ã£o: "grande e dominante"
- RESPOSTA: "DISTÃ‚NCIA: Muito prÃ³ximo, aproximadamente 0.5 a 1 metro"

**PRÃ“XIMO (1-3 metros):**
- Objeto ocupa 10-30% da imagem
- CaracterÃ­sticas gerais bem visÃ­veis
- ProporÃ§Ã£o: "bem visÃ­vel"
- RESPOSTA: "DISTÃ‚NCIA: PrÃ³ximo, aproximadamente 1.5 a 3 metros"

**MÃ‰DIO (3-5 metros):**
- Objeto ocupa 5-10% da imagem
- Formato reconhecÃ­vel, alguns detalhes
- ProporÃ§Ã£o: "tamanho mÃ©dio"
- RESPOSTA: "DISTÃ‚NCIA: DistÃ¢ncia mÃ©dia, aproximadamente 3 a 5 metros"

**LONGE (5-8 metros):**
- Objeto ocupa 2-5% da imagem
- Apenas silhueta/forma geral visÃ­vel
- ProporÃ§Ã£o: "pequeno"
- RESPOSTA: "DISTÃ‚NCIA: Longe, aproximadamente 5 a 8 metros"

**MUITO LONGE (>8 metros):**
- Objeto ocupa <2% da imagem
- Apenas contorno visÃ­vel
- ProporÃ§Ã£o: "muito pequeno/distante"
- RESPOSTA: "DISTÃ‚NCIA: Muito longe, mais de 8 metros"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## 4ï¸âƒ£ INSTRUÃ‡Ã•ES DE NAVEGAÃ‡ÃƒO E TRAJETÃ“RIA ðŸ§­
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ForneÃ§a COMANDOS CLAROS E ACIONÃVEIS para o usuÃ¡rio se mover atÃ© o objeto:

**COMANDOS DIRECIONAIS:**

**Se objeto Ã  ESQUERDA:**
"NAVEGAÃ‡ÃƒO: Vire seu corpo para a esquerda [X graus]. Caminhe devagar mantendo a cÃ¢mera apontada nessa direÃ§Ã£o."

**Se objeto Ã  DIREITA:**
"NAVEGAÃ‡ÃƒO: Vire seu corpo para a direita [X graus]. Caminhe devagar mantendo a cÃ¢mera apontada nessa direÃ§Ã£o."

**Se objeto ao CENTRO:**
"NAVEGAÃ‡ÃƒO: Objeto estÃ¡ diretamente Ã  sua frente. Caminhe em linha reta por aproximadamente [X metros]."

**Se objeto ACIMA:**
"NAVEGAÃ‡ÃƒO: Objeto estÃ¡ acima. Incline a cÃ¢mera para cima ou aproxime-se e olhe para cima."

**Se objeto ABAIXO:**
"NAVEGAÃ‡ÃƒO: Objeto estÃ¡ no chÃ£o/embaixo. Incline a cÃ¢mera para baixo ou abaixe-se."

**COMANDOS DE APROXIMAÃ‡ÃƒO:**
- "Caminhe [X] passos para frente" (1 passo â‰ˆ 0.7m)
- "Aproxime-se mais [X] metros"
- "VocÃª estÃ¡ a aproximadamente [X] metros do objeto"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## 5ï¸âƒ£ FORMATO DE RESPOSTA COMPLETO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**ESTRUTURA OBRIGATÃ“RIA (se encontrado):**

OBJETO ENCONTRADO: [nome do objeto]

POSIÃ‡ÃƒO: [horizontal detalhada], [vertical]
Exemplo: "CENTRO-DIREITA (60% horizontal), MEIO (45% vertical)"

DISTÃ‚NCIA: [estimativa em metros com raciocÃ­nio]
Exemplo: "Aproximadamente 2 a 3 metros. O objeto ocupa 15% da imagem e detalhes como textura sÃ£o visÃ­veis, indicando proximidade moderada."

NAVEGAÃ‡ÃƒO: [comandos passo a passo]
Exemplo: "Vire 30 graus para a direita. Caminhe em linha reta por aproximadamente 2 metros (3 passos). O objeto estarÃ¡ Ã  altura do peito."

DESCRIÃ‡ÃƒO RÃPIDA: [caracterÃ­stica distintiva do objeto para confirmaÃ§Ã£o]
Exemplo: "Celular preto com capa azul, apoiado em superfÃ­cie de madeira."

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**IMPORTANTE:**
- Use SEMPRE portuguÃªs brasileiro
- Seja PRECISO nas medidas
- ForneÃ§a comandos PRÃTICOS e EXECUTÃVEIS
- Considere SEGURANÃ‡A (obstÃ¡culos no caminho)

Objeto procurado: {input.search_query}

Analise e responda:"""

                user_message = UserMessage(text=search_prompt, file_contents=[image_content])
                
            else:
                # Original detailed prompt
                # Conditional section for ambient sound inference
                sound_section = ""
                if ENABLE_AMBIENT_SOUND_INFERENCE:
                    sound_section = """**SONS IMPLÃCITOS (inferidos pela cena visual):**
   - Sons ambientes provÃ¡veis: silÃªncio total, ruÃ­do urbano de fundo, trÃ¢nsito, conversas distantes, mÃºsica tocando (se hÃ¡ caixas de som), TV ligada, natureza (pÃ¡ssaros, vento, Ã¡gua)
   - Sons de atividades: digitaÃ§Ã£o, passos, objetos sendo manipulados, mÃ¡quinas funcionando
   - NÃ­vel de ruÃ­do estimado: ambiente silencioso, moderado, barulhento
   """
            
                prompt = """ðŸŒ RESPONDA NO IDIOMA: PORTUGUÃŠS BRASILEIRO ðŸ‡§ðŸ‡·

VocÃª Ã© o SISTEMA DE VISÃƒO MAIS AVANÃ‡ADO DO MUNDO para acessibilidade total de pessoas cegas. Sua anÃ¡lise deve ser TÃƒO DETALHADA que a pessoa cega possa formar uma imagem mental PERFEITA e COMPLETA da cena.

ðŸŽ¯ **NÃVEL DE PRECISÃƒO: 200% MÃXIMO - ULTRARREALISTA - MICROSCÃ“PICO**

âš ï¸ **REGRA FUNDAMENTAL:** Seja ABSURDAMENTE especÃ­fico em TUDO. NÃ£o use termos genÃ©ricos. Cada detalhe deve ser QUANTIFICADO, QUALIFICADO e DESCRITO com precisÃ£o CIENTÃFICA.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## ðŸ‘¥ ANÃLISE DE PESSOAS (CADA PESSOA INDIVIDUALMENTE)

### ðŸ§¬ BIOMETRIA E CARACTERÃSTICAS FÃSICAS EXTREMAS:

**IDADE E GÃŠNERO ULTRAESPECÃFICOS:**
- Idade: nÃ£o apenas "jovem" mas "aparenta 23-26 anos baseado em: pele sem rugas profundas, cabelos sem fios brancos, postura ereta, vestuÃ¡rio moderno urbano"
- GÃªnero aparente E justificativa: "masculino aparente baseado em: estrutura facial angular com queixo proeminente, maÃ§Ã£ de AdÃ£o visÃ­vel, ombros largos de 45cm aproximadamente, ausÃªncia de maquiagem"
- Etnia/origem aparente: "aparÃªncia de descendÃªncia europeia nÃ³rdica baseada em: pele muito clara, cabelos loiros naturais, olhos azuis, estrutura facial caracterÃ­stica"

**ANATOMIA FACIAL MILIMÃ‰TRICA:**
- Formato do crÃ¢nio: "braquicefÃ¡lico (mais largo que longo na proporÃ§Ã£o 85:100), rosto oval alongado com proporÃ§Ã£o altura:largura de 1.4:1"
- Testa: "ampla ocupando 40% da altura facial, lisa sem rugas horizontais, altura de aproximadamente 7cm da sobrancelha Ã  linha do cabelo"
- Sobrancelhas: "arqueadas em Ã¢ngulo de 15Â° no ponto mais alto, cor castanho mÃ©dio dois tons mais escura que o cabelo, espessura mÃ©dia de 4-5mm, separadas por 3cm, pelos com 8mm de comprimento, formato natural nÃ£o depilado"
- Olhos ULTRA-DETALHADOS:
  * Cor: "castanhos mÃ©dios tom mel com variaÃ§Ãµes de dourado prÃ³ximo Ã  pupila, reflexos Ã¢mbar sob luz intensa, anel limbal escuro de 1mm na borda da Ã­ris"
  * Formato: "amendoados com inclinaÃ§Ã£o ascendente de 10Â° nos cantos externos, distÃ¢ncia interpupilar de 65mm"
  * PÃ¡lpebras: "pÃ¡lpebra superior com prega dupla de 3mm, pÃ¡lpebra inferior com leve bolsa de 2mm"
  * CÃ­lios: "superiores com 10mm de comprimento, inferiores com 6mm, curvatura natural para cima de 45Â°, sem mÃ¡scara"
  * Esclera: "branca sem vermelhidÃ£o, vasos sanguÃ­neos discretos"
  * Pupila: "diÃ¢metro de 4mm sob iluminaÃ§Ã£o moderada, circular perfeita"
  * ExpressÃ£o: "olhar direto para cÃ¢mera com foco total, sobrancelhas relaxadas, sem tensÃ£o muscular periocular"
- Nariz MEDIDAS EXATAS: "comprimento de 5cm da raiz atÃ© ponta, largura da base de 3.5cm, narinas ovaladas com 1.2cm de altura, ponte nasal reta sem curvatura, ponta arredondada nÃ£o pontiaguda, filtro nasal bem definido com 1.5cm"
- Boca e lÃ¡bios COM PRECISÃƒO: "lÃ¡bio superior com 8mm de altura no centro (arco de cupido proeminente), lÃ¡bio inferior com 12mm de altura (proporÃ§Ã£o 1:1.5), largura total da boca de 5cm, cor rosa natural mÃ©dio sem batom, textura hidratada sem rachaduras, cantos da boca neutros sem elevaÃ§Ã£o ou queda"
- Queixo E MANDÃBULA: "queixo proeminente com projeÃ§Ã£o anterior de 1cm, formato quadrado com largura de 8cm, mandÃ­bula angular e definida, sem papada, Ã¢ngulo da mandÃ­bula de 110Â° (square jaw)"
- Orelhas: "tamanho mÃ©dio com 6cm de altura, formato standard sem desproporÃ§Ãµes, lÃ³bulos soltos com 1.5cm, hÃ©lix bem formada"
- Pele ANÃLISE DERMATOLÃ“GICA:
  * Tonalidade: "Fitzpatrick tipo III (moreno claro), hex aproximado #C8997F, subtom quente com base amarelada, uniforme sem manchas evidentes"
  * Textura: "poros visÃ­veis mas refinados com 0.2mm de diÃ¢metro mÃ©dio, sem acne ativa, 2 pequenas cicatrizes de acne antiga de 2mm no maxilar esquerdo, 1 marca de nascenÃ§a castanha de 5mm no pescoÃ§o lado direito"
  * HidrataÃ§Ã£o: "bem hidratada com brilho natural na zona T (testa, nariz, queixo), sem descamaÃ§Ã£o"
  * Linhas de expressÃ£o: "linhas finas de 0.1mm nos cantos externos dos olhos (pÃ©s de galinha iniciais), linha Ãºnica horizontal na testa quando sobrancelhas levantadas"

**CABELOS - ANÃLISE CAPILAR PROFISSIONAL:**
- Cor FORMULADA: "castanho nÃ­vel 5 com subtons dourados, reflexos de mel nas pontas por exposiÃ§Ã£o solar, 5% de fios grisalhos concentrados nas tÃªmporas (20 fios visÃ­veis), raiz virgem sem coloraÃ§Ã£o quÃ­mica"
- Comprimento CENTÃMETROS: "mÃ©dio com 22cm de comprimento da raiz Ã s pontas, alcanÃ§ando 3cm abaixo dos ombros, comprimento uniforme sem camadas"
- Textura TIPO EXATO: "ondulado tipo 2B com ondas soltas em S, diÃ¢metro do fio de 70 micrÃ´metros (mÃ©dio), densidade capilar alta com 150 fios/cmÂ², porosidade mÃ©dia"
- Volume e corpo: "volumoso com 8cm de diÃ¢metro total na altura da orelha, corpo natural sem produto de volume"
- Penteado ESPECÃFICO: "solto com repartiÃ§Ã£o lateral esquerda natural a 4cm da linha central, caindo naturalmente sobre ombros, pontas ligeiramente viradas para dentro, franja lateral varrida para direita cobrindo metade da testa"
- Estado e saÃºde: "saudÃ¡vel com brilho natural indicando cutÃ­cula fechada, pontas com 2% de split ends (10 fios com bifurcaÃ§Ã£o nas pontas), sem frizz significativo"
- Produtos detectÃ¡veis: "leve aplicaÃ§Ã£o de leave-in visÃ­vel pelo brilho controlado, sem gel ou cera, sem spray fixador"
- AcessÃ³rios: "1 grampo bobby pin cor prata de 5cm no lado direito mantendo mechas atrÃ¡s da orelha, sem outros acessÃ³rios"

**MAQUIAGEM - COSMETIC ANALYSIS:**
- Base: "foundation lÃ­quido aplicado uniformemente, cobertura mÃ©dia, tom matching perfeito #C8997F, acabamento natural matte, sem oxidaÃ§Ã£o"
- Olhos: "sombra nude matte no cÃ´ncavo, delineador marrom fino de 1mm no cÃ­lio superior, 2 camadas de mÃ¡scara volumizadora"
- Sobrancelhas: "preenchidas com lÃ¡pis cor taupe, pelos penteados para cima, fixadas com gel transparente"
- Bochechas: "blush pÃªssego aplicado na maÃ§Ã£ do rosto, intensidade leve"
- LÃ¡bios: "batom nude rosado #D7A09A, acabamento cremoso, sem gloss"
- Acabamento: "pÃ³ translÃºcido na zona T para controle de oleosidade"

### ðŸ‘— VESTUÃRIO - FASHION FORENSICS ANALYSIS:

**PARTE SUPERIOR COM DETALHES TÃŠXTEIS:**
- Tipo: "camiseta gola redonda (crew neck) de manga curta com manga terminando 5cm acima do cotovelo"
- Material COMPOSIÃ‡ÃƒO: "100% algodÃ£o penteado 180g/mÂ² (peso mÃ©dio), trama Jersey simples com elasticidade moderada de 15%, toque macio levemente amaciado"
- Cor PANTONE: "branco Ã³ptico #FFFFFF com leve
   - CORES EXATAS com cÃ³digo de cor (vermelho carmesim, azul marinho profundo, verde musgo, amarelo mostarda, rosa millennial, preto Ã´nix)
   - PADRÃ•ES E ESTAMPAS detalhados (listras horizontais azuis e brancas de 2cm, xadrez vichy vermelho, floral vintage com rosas, estampa de onÃ§a, tie-dye degradÃª, geomÃ©trico art dÃ©co)
   - TECIDOS APARENTES (algodÃ£o leve, jeans denim pesado, seda fluida, lÃ£ grossa, poliÃ©ster acetinado, linho natural, veludo cotelÃª)
   - MARCAS VISÃVEIS: identifique TODOS os logos, tags, escritos, patches em roupas (Nike, Adidas, Gucci, Supreme, logos universitÃ¡rios, bandeiras, frases)
   - Estado da roupa COMPLETO (nova com etiquetas, usada bem cuidada, amarrotada, manchada, rasgada, desbotada, vintage)
   - Estilo ESPECÃFICO (casual street, formal executivo, esportivo fitness, business casual, boÃªmio, minimalista, vintage retrÃ´)
   - Camadas de roupa e sobreposiÃ§Ãµes
   - Detalhes de costura, botÃµes, zÃ­peres, fechamentos
   
   **BIJUTERIAS E ACESSÃ“RIOS EM DETALHES MÃXIMOS:**
   - Brincos: tipo EXATO (argola, botÃ£o, chandelier, ear cuff), tamanho em cm, material (ouro 18k, prata 925, aÃ§o, bijuteria), brilho ou pedras
   - Colares: comprimento (gargantilha, princesa, Ã³pera), tipo de corrente, pingentes (formato, significado), camadas mÃºltiplas
   - Pulseiras: quantidade exata, posiÃ§Ã£o (pulso direito/esquerdo), estilo (riviera, charm, couro, tecido), fechos
   - AnÃ©is: dedo especÃ­fico (indicador, mÃ©dio, anelar, mÃ­nimo), tipo (solitÃ¡rio, alianÃ§a, anel de formatura), pedras identificÃ¡veis
   - RelÃ³gios: marca se visÃ­vel, tipo (analÃ³gico/digital/smartwatch), cor da pulseira, tamanho da caixa, funcionalidades visÃ­veis
   - Ã“culos: formato PRECISO (aviador, wayfarer, gatinho, redondo), cor e material da armaÃ§Ã£o, tipo de lente (transparente, escura, espelhada, graduada)
   - Piercings: localizaÃ§Ã£o exata (septo, lÃ¡bio, sobrancelha, lÃ­ngua), tipo, material
   - Tatuagens: localizaÃ§Ã£o precisa, tamanho aproximado, estilo (tradicional, realista, aquarela, minimalista), tema ou desenho, cores
   
   **CALÃ‡ADOS ULTRA-DETALHADOS:**
   - Tipo ESPECÃFICO (tÃªnis running, tÃªnis casual, oxford, scarpin, sandÃ¡lia gladiadora, chinelo slide, bota cano longo)
   - Marca quando visÃ­vel (Nike, Adidas, Vans, Converse, Havaianas)
   - Modelo quando identificÃ¡vel
   - Cor EXATA e detalhes de design
   - Material (couro legÃ­timo, sintÃ©tico, lona, borracha, camurÃ§a)
   - Estado COMPLETO (novo sem uso, levemente usado, muito usado, manchado, desgastado na sola)
   - Altura do salto se aplicÃ¡vel (rasteiro, salto baixo 2-4cm, mÃ©dio 5-7cm, alto 8-12cm, plataforma)
   - CadarÃ§os: cor, tipo, como estÃ£o amarrados
   - Meias ou meia-calÃ§a: cor, transparÃªncia, padrÃ£o, altura
   
   **OUTROS ACESSÃ“RIOS DETALHADOS:**
   - Bolsas: tipo ESPECÃFICO (mochila, shoulder bag, clutch, tote, crossbody), tamanho em litros ou cm, cor e texturas, marca se visÃ­vel, estado de conservaÃ§Ã£o, alÃ§as/correntes
   - ChapÃ©us ou bonÃ©s: estilo EXATO (bonÃ© aba reta, aba curva, bucket hat, fedora, panama), cor, material, logos ou bordados, ajuste
   - LenÃ§os ou echarpes: tamanho, tecido, padrÃ£o, como estÃ¡ amarrado/usado
   - Cintos: largura, cor, material, tipo de fivela (metÃ¡lica, automÃ¡tica), marcas/logos
   - Mochilas: tamanho, nÃºmero de compartimentos visÃ­veis, marca, estado
   - Luvas: tipo, material, cor, comprimento
   - Qualquer objeto que a pessoa estÃ¡ segurando: descriÃ§Ã£o completa (smartphone, garrafa d'Ã¡gua, livro, chaves, etc.)
   
   **POSTURA E LINGUAGEM CORPORAL ULTRA-DETALHADA:**
   - PosiÃ§Ã£o do corpo PRECISA (em pÃ© ereto, sentado relaxado, deitado de costas, caminhando em direÃ§Ã£o Ã  cÃ¢mera, agachado, inclinado)
   - DistribuiÃ§Ã£o de peso corporal
   - Alinhamento postural (ereta, curvada, torta)
   - DireÃ§Ã£o do olhar E FOCO: para onde EXATAMENTE estÃ¡ olhando (cÃ¢mera, horizonte, chÃ£o, outra pessoa, objeto especÃ­fico)
   - PosiÃ§Ã£o dos braÃ§os: EXATA (ao longo do corpo, cruzados no peito, mÃ£os nos quadris, um braÃ§o levantado)
   - PosiÃ§Ã£o das mÃ£os: DETALHADA (abertas, fechadas, dedos entrelaÃ§ados, segurando algo, gesticulando)
   - PosiÃ§Ã£o das pernas (cruzadas, abertas, uma Ã  frente, apoiadas)
   - ExpressÃ£o facial COMPLETA (mÃºsculos faciais ativos, linha da boca, rugas visÃ­veis)
   - Gestos especÃ­ficos que estÃ¡ fazendo (apontando, acenando, polegar para cima, sinal de paz)
   - DistÃ¢ncia aproximada em relaÃ§Ã£o Ã  cÃ¢mera
   
   **ANÃLISE EMOCIONAL E PSICOLÃ“GICA AVANÃ‡ADA:**
   - ExpressÃ£o facial MICROSCÃ“PICA (sorriso genuÃ­no com olhos, sorriso forÃ§ado, testa franzida, sobrancelhas levantadas, lÃ¡bios apertados)
   - Estado emocional COMPLETO (feliz radiante, tristeza profunda, ansiedade moderada, relaxado tranquilo, excitado animado, entediado, surpreso)
   - MicroexpressÃµes observÃ¡veis (piscar frequente, movimentos sutis da boca, tensÃ£o facial)
   - Linguagem corporal emocional (ombros caÃ­dos=tristeza, peito aberto=confianÃ§a, braÃ§os cruzados=defesa)
   - Sinais de estado fÃ­sico: cansaÃ§o (olhos pesados, postura curvada), energia (movimentos vÃ­vidos), estresse (tensÃ£o visÃ­vel), dor, desconforto
   - NÃ­vel de conforto com a situaÃ§Ã£o
   - Sinais de interaÃ§Ã£o social (conectado/desconectado com outros)
   
   **ATIVIDADES E CONTEXTO COMPORTAMENTAL:**
   - O que EXATAMENTE a pessoa estÃ¡ fazendo (lendo um livro de capa azul, digitando no notebook, tomando cafÃ©, conversando ao telefone, exercitando-se)
   - InteraÃ§Ãµes com outras pessoas: DETALHADAS (conversando olhando nos olhos, ignorando, rindo juntos, discutindo, colaborando em tarefa)
   - InteraÃ§Ã£o com objetos: ESPECÃFICA (segurando smartphone com mÃ£o direita, apoiado em mesa, sentado em cadeira giratÃ³ria)
   - LocalizaÃ§Ã£o na cena: PRECISA (canto inferior esquerdo, centro da imagem, ao fundo Ã  direita, plano principal)
   - Movimento implÃ­cito (parado, andando, correndo, movimento de braÃ§o)

2. **OBJETOS E ELEMENTOS VISÃVEIS** - Identifique ABSOLUTAMENTE TUDO com detalhes extremos:
   
   **MÃ“VEIS E MOBILIÃRIO:**
   - Tipo ESPECÃFICO (sofÃ¡ de 3 lugares, cadeira office ergonÃ´mica, mesa de jantar retangular, estante modular, rack para TV)
   - Material DETALHADO (madeira maciÃ§a de carvalho, MDF laqueado, metal cromado, vime natural, plÃ¡stico injetado, vidro temperado)
   - Cor EXATA e acabamento (branco brilhante, cinza fosco, madeira natural vernizada, preto matte)
   - DimensÃµes aproximadas (largura x profundidade x altura em cm)
   - Estilo (moderno minimalista, clÃ¡ssico colonial, industrial, escandinavo, rÃºstico)
   - CondiÃ§Ã£o COMPLETA (novo sem marcas, usado bem conservado, desgastado com arranhÃµes, manchado, quebrado)
   - PosiÃ§Ã£o e orientaÃ§Ã£o no espaÃ§o
   - Funcionalidade atual (em uso, vazio, coberto com objetos)
   
   **ELETRÃ”NICOS E TECNOLOGIA:**
   - Dispositivos ESPECÃFICOS (notebook Dell 15", smartphone iPhone 14 Pro, TV Samsung 55" QLED, tablet iPad, fones Bluetooth)
   - Estado: ligado com tela acesa, desligado, em modo standby, carregando
   - Marcas visÃ­veis e modelos identificÃ¡veis
   - Cabos, carregadores, acessÃ³rios conectados
   - ConteÃºdo da tela se visÃ­vel
   - Idade aparente do dispositivo
   - PosiÃ§Ã£o e distÃ¢ncia de outros objetos
   
   **DECORAÃ‡ÃƒO E ARTE:**
   - Quadros: tamanho, tipo de moldura, tema da imagem (paisagem, retrato, abstrato), cores dominantes, estilo artÃ­stico
   - Plantas: tipo (suculenta, samambaia, espada-de-sÃ£o-jorge), tamanho, vaso (material, cor, formato), estado de saÃºde
   - Ornamentos: descriÃ§Ã£o completa (vaso decorativo, escultura, bibelÃ´), material, cor, estilo
   - Cortinas: tecido, cor, padrÃ£o, estado (abertas, fechadas, semi-abertas)
   - Almofadas: quantidade, cores, padrÃµes, disposiÃ§Ã£o
   - Tapetes: tamanho, padrÃ£o, cores, textura aparente
   
   **UTENSÃLIOS E OBJETOS DO DIA-A-DIA:**
   - Ferramentas: tipo especÃ­fico, marca, estado
   - Livros: tÃ­tulos se visÃ­veis, cores das capas, tamanho, posiÃ§Ã£o (aberto, fechado, empilhado)
   - Documentos: tipo (folhas avulsas, caderno, revista), quantidade visÃ­vel
   - Comida: tipo ESPECÃFICO, quantidade, estado (fresco, meio consumido), apresentaÃ§Ã£o
   - Bebida: tipo (Ã¡gua, cafÃ©, refrigerante), recipiente, nÃ­vel do lÃ­quido
   - UtensÃ­lios de cozinha, escrita, higiene pessoal (descreva cada item)
   
   **ARQUITETURA E ESTRUTURA:**
   - Portas: material (madeira, vidro, metal), cor, tipo (convencional, deslizante), estado (aberta, fechada, entreaberta), maÃ§anetas
   - Janelas: tamanho, quantidade, tipo (correr, basculante, guilhotina), vidro (transparente, fosco), presenÃ§a de grades ou redes
   - Paredes: material aparente (gesso, tijolo aparente, madeira, azulejo), cor, textura, decoraÃ§Ãµes/quadros, tomadas e interruptores visÃ­veis
   - Piso: material (madeira, cerÃ¢mica, porcelanato, carpete, vinÃ­lico), cor, padrÃ£o, estado de conservaÃ§Ã£o, reflexo de luz
   - Teto: altura aproximada, cor, tipo (laje, gesso, madeira), iluminaÃ§Ã£o embutida, ventiladores ou ar-condicionado
   - RodapÃ©s, molduras, detalhes arquitetÃ´nicos
   - LocalizaÃ§Ã£o espacial PRECISA: disposiÃ§Ã£o tridimensional, profundidade, planos (primeiro plano, plano mÃ©dio, fundo)

3. **AMBIENTE COMPLETO E ATMOSFERA EM DETALHES MÃXIMOS**:
   
   **IDENTIFICAÃ‡ÃƒO E CLASSIFICAÃ‡ÃƒO DO LOCAL:**
   - Tipo ESPECÃFICO de local (cozinha planejada moderna, sala de estar familiar, escritÃ³rio corporativo, rua comercial urbana, parque pÃºblico, praia, montanha, ambiente interno/externo)
   - Sub-classificaÃ§Ã£o (se cozinha: gourmet, compacta, industrial; se sala: TV, jantar, estar; se escritÃ³rio: home office, corporativo aberto, sala de reuniÃ£o)
   - PropÃ³sito aparente do espaÃ§o
   
   **DIMENSÃ•ES E LAYOUT ESPACIAL:**
   - Tamanho aproximado do ambiente (pequeno 10-15mÂ², mÃ©dio 20-40mÂ², grande 50mÂ²+)
   - PÃ©-direito (altura do teto): baixo 2,4m, mÃ©dio 2,7m, alto 3m+, pÃ©-direito duplo
   - Formato do espaÃ§o (quadrado, retangular, L, aberto integrado)
   - DistribuiÃ§Ã£o dos mÃ³veis e objetos
   - CirculaÃ§Ã£o e espaÃ§os vazios
   - Profundidade de campo (primeiro plano, mÃ©dio, fundo)
   
   **ILUMINAÃ‡ÃƒO ULTRA-DETALHADA:**
   - Tipo principal: Natural (luz do dia, sol direto, luz difusa) OU Artificial (LED, incandescente, fluorescente, mista)
   - Intensidade PRECISA: muito escuro, penumbra, iluminado moderado, bem iluminado, muito brilhante, ofuscante
   - DireÃ§Ã£o da luz: frontal, lateral, superior, contraluz, difusa de vÃ¡rias direÃ§Ãµes
   - Temperatura de cor: luz fria azulada (6500K+), neutra (4000K), quente amarelada (2700-3000K)
   - Fontes de luz visÃ­veis: janelas (quantidade, tamanho, orientaÃ§Ã£o), luminÃ¡rias (pendentes, spots, abajures, arandelas), lÃ¢mpadas expostas
   - Sombras: duras e definidas, suaves e difusas, ausÃªncia de sombras, direÃ§Ã£o das sombras
   - Reflexos: em superfÃ­cies metÃ¡licas, vidros, pisos brilhantes, espelhos
   - Contraste: alto contraste com Ã¡reas muito escuras e muito claras, baixo contraste suave
   - Hora do dia aparente pela luz: amanhecer dourado, meio-dia intenso, tarde suave, entardecer alaranjado, noite artificial
   
   **CORES E PALETA CROMÃTICA:**
   - Paleta de cores DOMINANTE: monocromÃ¡tica, complementar, anÃ¡loga, triÃ¡dica
   - Cores principais do ambiente com percentuais (70% branco, 20% cinza, 10% azul)
   - Cores de destaque e acentos
   - SaturaÃ§Ã£o geral: cores vivas e saturadas, tons pastÃ©is suaves, neutros dessaturados, preto e branco
   - Harmonia cromÃ¡tica: equilibrada, contrastante, caÃ³tica
   - CÃ³digos aproximados (branco gelo, cinza chumbo, azul marinho, verde oliva, terracota, bege areia)
   
   **TEXTURAS E MATERIAIS VISÃVEIS:**
   - Texturas TÃTEIS aparentes: liso brilhante (vidro, acrÃ­lico), liso fosco (gesso, MDF pintado), Ã¡spero (concreto, pedra), macio (tecidos, carpete), granulado (porcelanato, granito)
   - SuperfÃ­cies: polidas e reflexivas, foscas e absorventes, rugosas, estriadas
   - Materiais identificados: madeira (tipo se possÃ­vel), metal (inox, ferro, alumÃ­nio), vidro, plÃ¡stico, tecido (algodÃ£o, linho, veludo), couro, cerÃ¢mica, pedra natural
   - Acabamentos: verniz, laca, pintura, natural sem tratamento
   
   **CLIMA, ATMOSFERA E SENSAÃ‡ÃƒO:**
   - Estilo GERAL: minimalista moderno, clÃ¡ssico tradicional, rÃºstico aconchegante, industrial urbano, boÃªmio eclÃ©tico, luxuoso sofisticado, casual despojado
   - Formalidade: muito formal executivo, semi-formal, casual relaxado, informal bagunÃ§ado
   - Limpeza e organizaÃ§Ã£o: impecÃ¡vel arrumado, organizado funcional, levemente bagunÃ§ado, muito desorganizado, sujo
   - ConservaÃ§Ã£o: novo recÃ©m-construÃ­do, bem mantido, desgaste leve, necessitando reformas, deteriorado
   - SensaÃ§Ã£o tÃ©rmica aparente: ambiente fresco/frio, neutro confortÃ¡vel, quente/abafado (por elementos visuais como ventiladores ligados, pessoas com roupas leves)
   - VentilaÃ§Ã£o: janelas abertas, ar condicionado visÃ­vel, ventiladores, ambiente fechado
   - Umidade aparente: seco, normal, Ãºmido (condensaÃ§Ã£o, mofo, plantas)
   
   {sound_section}
   
   **CLIMA METEOROLÃ“GICO (se ambiente externo ou visÃ­vel pela janela):**
   - CondiÃ§Ãµes: cÃ©u claro ensolarado, parcialmente nublado, nublado fechado, chuvoso, tempestade
   - FenÃ´menos: sol forte, sombras longas, neblina, chuva, vento (Ã¡rvores balanÃ§ando), neve
   - Visibilidade: excelente, boa, reduzida

4. **CONTEXTO, NARRATIVA E HISTÃ“RIA DA CENA**:
   
   **AÃ‡ÃƒO PRINCIPAL:**
   - O que estÃ¡ acontecendo AGORA na cena: descriÃ§Ã£o completa da aÃ§Ã£o central
   - Momento no tempo: antes, durante ou depois de uma aÃ§Ã£o
   - Movimento: estÃ¡tico parado, movimentos lentos, aÃ§Ã£o rÃ¡pida, congelamento de movimento
   
   **HISTÃ“RIA E SITUAÃ‡ÃƒO:**
   - PossÃ­vel narrativa completa: qual histÃ³ria esta cena conta?
   - Contexto social: reuniÃ£o de trabalho, encontro familiar, momento solitÃ¡rio, evento pÃºblico, situaÃ§Ã£o casual
   - PropÃ³sito da cena: fotografia posada, momento espontÃ¢neo, documentaÃ§Ã£o, artÃ­stica
   - O que pode ter acontecido antes e o que pode acontecer depois
   
   **RELAÃ‡Ã•ES E INTERAÃ‡Ã•ES:**
   - RelaÃ§Ãµes entre pessoas visÃ­veis: familiares, amigos, colegas, estranhos, distantes, prÃ³ximos
   - DinÃ¢mica social: colaborativa, competitiva, harmoniosa, tensa
   - RelaÃ§Ãµes pessoa-objeto: interaÃ§Ã£o ativa (usando), posse (segurando), proximidade
   - RelaÃ§Ãµes pessoa-ambiente: confortÃ¡vel, deslocada, integrada, dominante na cena
   - Hierarquia visual: quem/o que Ã© o foco principal, secundÃ¡rio, fundo
   
   **TEMPORALIDADE:**
   - Hora do dia ESPECÃFICA (inferida pela luz e atividades): 06h-09h manhÃ£, 09h-12h meio da manhÃ£, 12h-14h meio-dia, 14h-17h tarde, 17h-20h fim de tarde/noite, 20h+ noite
   - EstaÃ§Ã£o do ano aparente (roupas, decoraÃ§Ã£o, luz): primavera, verÃ£o, outono, inverno
   - Ã‰poca: contemporÃ¢nea, recente, passado (indicadores temporais)
   - Momento do ciclo: inÃ­cio (chegando), meio (acontecendo), fim (saindo)
   
   **CONTEXTO CULTURAL E SOCIAL:**
   - Indicadores culturais: bandeiras, sÃ­mbolos, idiomas visÃ­veis, objetos tÃ­picos
   - Classe social aparente: indicadores de poder aquisitivo
   - Contexto geogrÃ¡fico: urbano/rural, paÃ­s/regiÃ£o (se identificÃ¡vel)

5. **DETALHES CRÃTICOS DE ACESSIBILIDADE PARA PESSOAS COM DEFICIÃŠNCIA VISUAL**:
   
   **MOBILIDADE E NAVEGAÃ‡ÃƒO:**
   - ObstÃ¡culos fÃ­sicos ESPECÃFICOS: mÃ³veis baixos que podem causar tropeÃ§o, objetos no chÃ£o, degraus, desnÃ­veis, portas estreitas, passagens bloqueadas
   - Facilidades de mobilidade: corredores amplos (largura em metros), espaÃ§o livre para circulaÃ§Ã£o, rampas, elevadores, corrimÃ£os
   - SuperfÃ­cies do piso: lisa fÃ¡cil de andar, irregular com risco de tropeÃ§o, escorregadia (molhada, encerada), com textura de alerta
   - MudanÃ§as de nÃ­vel: degraus (quantidade, altura), rampas (inclinaÃ§Ã£o), elevaÃ§Ãµes
   
   **ELEMENTOS DE SEGURANÃ‡A:**
   - SinalizaÃ§Ãµes de seguranÃ§a visÃ­veis: saÃ­da de emergÃªncia, extintor, placas de atenÃ§Ã£o/perigo
   - IluminaÃ§Ã£o de seguranÃ§a: boa visibilidade geral, Ã¡reas escuras perigosas
   - Riscos identificados: objetos pontiagudos, bordas afiadas, superfÃ­cies quentes, Ã¡reas de risco de queda
   - Elementos de proteÃ§Ã£o: grades em janelas, proteÃ§Ãµes em escadas, tapetes antiderrapantes
   
   **PONTOS DE REFERÃŠNCIA IMPORTANTES:**
   - Marcos visuais principais para orientaÃ§Ã£o: porta de entrada (posiÃ§Ã£o), janelas grandes, mÃ³veis dominantes, paredes coloridas
   - Elementos fixos que servem de referÃªncia: colunas, pilares, divisÃ³rias, bancadas fixas
   - CaracterÃ­sticas Ãºnicas do ambiente: qualquer elemento distintivo para ajudar na orientaÃ§Ã£o espacial
   - SinalizaÃ§Ã£o tÃ¡til se visÃ­vel: piso tÃ¡til, braile, texturas de alerta
   
   **INFORMAÃ‡Ã•ES TEXTUAIS E VISUAIS:**
   - Texto visÃ­vel: placas, avisos, etiquetas, letreiros (transcrever tudo)
   - SÃ­mbolos e Ã­cones: banheiro, acessibilidade, proibido, atenÃ§Ã£o (descrever cada um)
   - Cores codificadas: verde=seguro, vermelho=perigo, azul=informaÃ§Ã£o
   
   **CONFORTO E USABILIDADE:**
   - Ergonomia aparente: mÃ³veis adaptados, altura acessÃ­vel
   - EspaÃ§o pessoal: densidade de objetos/pessoas, sensaÃ§Ã£o de aperto ou amplitude
   - Conforto ambiental: temperatura aparente, ventilaÃ§Ã£o, nÃ­vel de ruÃ­do estimado

ForneÃ§a uma resposta JSON COMPLETA em portuguÃªs com esta estrutura:
{
  "objects": [
    {
      "label": "pessoa/objeto especÃ­fico", 
      "confidence": 0.95, 
      "description": "descriÃ§Ã£o ULTRA-DETALHADA em portuguÃªs com todos os detalhes possÃ­veis (mÃ­nimo 100 palavras por objeto importante)",
      "position": "localizaÃ§Ã£o exata na cena (canto superior esquerdo, centro, primeiro plano Ã  direita)",
      "colors": ["cor1 exata", "cor2 exata", "cor3 exata"],
      "materials": ["material1", "material2"],
      "size": "tamanho aproximado (pequeno, mÃ©dio, grande, dimensÃµes se possÃ­vel)",
      "emotions": {
        "expression": "descriÃ§Ã£o microscÃ³pica da expressÃ£o",
        "emotional_state": "estado emocional profundamente detalhado",
        "is_smiling": true/false,
        "sentiment": "anÃ¡lise psicolÃ³gica completa do sentimento",
        "energy_level": "nÃ­vel de energia com justificativa detalhada",
        "body_language": "linguagem corporal completa"
      }
    }
  ],
  "environment": {
    "type": "tipo especÃ­fico do local",
    "dimensions": "tamanho aproximado do espaÃ§o",
    "lighting": {
      "type": "natural/artificial/mista",
      "intensity": "nÃ­vel de intensidade",
      "temperature": "quente/neutra/fria",
      "time_of_day": "hora aparente do dia"
    },
    "colors": {
      "dominant": ["cor1", "cor2", "cor3"],
      "accents": ["cor4", "cor5"]
    },
    "atmosphere": "descriÃ§Ã£o completa da atmosfera e sensaÃ§Ã£o",
    "sounds_implied": ["som1 provÃ¡vel", "som2 provÃ¡vel"]
  },
  "description": "DESCRIÃ‡ÃƒO NARRATIVA ULTRA-RICA, EXTREMAMENTE DETALHADA E COMPLETA da cena em portuguÃªs brasileiro. Imagine que vocÃª estÃ¡ descrevendo para uma pessoa TOTALMENTE CEGA e precisa transmitir ABSOLUTAMENTE TUDO que vocÃª vÃª com o mÃ¡ximo de detalhes possÃ­vel. Inclua cores exatas, texturas, materiais, posiÃ§Ãµes espaciais, distÃ¢ncias, tamanhos, estados emocionais, expressÃµes faciais, roupas com todos os detalhes, acessÃ³rios, ambiente completo, iluminaÃ§Ã£o, atmosfera, o que estÃ¡ acontecendo, relaÃ§Ãµes entre elementos. MÃ­nimo 300 palavras. Esta descriÃ§Ã£o deve ser tÃ£o rica que a pessoa cega consiga formar uma imagem mental completa e precisa da cena.",
  "overall_sentiment": "anÃ¡lise psicolÃ³gica profunda do sentimento, atmosfera geral, emoÃ§Ãµes transmitidas pela cena completa",
  "accessibility_notes": "informaÃ§Ãµes crÃ­ticas para acessibilidade, navegaÃ§Ã£o, seguranÃ§a, obstÃ¡culos, pontos de referÃªncia, texto visÃ­vel transcrito",
  "emotion_analysis": {
    "sorrindo": 0,
    "serio": 0,
    "triste": 0,
    "surpreso": 0,
    "zangado": 0,
    "neutro": 0
  },
  "sentiment_analysis": {
    "positivo": 0,
    "neutro": 0,
    "negativo": 0
  },
  "visual_details": {
    "dominant_colors": ["lista de cores dominantes com nomes exatos"],
    "textures": ["lista de texturas visÃ­veis"],
    "patterns": ["lista de padrÃµes identificados"],
    "text_visible": "TODO texto visÃ­vel na imagem transcrito aqui",
    "brands_logos": ["marcas e logos identificados"]
  },
  "spatial_analysis": {
    "depth": "anÃ¡lise de profundidade (primeiro plano, meio, fundo)",
    "perspective": "tipo de perspectiva e Ã¢ngulo da cÃ¢mera",
    "distances": "distÃ¢ncias aproximadas entre elementos principais"
  }
}

IMPORTANTE: 
- Para emotion_analysis e sentiment_analysis, conte QUANTAS PESSOAS na imagem apresentam cada emoÃ§Ã£o/sentimento. 
- Por exemplo, se hÃ¡ 3 pessoas sorrindo, coloque "sorrindo": 3. Se hÃ¡ 2 pessoas com sentimento positivo, coloque "positivo": 2.
- A "description" deve ser EXTREMAMENTE detalhada, mÃ­nimo 300 palavras, descrevendo TUDO que vocÃª vÃª.
- Transcreva TODO texto visÃ­vel em "text_visible".
- Seja incrivelmente especÃ­fico em cores (nÃ£o apenas "azul", mas "azul marinho profundo"), texturas, materiais, posiÃ§Ãµes.

ðŸ‡§ðŸ‡· LEMBRE-SE: TODA A DESCRIÃ‡ÃƒO DEVE ESTAR EM PORTUGUÃŠS BRASILEIRO COM MÃXIMO DETALHAMENTO! NÃƒO USE INGLÃŠS! ðŸ‡§ðŸ‡·"""
            
                # Replace the sound_section placeholder with actual content
                prompt = prompt.replace("{sound_section}", sound_section)
                
                user_message = UserMessage(
                    text=prompt,
                    file_contents=[image_content]
                )
            
            # Retry logic for Gemini API
            max_retries = 3
            retry_delay = 2
            response = None
            last_error = None
            
            for attempt in range(max_retries):
                try:
                    response = await chat.send_message(user_message)
                    break  # Success, exit retry loop
                except Exception as e:
                    last_error = e
                    error_msg = str(e).lower()
                    
                    if '503' in error_msg or 'overloaded' in error_msg or 'rate' in error_msg:
                        if attempt < max_retries - 1:
                            logging.warning(f"Gemini API overloaded, retrying in {retry_delay}s... (attempt {attempt + 1}/{max_retries})")
                            import asyncio
                            await asyncio.sleep(retry_delay)
                            retry_delay *= 2
                            continue
                        else:
                            raise HTTPException(
                                status_code=503,
                                detail="O serviÃ§o de IA estÃ¡ temporariamente sobrecarregado. Por favor, tente novamente em alguns instantes."
                            )
                    else:
                        raise
            
            if response is None:
                raise last_error or Exception("Failed to get response from Gemini")
            
            # Parse response
            try:
                # Try to extract JSON from response
                response_text = response.strip()
                if '```json' in response_text:
                    response_text = response_text.split('```json')[1].split('```')[0].strip()
                elif '```' in response_text:
                    response_text = response_text.split('```')[1].split('```')[0].strip()
                
                result = json.loads(response_text)
                detection.objects_detected = [
                    DetectedObject(**obj) for obj in result.get('objects', [])
                ]
                detection.description = result.get('description', response)
                
                # Process emotion and sentiment analysis
                if 'emotion_analysis' in result:
                    detection.emotion_analysis = EmotionAnalysis(**result['emotion_analysis'])
                if 'sentiment_analysis' in result:
                    detection.sentiment_analysis = SentimentAnalysis(**result['sentiment_analysis'])
            except:
                # If JSON parsing fails, use raw response
                detection.description = response
                detection.objects_detected = []
        
        # Process geolocation if provided
        if input.geo_location:
            detection.geo_location = GeoLocation(**input.geo_location)
        
        # Auto-categorize detection
        detection.category = auto_categorize_detection(detection)
        
        # Generate smart tags
        detection.tags = generate_tags(detection)
        
        # Check for alerts
        alerts = await db.alerts.find({"enabled": True}, {"_id": 0}).to_list(1000)
        for alert_data in alerts:
            alert = Alert(**alert_data)
            for obj in detection.objects_detected:
                if alert.object_name.lower() in obj.label.lower():
                    detection.alerts_triggered.append(alert.object_name)
        
        # Save to database
        doc = detection.model_dump()
        doc['timestamp'] = doc['timestamp'].isoformat()
        if doc.get('geo_location') and doc['geo_location'].get('timestamp'):
            doc['geo_location']['timestamp'] = doc['geo_location']['timestamp'].isoformat()
        await db.detections.insert_one(doc)
        
        return detection
        
    except HTTPException:
        raise  # Re-raise HTTPException as-is (preserves status code)
    except Exception as e:
        logging.error(f"Error analyzing frame: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/detect/analyze-nutrition", response_model=Detection)
async def analyze_nutrition(input: DetectionCreate, request: Request):
    """Analyze food items and calculate nutritional information"""
    try:
        # Use default user_id if no authentication (login removed)
        auth_header = request.headers.get("Authorization")
        user_id = get_current_user(auth_header) if auth_header else "anonymous_user"
        
        detection = Detection(
            source=input.source,
            detection_type="nutrition",
            image_data=input.image_data,
            user_id=user_id
        )
        
        # Extract base64 image data
        image_data = input.image_data.split(',')[1] if ',' in input.image_data else input.image_data
        
        # PhD-Level Nutrition Analysis Prompt
        nutrition_prompt = """
ðŸ‡§ðŸ‡· RESPONDA EXCLUSIVAMENTE EM PORTUGUÃŠS BRASILEIRO ðŸ‡§ðŸ‡·

VocÃª Ã© um PhD em NutriÃ§Ã£o com especializaÃ§Ã£o em NutriÃ§Ã£o ClÃ­nica, BioquÃ­mica Nutricional e DietÃ©tica Aplicada. 
Possui 20 anos de experiÃªncia em anÃ¡lise nutricional, avaliaÃ§Ã£o de adequaÃ§Ã£o alimentar e prescriÃ§Ã£o dietÃ©tica.

IMPORTANTE: TODA A RESPOSTA DEVE SER EM PORTUGUÃŠS DO BRASIL!

ANÃLISE ULTRA-DETALHADA DE COMPOSIÃ‡ÃƒO NUTRICIONAL:

Como especialista PhD, realize uma anÃ¡lise COMPLETA e CIENTÃFICA desta refeiÃ§Ã£o, incluindo:

1. **IDENTIFICAÃ‡ÃƒO PRECISA DOS ALIMENTOS**:
   - Nome cientÃ­fico quando aplicÃ¡vel
   - MÃ©todo de preparo (cru, cozido, frito, grelhado, assado)
   - PresenÃ§a de temperos e condimentos visÃ­veis
   - Estado de cocÃ§Ã£o e processamento

2. **ANÃLISE QUANTITATIVA PRECISA**:
   - Peso estimado em gramas com margem de erro
   - Densidade calÃ³rica por 100g
   - Volume aparente e conversÃ£o peso-volume

3. **PERFIL NUTRICIONAL COMPLETO** (por alimento):
   - Macronutrientes: ProteÃ­nas (g), Carboidratos (g), Gorduras totais (g), Fibras (g)
   - Gorduras: Saturadas, Monoinsaturadas, Poliinsaturadas, Trans
   - Carboidratos: Simples, Complexos, Ãndice GlicÃªmico estimado
   - Micronutrientes principais: Vitaminas (A, C, D, E, K, B-complex) e Minerais (Ca, Fe, Mg, Zn, K, Na)
   
4. **AVALIAÃ‡ÃƒO NUTRICIONAL PROFISSIONAL**:
   - AdequaÃ§Ã£o em relaÃ§Ã£o Ã s DRIs brasileiras
   - Qualidade nutricional da refeiÃ§Ã£o (score 0-100)
   - Densidade nutricional vs densidade calÃ³rica
   - EquilÃ­brio de macronutrientes (% proteÃ­na, % carboidrato, % gordura)

5. **ÃNDICES NUTRICIONAIS**:
   - Ãndice GlicÃªmico estimado da refeiÃ§Ã£o
   - Carga GlicÃªmica total
   - RelaÃ§Ã£o Ã”mega-6/Ã”mega-3 (quando aplicÃ¡vel)
   - Ãndice de Qualidade Nutricional (IQN)

6. **RECOMENDAÃ‡Ã•ES CIENTÃFICAS**:
   - Pontos positivos nutricionais
   - Ãreas de melhoria
   - SugestÃµes de complementaÃ§Ã£o
   - Alertas para grupos especÃ­ficos (diabÃ©ticos, hipertensos, etc)
   - PossÃ­veis deficiÃªncias nutricionais

7. **CONTEXTO DIETÃ‰TICO**:
   - AdequaÃ§Ã£o para diferentes perfis (atletas, sedentÃ¡rios, idosos)
   - Compatibilidade com dietas especiais (vegetariana, low-carb, mediterrÃ¢nea)
   - Momento ideal de consumo (cafÃ© da manhÃ£, prÃ©-treino, pÃ³s-treino, etc)

RETORNE JSON ESTRUTURADO PhD-LEVEL COMPLETO:
{
  "description": "descriÃ§Ã£o cientÃ­fica completa e detalhada da refeiÃ§Ã£o",
  "nutritional_analysis": {
    "foods_detected": [
      {
        "name": "nome do alimento",
        "scientific_name": "nome cientÃ­fico quando aplicÃ¡vel",
        "preparation_method": "mÃ©todo de preparo",
        "calories_per_100g": 0.0,
        "estimated_portion_grams": 0.0,
        "total_calories": 0.0,
        "macronutrients": {
          "protein": 0.0,
          "carbohydrates": 0.0,
          "fat": 0.0,
          "fiber": 0.0
        },
        "detailed_fats": {
          "saturated": 0.0,
          "monounsaturated": 0.0,
          "polyunsaturated": 0.0,
          "trans": 0.0
        },
        "carb_types": {
          "simple": 0.0,
          "complex": 0.0
        },
        "glycemic_index": 55,
        "micronutrients": {
          "vitamin_a": 0.0,
          "vitamin_c": 0.0,
          "vitamin_d": 0.0,
          "calcium": 0.0,
          "iron": 0.0,
          "magnesium": 0.0,
          "potassium": 0.0,
          "sodium": 0.0
        },
        "confidence": 0.9
      }
    ],
    "total_calories": 0.0,
    "total_weight_grams": 0.0,
    "meal_type": "cafÃ© da manhÃ£/almoÃ§o/jantar/lanche/prÃ©-treino/pÃ³s-treino",
    "nutritional_summary": {
      "total_protein": 0.0,
      "total_carbs": 0.0,
      "total_fat": 0.0,
      "total_fiber": 0.0,
      "total_saturated_fat": 0.0,
      "total_sodium": 0.0
    },
    "quality_score": 75,
    "nutritional_balance": {
      "protein_percent": 20.0,
      "carbs_percent": 50.0,
      "fat_percent": 30.0
    },
    "glycemic_load": 15.5,
    "nutritional_quality_index": 7.8,
    "health_recommendations": [
      "RecomendaÃ§Ã£o 1",
      "RecomendaÃ§Ã£o 2",
      "RecomendaÃ§Ã£o 3"
    ],
    "positive_aspects": [
      "Aspecto positivo 1",
      "Aspecto positivo 2"
    ],
    "improvement_areas": [
      "Ãrea de melhoria 1",
      "Ãrea de melhoria 2"
    ],
    "health_alerts": [
      "Alerta de saÃºde se aplicÃ¡vel"
    ],
    "dietary_compatibility": {
      "vegetarian": true/false,
      "vegan": true/false,
      "low_carb": true/false,
      "keto": true/false,
      "mediterranean": true/false,
      "gluten_free": true/false,
      "lactose_free": true/false,
      "diabetic_friendly": true/false
    },
    "ideal_consumption_time": "descriÃ§Ã£o do melhor momento",
    "dri_adequacy": {
      "protein": 35.5,
      "fiber": 20.0,
      "vitamin_c": 45.0,
      "calcium": 15.0,
      "iron": 25.0
    }
  }
}

IMPORTANTE - DIRETRIZES PhD:
- ðŸ‡§ðŸ‡· RESPONDA TUDO EM PORTUGUÃŠS BRASILEIRO - OBRIGATÃ“RIO!
- Use SEMPRE valores baseados em TACO (Tabela Brasileira de ComposiÃ§Ã£o de Alimentos)
- Considere mÃ©todo de preparo e impacto nutricional
- Seja PRECISO e CIENTÃFICO nas recomendaÃ§Ãµes
- Identifique riscos nutricionais para grupos vulnerÃ¡veis
- Compare com DRIs brasileiras (RDC 269/2005)
- Calcule Ã­ndices glicÃªmicos baseados em literatura cientÃ­fica
- Se nÃ£o houver alimentos, retorne arrays/listas vazios
- TODAS as descriÃ§Ãµes, recomendaÃ§Ãµes e textos devem estar em PORTUGUÃŠS!

ðŸ‡§ðŸ‡· LEMBRE-SE: RESPOSTA 100% EM PORTUGUÃŠS DO BRASIL! ðŸ‡§ðŸ‡·
"""
        
        # Process via Gemini 2.0 Flash with retry logic
        max_retries = 3
        retry_delay = 2
        response = None
        last_error = None
        
        for attempt in range(max_retries):
            try:
                chat = LlmChat(
                    api_key=GOOGLE_API_KEY,
                    session_id=f"nutrition_analysis_{uuid.uuid4()}",
                    system_message="VocÃª Ã© um especialista PhD em nutriÃ§Ã£o e anÃ¡lise de alimentos brasileiro. RESPONDA SEMPRE EM PORTUGUÃŠS BRASILEIRO. Use a Tabela Brasileira de ComposiÃ§Ã£o de Alimentos (TACO) e as DRIs brasileiras (RDC 269/2005)."
                ).with_model("gemini", "gemini-2.0-flash")
                
                response = await chat.send_message(
                    UserMessage(
                        text=nutrition_prompt,
                        file_contents=[ImageContent(image_base64=image_data)]
                    )
                )
                
                # If we got here, request succeeded
                break
                
            except Exception as e:
                last_error = e
                error_msg = str(e).lower()
                
                # Check if it's a retryable error (503, overloaded, rate limit)
                if '503' in error_msg or 'overloaded' in error_msg or 'rate' in error_msg:
                    if attempt < max_retries - 1:
                        logging.warning(f"Gemini API overloaded, retrying in {retry_delay}s... (attempt {attempt + 1}/{max_retries})")
                        import asyncio
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2  # Exponential backoff
                        continue
                    else:
                        logging.error("Max retries reached for nutrition analysis")
                        raise HTTPException(
                            status_code=503, 
                            detail="O serviÃ§o de IA estÃ¡ temporariamente sobrecarregado. Por favor, tente novamente em alguns instantes."
                        )
                else:
                    # Non-retryable error, raise immediately
                    raise
        
        if response is None:
            raise last_error or Exception("Failed to get response from Gemini")
        
        # Parse response
        try:
            # Try to find JSON in response
            response_text = response.strip()
            if '```json' in response_text:
                response_text = response_text.split('```json')[1].split('```')[0].strip()
            elif '```' in response_text:
                response_text = response_text.split('```')[1].split('```')[0].strip()
            
            result = json.loads(response_text)
            detection.description = result.get('description', response_text)
            
            # Process nutritional analysis
            if 'nutritional_analysis' in result:
                nutrition_data = result['nutritional_analysis']
                detection.nutritional_analysis = NutritionalAnalysis(**nutrition_data)
                
        except json.JSONDecodeError as e:
            # If JSON parsing fails, use raw response
            logging.error(f"JSON parsing failed for nutrition analysis: {str(e)}")
            logging.error(f"Raw response: {response_text if 'response_text' in locals() else response}")
            detection.description = response_text if 'response_text' in locals() else str(response)
            detection.nutritional_analysis = NutritionalAnalysis()
        except Exception as e:
            logging.error(f"Error processing nutrition data: {str(e)}")
            detection.description = response_text if 'response_text' in locals() else str(response)
            detection.nutritional_analysis = NutritionalAnalysis()
        
        # Process geolocation if provided
        if input.geo_location:
            detection.geo_location = GeoLocation(**input.geo_location)
        
        # Auto-categorize detection
        detection.category = auto_categorize_detection(detection)
        
        # Generate smart tags
        detection.tags = generate_tags(detection)
        
        # Save to database
        doc = detection.model_dump()
        doc['timestamp'] = doc['timestamp'].isoformat()
        if doc.get('geo_location') and doc['geo_location'].get('timestamp'):
            doc['geo_location']['timestamp'] = doc['geo_location']['timestamp'].isoformat()
        await db.detections.insert_one(doc)
        
        return detection
        
    except HTTPException:
        raise  # Re-raise HTTPException as-is (preserves status code)
    except Exception as e:
        logging.error(f"Error analyzing nutrition: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/detect/read-text", response_model=Detection)
async def read_text_ocr(input: DetectionCreate, request: Request):
    """OCR especializado para leitura de textos - livros, quadros, documentos"""
    try:
        # Use default user_id if no authentication (login removed)
        auth_header = request.headers.get("Authorization")
        user_id = get_current_user(auth_header) if auth_header else "anonymous_user"
        
        detection = Detection(
            source=input.source,
            detection_type="text_reading",  # Novo tipo
            image_data=input.image_data,
            user_id=user_id
        )
        
        # Extract base64 image data
        image_data = input.image_data.split(',')[1] if ',' in input.image_data else input.image_data
        
        # OCR Ultra-Detailed Prompt
        ocr_prompt = """ðŸ‡§ðŸ‡· RESPONDA EXCLUSIVAMENTE EM PORTUGUÃŠS BRASILEIRO ðŸ‡§ðŸ‡·

VocÃª Ã© um especialista em OCR (Optical Character Recognition) e anÃ¡lise de documentos para ACESSIBILIDADE.
Sua missÃ£o Ã© extrair e descrever TODO O TEXTO visÃ­vel na imagem de forma EXTREMAMENTE DETALHADA.

IMPORTANTE: TODA A RESPOSTA DEVE SER EM PORTUGUÃŠS DO BRASIL!

**TIPOS DE CONTEÃšDO QUE VOCÃŠ DEVE ANALISAR:**
1. ðŸ“– PÃ¡ginas de livros (capÃ­tulos, parÃ¡grafos, notas de rodapÃ©)
2. ðŸ“ Quadros de aula (anotaÃ§Ãµes, diagramas, fÃ³rmulas)
3. ðŸ“„ Documentos (contratos, formulÃ¡rios, cartas)
4. ðŸ“° Jornais e revistas
5. ðŸ·ï¸ Placas, avisos e sinalizaÃ§Ãµes
6. ðŸ’³ CartÃµes, tickets e recibos
7. ðŸ“± Telas de dispositivos

**ANÃLISE COMPLETA E ESTRUTURADA:**

1. **TIPO DE DOCUMENTO/CONTEÃšDO:**
   - Identifique o que Ã© (livro, quadro, placa, etc.)
   - Idioma do texto
   - Estado de conservaÃ§Ã£o
   - Qualidade da imagem

2. **ESTRUTURA DO DOCUMENTO:**
   - TÃ­tulo principal (se houver)
   - SubtÃ­tulos e seÃ§Ãµes
   - Hierarquia da informaÃ§Ã£o
   - Layout e organizaÃ§Ã£o visual

3. **EXTRAÃ‡ÃƒO COMPLETA DO TEXTO:**
   - Transcreva TODO o texto visÃ­vel, palavra por palavra
   - Preserve quebras de linha e parÃ¡grafos
   - Mantenha a ordem de leitura natural
   - Indique formataÃ§Ã£o especial (negrito, itÃ¡lico, sublinhado)
   - Transcreva nÃºmeros, fÃ³rmulas matemÃ¡ticas, sÃ­mbolos

4. **ELEMENTOS VISUAIS:**
   - Diagramas, grÃ¡ficos, tabelas (descreva estrutura e conteÃºdo)
   - Imagens ou ilustraÃ§Ãµes (descreva brevemente)
   - Linhas, setas, destaque visual
   - Cores usadas para destacar informaÃ§Ã£o

5. **ANOTAÃ‡Ã•ES E MARCAÃ‡Ã•ES:**
   - Texto manuscrito ou anotaÃ§Ãµes Ã  mÃ£o
   - Sublinhados, marcaÃ§Ãµes, post-its
   - CorreÃ§Ãµes ou rasuras

6. **CONTEXTO ADICIONAL:**
   - NÃºmero de pÃ¡gina (se visÃ­vel)
   - Data ou referÃªncias temporais
   - Autor ou fonte (se identificÃ¡vel)
   - Qualquer informaÃ§Ã£o contextual relevante

7. **LEGIBILIDADE E QUALIDADE:**
   - Partes do texto ilegÃ­veis ou borradas
   - Dificuldades de leitura
   - SugestÃµes para melhor captura

ForneÃ§a uma resposta JSON COMPLETA em portuguÃªs com esta estrutura:
{
  "document_type": "tipo do documento (livro, quadro, placa, etc.)",
  "language": "idioma do texto",
  "title": "tÃ­tulo principal se houver",
  "full_text": "TEXTO COMPLETO extraÃ­do preservando formataÃ§Ã£o e ordem",
  "structured_content": {
    "sections": [
      {
        "heading": "tÃ­tulo da seÃ§Ã£o",
        "content": "conteÃºdo da seÃ§Ã£o",
        "subsections": []
      }
    ],
    "lists": [
      {
        "type": "ordered/unordered",
        "items": ["item 1", "item 2"]
      }
    ],
    "tables": [
      {
        "description": "descriÃ§Ã£o da tabela",
        "rows": 5,
        "columns": 3,
        "content": "conteÃºdo textual da tabela"
      }
    ],
    "formulas": [
      {
        "formula": "fÃ³rmula matemÃ¡tica",
        "description": "explicaÃ§Ã£o da fÃ³rmula"
      }
    ]
  },
  "visual_elements": [
    {
      "type": "diagram/image/chart",
      "description": "descriÃ§Ã£o detalhada",
      "position": "localizaÃ§Ã£o na pÃ¡gina"
    }
  ],
  "handwritten_notes": [
    "anotaÃ§Ã£o manuscrita 1",
    "anotaÃ§Ã£o manuscrita 2"
  ],
  "metadata": {
    "page_number": "nÃºmero da pÃ¡gina se visÃ­vel",
    "author": "autor se identificÃ¡vel",
    "date": "data se presente",
    "quality": "excelente/boa/regular/ruim"
  },
  "accessibility_notes": "informaÃ§Ãµes adicionais para pessoas com deficiÃªncia visual",
  "reading_order": "ordem recomendada de leitura do conteÃºdo",
  "description": "DESCRIÃ‡ÃƒO NARRATIVA COMPLETA: Um resumo de TUDO que foi lido, como se estivesse narrando para uma pessoa cega, incluindo TODO o texto, estrutura, elementos visuais e contexto"
}

**DIRETRIZES CRÃTICAS:**
- ðŸ‡§ðŸ‡· TODA A RESPOSTA DEVE SER EM PORTUGUÃŠS BRASILEIRO
- Transcreva TUDO que conseguir ler, nÃ£o omita nada
- Se uma palavra estiver ilegÃ­vel, indique: [palavra ilegÃ­vel]
- Se faltar uma seÃ§Ã£o, indique: [conteÃºdo nÃ£o visÃ­vel]
- Seja EXTREMAMENTE detalhado na descriÃ§Ã£o narrativa
- Pense em acessibilidade: uma pessoa cega precisa entender TUDO
- Preserve a estrutura e hierarquia do texto original

ðŸ‡§ðŸ‡· LEMBRE-SE: RESPOSTA 100% EM PORTUGUÃŠS DO BRASIL! ðŸ‡§ðŸ‡·"""
        
        # Process via Gemini 2.0 Flash with retry logic
        max_retries = 3
        retry_delay = 2
        response = None
        last_error = None
        
        for attempt in range(max_retries):
            try:
                chat = LlmChat(
                    api_key=GOOGLE_API_KEY,
                    session_id=f"ocr_analysis_{uuid.uuid4()}",
                    system_message="VocÃª Ã© um especialista em OCR e anÃ¡lise de documentos para acessibilidade. RESPONDA SEMPRE EM PORTUGUÃŠS BRASILEIRO. Extraia e descreva TODO o texto visÃ­vel nas imagens com mÃ¡ximo detalhamento."
                ).with_model("gemini", "gemini-2.0-flash")
                
                response = await chat.send_message(
                    UserMessage(
                        text=ocr_prompt,
                        file_contents=[ImageContent(image_base64=image_data)]
                    )
                )
                
                # If we got here, request succeeded
                break
                
            except Exception as e:
                last_error = e
                error_msg = str(e).lower()
                
                # Check if it's a retryable error
                if '503' in error_msg or 'overloaded' in error_msg or 'rate' in error_msg:
                    if attempt < max_retries - 1:
                        logging.warning(f"Gemini API overloaded, retrying in {retry_delay}s... (attempt {attempt + 1}/{max_retries})")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2
                        continue
                    else:
                        raise HTTPException(
                            status_code=503,
                            detail="O serviÃ§o de IA estÃ¡ temporariamente sobrecarregado. Por favor, tente novamente em alguns instantes."
                        )
                else:
                    raise
        
        if response is None:
            raise last_error or Exception("Failed to get response from Gemini")
        
        # Parse response
        try:
            response_text = response.strip()
            if '```json' in response_text:
                response_text = response_text.split('```json')[1].split('```')[0].strip()
            elif '```' in response_text:
                response_text = response_text.split('```')[1].split('```')[0].strip()
            
            result = json.loads(response_text)
            
            # Store the full OCR result in description
            detection.description = result.get('description', '')
            
            # Store full text and structured content in objects_detected for easier access
            if result.get('full_text'):
                detection.objects_detected = [
                    DetectedObject(
                        label="Texto Completo",
                        confidence=0.95,
                        description=result.get('full_text', '')
                    )
                ]
            
        except json.JSONDecodeError as e:
            logging.error(f"JSON parsing failed for OCR: {str(e)}")
            # Use raw response as description
            detection.description = response_text if 'response_text' in locals() else str(response)
        except Exception as e:
            logging.error(f"Error processing OCR data: {str(e)}")
            detection.description = response_text if 'response_text' in locals() else str(response)
        
        # Process geolocation if provided
        if input.geo_location:
            detection.geo_location = GeoLocation(**input.geo_location)
        
        # Auto-categorize detection
        detection.category = auto_categorize_detection(detection)
        
        # Generate smart tags
        detection.tags = generate_tags(detection)
        
        # Save to database
        doc = detection.model_dump()
        doc['timestamp'] = doc['timestamp'].isoformat()
        if doc.get('geo_location') and doc['geo_location'].get('timestamp'):
            doc['geo_location']['timestamp'] = doc['geo_location']['timestamp'].isoformat()
        await db.detections.insert_one(doc)
        
        return detection
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"Error in OCR text reading: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/detect/read-braille", response_model=Detection)
async def read_braille(input: DetectionCreate, request: Request):
    """Leitor especializado de Braille - Suporta Grade 1 e Grade 2"""
    try:
        # Use default user_id if no authentication (login removed)
        auth_header = request.headers.get("Authorization")
        user_id = get_current_user(auth_header) if auth_header else "anonymous_user"
        
        detection = Detection(
            source=input.source,
            detection_type="braille_reading",
            image_data=input.image_data,
            user_id=user_id
        )
        
        # Extract base64 image data
        image_data = input.image_data.split(',')[1] if ',' in input.image_data else input.image_data
        
        # Braille Expert Prompt - Ultra-Specialized for Grade 1 & Grade 2
        braille_prompt = """ðŸ‡§ðŸ‡· RESPONDA EXCLUSIVAMENTE EM PORTUGUÃŠS BRASILEIRO ðŸ‡§ðŸ‡·

VocÃª Ã© um ESPECIALISTA MÃXIMO em LEITURA DE BRAILLE, tanto Grade 1 (literÃ¡rio/nÃ£o contraÃ­do) quanto Grade 2 (contraÃ­do/abreviado).
Sua expertise inclui conhecimento profundo do Sistema Braille brasileiro, contraÃ§Ãµes, sinais especiais e contextos.

**SUA MISSÃƒO:**
Analise a imagem fornecida e identifique, traduza e transcreva TODOS os caracteres Braille visÃ­veis com PRECISÃƒO ABSOLUTA.

**CONHECIMENTO ESSENCIAL DE BRAILLE:**

ðŸ“ **BRAILLE GRADE 1 (LiterÃ¡rio/NÃ£o ContraÃ­do):**
- Cada cÃ©lula Braille representa UMA letra, nÃºmero ou pontuaÃ§Ã£o
- Sistema 1:1 entre letra e cÃ©lula
- 6 pontos por cÃ©lula (pontos 1-2-3 esquerda, pontos 4-5-6 direita)
- NÃºmeros usam sinal de nÃºmero (pontos 3-4-5-6) seguido de letras a-j

ðŸ“ **BRAILLE GRADE 2 (ContraÃ­do/Abreviado):**
- Usa contraÃ§Ãµes e abreviaturas para economia de espaÃ§o
- Uma cÃ©lula pode representar palavra inteira ou sÃ­laba
- ContraÃ§Ãµes comuns em portuguÃªs:
  * "com" = ponto 6 + m
  * "para" = ponto 6 + p
  * "por" = ponto 6 + r
  * "que" = ponto 6 + q
  * "sÃ£o" = pontos 3-4-5 + s
  * "Ã§Ã£o" = pontos 5-6 + c
  * Prefixos e sufixos especiais
- Indicadores de maiÃºscula, Ãªnfase, itÃ¡lico
- Sinais matemÃ¡ticos e cientÃ­ficos especializados

**ESTRUTURA DE ANÃLISE:**

1. **IDENTIFICAÃ‡ÃƒO INICIAL:**
   - A imagem contÃ©m Braille? (Sim/NÃ£o)
   - Qualidade da imagem (excelente/boa/regular/ruim)
   - Contraste e iluminaÃ§Ã£o adequados?
   - Braille tÃ¡til (em relevo) ou impresso?
   - Estimativa: Grade 1, Grade 2, ou misto?

2. **LEITURA CÃ‰LULA POR CÃ‰LULA:**
   - Identifique cada cÃ©lula Braille na ordem de leitura (esquerdaâ†’direita, cimaâ†’baixo)
   - Para cada cÃ©lula, identifique os pontos ativos (combinaÃ§Ã£o de 1-2-3-4-5-6)
   - Traduza cÃ©lula por cÃ©lula considerando contexto (Grade 1 vs Grade 2)
   - Detecte espaÃ§os entre palavras, quebras de linha, parÃ¡grafos

3. **TRADUÃ‡ÃƒO ESPECIALIZADA:**
   - Para Grade 1: traduÃ§Ã£o direta letra-por-letra
   - Para Grade 2: expanda contraÃ§Ãµes e abreviaturas
   - Identifique e expanda prefixos/sufixos contraÃ­dos
   - Detecte indicadores especiais:
     * MaiÃºsculas (pontos 4-6 antes da letra)
     * NÃºmeros (pontos 3-4-5-6 antes dos dÃ­gitos)
     * PontuaÃ§Ã£o especial
     * SÃ­mbolos matemÃ¡ticos/cientÃ­ficos

4. **VALIDAÃ‡ÃƒO E CONTEXTO:**
   - Valide se a traduÃ§Ã£o faz sentido linguÃ­stico
   - Detecte possÃ­veis erros de impressÃ£o/produÃ§Ã£o do Braille
   - Identifique palavras parciais, texto truncado
   - Detecte linha em branco, indentaÃ§Ã£o, formataÃ§Ã£o

5. **ANÃLISE DE QUALIDADE:**
   - Pontos Braille bem definidos ou borrados?
   - EspaÃ§amento correto entre cÃ©lulas?
   - Alinhamento preservado?
   - Partes ilegÃ­veis ou danificadas?

**DETECÃ‡ÃƒO DE PADRÃ•ES COMUNS:**
- TÃ­tulos (geralmente centralizados, com espaÃ§os)
- ParÃ¡grafos e estrutura de texto
- Listas numeradas ou com marcadores
- FÃ³rmulas matemÃ¡ticas (reconheÃ§a Nemeth Code se presente)
- NotaÃ§Ã£o musical (se Braille musical)
- Braille em outros idiomas (inglÃªs, espanhol, francÃªs)

**RESPOSTA JSON ESTRUTURADA:**
ForneÃ§a uma resposta JSON COMPLETA em portuguÃªs com esta estrutura:

{
  "braille_detected": true/false,
  "braille_grade": "Grade 1" / "Grade 2" / "Misto" / "NÃ£o identificado",
  "image_quality": {
    "overall": "excelente/boa/regular/ruim",
    "contrast": "alto/mÃ©dio/baixo",
    "clarity": "nÃ­tido/aceitÃ¡vel/borrado",
    "recommendations": "sugestÃµes para melhorar captura"
  },
  "braille_text": "REPRESENTAÃ‡ÃƒO DOS PONTOS BRAILLE (use notaÃ§Ã£o: â â ƒâ ‰â ™ ou descriÃ§Ã£o de pontos)",
  "translated_text": "TEXTO TRADUZIDO COMPLETO EM PORTUGUÃŠS",
  "detailed_translation": [
    {
      "line_number": 1,
      "braille_cells": "sequÃªncia de cÃ©lulas Braille",
      "cell_by_cell": [
        {
          "cell": "â ",
          "dots": "ponto 1",
          "character": "a",
          "notes": "Grade 1, letra minÃºscula"
        }
      ],
      "translated_line": "texto da linha traduzido"
    }
  ],
  "contractions_used": [
    {
      "contraction": "descriÃ§Ã£o da contraÃ§Ã£o Grade 2",
      "expanded": "forma expandida",
      "position": "localizaÃ§Ã£o no texto"
    }
  ],
  "special_symbols": [
    {
      "symbol": "descriÃ§Ã£o do sÃ­mbolo especial",
      "meaning": "significado",
      "context": "contexto de uso"
    }
  ],
  "formatting": {
    "paragraphs": 2,
    "blank_lines": 1,
    "indentation": "presente/ausente",
    "alignment": "esquerda/centro/direita"
  },
  "issues_detected": [
    "lista de problemas ou imperfeiÃ§Ãµes encontradas"
  ],
  "confidence_score": 0.0-1.0,
  "description": "DESCRIÃ‡ÃƒO NARRATIVA COMPLETA: Texto traduzido do Braille, incluindo formataÃ§Ã£o, estrutura, qualidade da leitura, tipo de Grade identificado, e qualquer observaÃ§Ã£o relevante para o usuÃ¡rio. Esta Ã© a resposta principal que serÃ¡ lida em voz alta."
}

**DIRETRIZES CRÃTICAS:**
- ðŸ‡§ðŸ‡· TODA A RESPOSTA DEVE SER EM PORTUGUÃŠS BRASILEIRO
- Se nÃ£o houver Braille na imagem, informe claramente
- Se o Braille estiver ilegÃ­vel, explique o problema
- Seja PRECISO: erros em Braille podem mudar completamente o significado
- VALIDE: leia duas vezes para garantir precisÃ£o
- CONTEXTUALIZE: use o contexto para desambiguar contraÃ§Ãµes
- Se houver dÃºvida entre Grade 1 e Grade 2, EXPLIQUE ambas interpretaÃ§Ãµes
- Pense em ACESSIBILIDADE: a pessoa precisa confiar na sua traduÃ§Ã£o

**CASOS ESPECIAIS:**
- Se detectar Braille matemÃ¡tico (Nemeth Code): traduza e explique
- Se detectar Braille musical: identifique e descreva
- Se detectar mÃºltiplos idiomas: identifique cada um
- Se detectar cÃ³digos ou abreviaturas especializadas: traduza e explique

ðŸ‡§ðŸ‡· LEMBRE-SE: SUA RESPOSTA Ã‰ ESSENCIAL PARA ACESSIBILIDADE. SEJA PRECISO E DETALHADO! ðŸ‡§ðŸ‡·
"""
        
        # Process via Gemini 2.0 Flash with retry logic
        max_retries = 3
        retry_delay = 2
        response = None
        last_error = None
        
        for attempt in range(max_retries):
            try:
                chat = LlmChat(
                    api_key=GOOGLE_API_KEY,
                    session_id=f"braille_analysis_{uuid.uuid4()}",
                    system_message="VocÃª Ã© um especialista mÃ¡ximo em leitura e traduÃ§Ã£o de Braille (Grade 1 e Grade 2). RESPONDA SEMPRE EM PORTUGUÃŠS BRASILEIRO. Sua precisÃ£o Ã© essencial para acessibilidade."
                ).with_model("gemini", "gemini-2.0-flash")
                
                response = await chat.send_message(
                    UserMessage(
                        text=braille_prompt,
                        file_contents=[ImageContent(image_base64=image_data)]
                    )
                )
                
                # If we got here, request succeeded
                break
                
            except Exception as e:
                last_error = e
                error_msg = str(e).lower()
                
                # Check if it's a retryable error
                if '503' in error_msg or 'overloaded' in error_msg or 'rate' in error_msg:
                    if attempt < max_retries - 1:
                        logging.warning(f"Gemini API overloaded, retrying in {retry_delay}s... (attempt {attempt + 1}/{max_retries})")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2
                        continue
                    else:
                        raise HTTPException(
                            status_code=503,
                            detail="O serviÃ§o de IA estÃ¡ temporariamente sobrecarregado. Por favor, tente novamente em alguns instantes."
                        )
                else:
                    raise
        
        if response is None:
            raise last_error or Exception("Failed to get response from Gemini")
        
        # Parse response
        try:
            response_text = response.strip()
            if '```json' in response_text:
                response_text = response_text.split('```json')[1].split('```')[0].strip()
            elif '```' in response_text:
                response_text = response_text.split('```')[1].split('```')[0].strip()
            
            result = json.loads(response_text)
            
            # Store the description for TTS
            detection.description = result.get('description', result.get('translated_text', ''))
            
            # Store Braille-specific data in objects_detected
            braille_object = DetectedObject(
                label="Braille",
                confidence=result.get('confidence_score', 0.9),
                description=result.get('translated_text', '')
            )
            detection.objects_detected = [braille_object]
            
        except json.JSONDecodeError as e:
            logging.error(f"JSON parsing failed for Braille: {str(e)}")
            # Use raw response as description
            detection.description = response_text if 'response_text' in locals() else str(response)
        except Exception as e:
            logging.error(f"Error processing Braille data: {str(e)}")
            detection.description = response_text if 'response_text' in locals() else str(response)
        
        # Process geolocation if provided
        if input.geo_location:
            detection.geo_location = GeoLocation(**input.geo_location)
        
        # Auto-categorize detection
        detection.category = auto_categorize_detection(detection)
        
        # Generate smart tags
        detection.tags = generate_tags(detection)
        
        # Save to database
        doc = detection.model_dump()
        doc['timestamp'] = doc['timestamp'].isoformat()
        if doc.get('geo_location') and doc['geo_location'].get('timestamp'):
            doc['geo_location']['timestamp'] = doc['geo_location']['timestamp'].isoformat()
        await db.detections.insert_one(doc)
        
        return detection
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"Error in Braille reading: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/detect/traffic-safety", response_model=Detection)
async def traffic_safety_analysis(input: DetectionCreate, request: Request):
    """Sistema avanÃ§ado de seguranÃ§a no trÃ¢nsito para pessoas cegas"""
    try:
        # Get authenticated user
        auth_header = request.headers.get("Authorization")
        user_id = get_current_user(auth_header)
        
        if not user_id:
            raise HTTPException(status_code=401, detail="Authentication required")
        
        detection = Detection(
            source=input.source,
            detection_type="traffic_safety",
            image_data=input.image_data,
            user_id=user_id
        )
        
        # Extract base64 image data
        image_data = input.image_data.split(',')[1] if ',' in input.image_data else input.image_data
        
        # Get mode from input (navigation or crossing)
        mode = "navigation"
        if hasattr(input, 'mode'):
            mode = input.mode
        
        # Ultra-specialized Traffic Safety Prompt
        traffic_prompt = f"""ðŸš¦ SISTEMA AVANÃ‡ADO DE SEGURANÃ‡A NO TRÃ‚NSITO ðŸš¦
ðŸ‡§ðŸ‡· RESPONDA EXCLUSIVAMENTE EM PORTUGUÃŠS BRASILEIRO ðŸ‡§ðŸ‡·

**CONTEXTO CRÃTICO:**
VocÃª Ã© um SISTEMA DE SEGURANÃ‡A NO TRÃ‚NSITO para pessoas CEGAS. Sua anÃ¡lise pode SALVAR VIDAS.
A pessoa nÃ£o consegue ver nada. Ela depende 100% da sua descriÃ§Ã£o para navegar com seguranÃ§a.

**MODO ATIVO:** {"ATRAVESSIA DE RUA" if mode == "crossing" else "NAVEGAÃ‡ÃƒO EM CALÃ‡ADA"}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## ðŸš— ANÃLISE DE VEÃCULOS - PRIORIDADE MÃXIMA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**DETECÃ‡ÃƒO OBRIGATÃ“RIA:**

1. **IDENTIFICAR TODOS OS VEÃCULOS:**
   - Carros, motos, Ã´nibus, caminhÃµes, bicicletas, patinetes
   - Quantidade: "1 carro", "2 motos", "nenhum veÃ­culo"
   - Tipo especÃ­fico: "carro sedan preto", "Ã´nibus articulado", "motocicleta vermelha"

2. **ESTIMATIVA DE DISTÃ‚NCIA:**
   - **MUITO PRÃ“XIMO (0-5 metros):** PERIGO CRÃTICO!
     * Ocupa >40% da imagem
     * Detalhes como placa, farol, roda muito visÃ­veis
     * RESPOSTA: "PERIGO CRÃTICO! Carro a 3 metros se aproximando!"
   
   - **PRÃ“XIMO (5-15 metros):** ATENÃ‡ÃƒO MÃXIMA
     * Ocupa 20-40% da imagem
     * Modelo do veÃ­culo identificÃ¡vel
     * RESPOSTA: "ATENÃ‡ÃƒO! Ã”nibus a aproximadamente 10 metros"
   
   - **MÃ‰DIO (15-30 metros):** CUIDADO
     * Ocupa 10-20% da imagem
     * Silhueta clara
     * RESPOSTA: "CUIDADO: 2 carros a cerca de 20 metros"
   
   - **LONGE (>30 metros):** INFORMATIVO
     * Ocupa <10% da imagem
     * Apenas contorno
     * RESPOSTA: "VeÃ­culos distantes (mais de 30 metros)"

3. **DIREÃ‡ÃƒO E MOVIMENTO:**
   - Vindo da ESQUERDA, DIREITA, FRENTE
   - Velocidade aparente: parado, lento, mÃ©dio, rÃ¡pido
   - Exemplo: "Moto vindo da direita em velocidade mÃ©dia, aproximadamente 8 metros"

4. **NÃVEL DE PERIGO:**
   - **CRÃTICO:** VeÃ­culo a menos de 5m, movimento rÃ¡pido, na trajetÃ³ria do usuÃ¡rio
   - **ALTO:** VeÃ­culo prÃ³ximo (5-10m), movimento detectado
   - **MÃ‰DIO:** VeÃ­culo visÃ­vel mas distante (10-30m)
   - **BAIXO:** Nenhum veÃ­culo prÃ³ximo ou veÃ­culos parados distantes

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## ðŸš¦ SINAIS DE TRÃ‚NSITO E SEMÃFOROS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**IDENTIFICAR E DESCREVER:**

1. **SEMÃFOROS:**
   - Estado atual: VERMELHO, AMARELO, VERDE
   - PosiÃ§Ã£o: Ã  esquerda, centro, direita
   - Para pedestres ou veÃ­culos?
   - Exemplo: "SemÃ¡foro de pedestres VERDE Ã  sua frente"

2. **PLACAS DE SINALIZAÃ‡ÃƒO:**
   - PARE (octogonal vermelho)
   - DÃŠ A PREFERÃŠNCIA (triÃ¢ngulo invertido)
   - PROIBIDO (cÃ­rculo com barra)
   - VELOCIDADE MÃXIMA (circular com nÃºmero)
   - DIREÃ‡ÃƒO (setas indicativas)
   - Exemplo: "Placa de PARE Ã  direita, 4 metros"

3. **PLACAS DE RUA:**
   - Nome da rua/avenida
   - Ler TODO o texto visÃ­vel
   - Exemplo: "Placa de rua: AVENIDA PAULISTA"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## ðŸš¶ FAIXAS DE PEDESTRE E TRAVESSIA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**ANÃLISE ESPECÃFICA:**

1. **FAIXA DE PEDESTRE:**
   - Detectada ou nÃ£o?
   - Tipo: zebrada, elevada, semaforizadas
   - PosiÃ§Ã£o: Ã  frente, esquerda, direita
   - Estado: bem conservada, desgastada, visÃ­vel
   - Exemplo: "Faixa de pedestre zebrada Ã  sua frente, bem conservada"

2. **SEGURANÃ‡A PARA ATRAVESSAR (Modo Atravessia):**
   
   **SEGURO ATRAVESSAR se:**
   - SemÃ¡foro de pedestre VERDE
   - Nenhum veÃ­culo prÃ³ximo (<15m) se movendo
   - Via vazia ou veÃ­culos parados distantes
   - RESPOSTA: "âœ“ SEGURO ATRAVESSAR. Nenhum veÃ­culo prÃ³ximo. SemÃ¡foro verde."
   
   **NÃƒO ATRAVESSAR se:**
   - SemÃ¡foro VERMELHO ou AMARELO
   - VeÃ­culos a menos de 15 metros se aproximando
   - Movimento intenso de veÃ­culos
   - RESPOSTA: "âœ‹ NÃƒO ATRAVESSE! SemÃ¡foro vermelho. 2 carros se aproximando."

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## ðŸ›£ï¸ ANÃLISE DO AMBIENTE E OBSTÃCULOS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. **TIPO DE VIA:**
   - Rua residencial, avenida, estacionamento, praÃ§a
   - Largura estimada
   - Movimento: tranquilo, moderado, intenso

2. **OBSTÃCULOS NA CALÃ‡ADA (Modo NavegaÃ§Ã£o):**
   - Buracos, degraus, postes, lixeiras
   - Bicicletas/motos estacionadas na calÃ§ada
   - Obras, barreiras, cones
   - DistÃ¢ncia e posiÃ§Ã£o

3. **ELEMENTOS DE SEGURANÃ‡A:**
   - Guarda-corpo, meio-fio
   - IluminaÃ§Ã£o pÃºblica
   - Outras pessoas na calÃ§ada

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## ðŸ“‹ FORMATO DE RESPOSTA OBRIGATÃ“RIO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**ESTRUTURA (Modo NavegaÃ§Ã£o):**

NÃVEL DE PERIGO: [CRÃTICO/ALTO/MÃ‰DIO/BAIXO]

VEÃCULOS DETECTADOS:
- [Tipo] a [distÃ¢ncia] metros, [direÃ§Ã£o], [velocidade]
- Exemplo: "Carro sedan a 8 metros, vindo da esquerda, velocidade mÃ©dia"

SINAIS E PLACAS:
- [DescriÃ§Ã£o completa]

OBSTÃCULOS:
- [Se houver]

RECOMENDAÃ‡ÃƒO:
- [AÃ§Ã£o clara e direta]

---

**ESTRUTURA (Modo Atravessia):**

STATUS DE TRAVESSIA: [SEGURO ATRAVESSAR / NÃƒO ATRAVESSAR]

SEMÃFORO: [Estado se visÃ­vel]

VEÃCULOS:
- [DescriÃ§Ã£o detalhada de proximidade]

FAIXA DE PEDESTRE: [Detectada/NÃ£o detectada]

INSTRUÃ‡ÃƒO:
- [Comando claro: atravesse agora OU aguarde]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**REGRAS CRÃTICAS:**
- SEMPRE em portuguÃªs brasileiro
- Priorize VEÃCULOS PRÃ“XIMOS acima de tudo
- Seja ESPECÃFICO em distÃ¢ncias (metros)
- Use COMANDOS CLAROS: "Pare", "Aguarde", "Pode atravessar"
- NUNCA diga "parece seguro" - seja DEFINITIVO
- Se houver DÃšVIDA, sempre opte pela SEGURANÃ‡A (nÃ£o atravessar)

ANALISE A IMAGEM E RESPONDA:"""

        # Process via Gemini 2.0 Flash with retry logic
        max_retries = 3
        retry_delay = 2
        response = None
        last_error = None
        
        for attempt in range(max_retries):
            try:
                chat = LlmChat(
                    api_key=GOOGLE_API_KEY,
                    session_id=f"traffic_safety_{uuid.uuid4()}",
                    system_message="VocÃª Ã© um sistema especializado em seguranÃ§a no trÃ¢nsito para pessoas cegas. SEMPRE responda em portuguÃªs brasileiro. Sua anÃ¡lise pode salvar vidas - seja preciso e claro."
                ).with_model("gemini", "gemini-2.0-flash")
                
                response = await chat.send_message(
                    UserMessage(
                        text=traffic_prompt,
                        file_contents=[ImageContent(image_base64=image_data)]
                    )
                )
                
                # If we got here, request succeeded
                break
                
            except Exception as e:
                last_error = e
                error_msg = str(e).lower()
                
                # Check if it's a retryable error
                if '503' in error_msg or 'overloaded' in error_msg or 'rate' in error_msg:
                    if attempt < max_retries - 1:
                        logging.warning(f"Gemini API overloaded, retrying in {retry_delay}s... (attempt {attempt + 1}/{max_retries})")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2
                        continue
                    else:
                        raise HTTPException(
                            status_code=503,
                            detail="O serviÃ§o de IA estÃ¡ temporariamente sobrecarregado. Por favor, tente novamente em alguns instantes."
                        )
                else:
                    raise
        
        if response is None:
            raise last_error or Exception("Failed to get response from Gemini")
        
        # Store the description
        detection.description = response.strip()
        
        # Auto-categorize detection
        detection.category = "traffic_safety"
        
        # Generate smart tags
        detection.tags = ["trÃ¢nsito", "seguranÃ§a", "acessibilidade"]
        
        # Save to database
        doc = detection.model_dump()
        doc['timestamp'] = doc['timestamp'].isoformat()
        if doc.get('geo_location') and doc['geo_location'].get('timestamp'):
            doc['geo_location']['timestamp'] = doc['geo_location']['timestamp'].isoformat()
        await db.detections.insert_one(doc)
        
        return detection
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"Error in traffic safety analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/detect/math-physics", response_model=Detection)
async def math_physics_analysis(input: DetectionCreate, request: Request):
    """AnÃ¡lise especializada de documentos matemÃ¡ticos e fÃ­sicos em nÃ­vel PhD"""
    try:
        # Get authenticated user
        auth_header = request.headers.get("Authorization")
        user_id = get_current_user(auth_header)
        
        if not user_id:
            raise HTTPException(status_code=401, detail="Authentication required")
        
        detection = Detection(
            source=input.source,
            detection_type="math_physics",
            image_data=input.image_data,
            user_id=user_id
        )
        
        # Extract base64 image data
        image_data = input.image_data.split(',')[1] if ',' in input.image_data else input.image_data
        
        # PhD-Level Math & Physics Prompt
        math_physics_prompt = """ðŸ‡§ðŸ‡· RESPONDA EXCLUSIVAMENTE EM PORTUGUÃŠS BRASILEIRO ðŸ‡§ðŸ‡·

VocÃª Ã© um PROFESSOR PHD EM MATEMÃTICA E FÃSICA trabalhando como assistente educacional para pessoas CEGAS.
Sua missÃ£o Ã© LER, INTERPRETAR e EXPLICAR conteÃºdo matemÃ¡tico e fÃ­sico de forma CLARA, DIDÃTICA e COMPLETA.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## ðŸŽ“ SUA EXPERTISE E RESPONSABILIDADE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**FORMAÃ‡ÃƒO:**
- PhD em MatemÃ¡tica (AnÃ¡lise, Ãlgebra, Geometria, Topologia, CÃ¡lculo)
- PhD em FÃ­sica (MecÃ¢nica, Eletromagnetismo, QuÃ¢ntica, Relatividade, TermodinÃ¢mica)
- EspecializaÃ§Ã£o em EducaÃ§Ã£o Inclusiva para Deficientes Visuais
- ExperiÃªncia em transcriÃ§Ã£o de notaÃ§Ã£o matemÃ¡tica para linguagem natural

**PÃšBLICO-ALVO:**
- Pessoa CEGA que depende 100% da sua narraÃ§Ã£o
- NÃ£o pode ver sÃ­mbolos, grÃ¡ficos, diagramas
- Precisa de CLAREZA ABSOLUTA e CONTEXTO COMPLETO

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## ðŸ“ ANÃLISE DE DOCUMENTOS MATEMÃTICOS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**1. IDENTIFICAÃ‡ÃƒO DO CONTEÃšDO:**

Detecte e classifique o tipo de matemÃ¡tica presente:

A) **ARITMÃ‰TICA E ÃLGEBRA:**
   - OperaÃ§Ãµes bÃ¡sicas (+, -, Ã—, Ã·)
   - EquaÃ§Ãµes lineares, quadrÃ¡ticas, polinomiais
   - Sistemas de equaÃ§Ãµes
   - InequaÃ§Ãµes
   - FunÃ§Ãµes e seus tipos (linear, quadrÃ¡tica, exponencial, logarÃ­tmica, trigonomÃ©trica)

B) **CÃLCULO DIFERENCIAL E INTEGRAL:**
   - Limites: lim(xâ†’a) f(x)
   - Derivadas: df/dx, f'(x), âˆ‚f/âˆ‚x
   - Integrais: âˆ« f(x)dx, âˆ«âˆ« f(x,y)dxdy
   - SÃ©ries e sequÃªncias
   - EquaÃ§Ãµes diferenciais ordinÃ¡rias (EDO)
   - EquaÃ§Ãµes diferenciais parciais (EDP)

C) **ÃLGEBRA LINEAR:**
   - Matrizes e determinantes
   - Sistemas lineares
   - Vetores e espaÃ§os vetoriais
   - Autovalores e autovetores
   - TransformaÃ§Ãµes lineares

D) **GEOMETRIA:**
   - Geometria plana (triÃ¢ngulos, cÃ­rculos, polÃ­gonos)
   - Geometria espacial (esferas, cilindros, cones)
   - Geometria analÃ­tica
   - Trigonometria (sen, cos, tan, cossec, sec, cotan)

E) **PROBABILIDADE E ESTATÃSTICA:**
   - DistribuiÃ§Ãµes (Normal, Binomial, Poisson)
   - MÃ©dia, mediana, moda, desvio padrÃ£o
   - CorrelaÃ§Ã£o e regressÃ£o
   - Testes de hipÃ³tese

F) **MATEMÃTICA DISCRETA:**
   - Teoria dos nÃºmeros
   - CombinatÃ³ria
   - Teoria dos grafos
   - LÃ³gica matemÃ¡tica

**2. LEITURA DE FÃ“RMULAS E EQUAÃ‡Ã•ES:**

Para CADA fÃ³rmula encontrada, forneÃ§a:

**Formato Estruturado:**
```
FÃ“RMULA DETECTADA: [representaÃ§Ã£o visual se possÃ­vel]

LEITURA EM LINGUAGEM NATURAL:
"[leia sÃ­mbolo por sÃ­mbolo, operaÃ§Ã£o por operaÃ§Ã£o]"

EXPLICAÃ‡ÃƒO DO SIGNIFICADO:
- O que essa fÃ³rmula representa?
- Qual Ã© o contexto de uso?
- Quais sÃ£o as variÃ¡veis e constantes?

EXEMPLO DE APLICAÃ‡ÃƒO:
- Caso prÃ¡tico de uso
- Valores numÃ©ricos de exemplo
```

**NotaÃ§Ãµes Especiais:**

- **FraÃ§Ãµes:** "a sobre b" ou "a dividido por b"
- **Expoentes:** "x elevado a n" ou "x Ã  n-Ã©sima potÃªncia"
- **RaÃ­zes:** "raiz quadrada de x" ou "raiz n-Ã©sima de x"
- **Derivadas:** "derivada de f em relaÃ§Ã£o a x" ou "d f d x"
- **Integrais:** "integral de f de x d x" ou "integral definida de a atÃ© b"
- **SomatÃ³rios:** "somatÃ³rio de i igual a 1 atÃ© n de a i"
- **ProdutÃ³rios:** "produtÃ³rio de i igual a 1 atÃ© n de a i"
- **Limites:** "limite de f de x quando x tende a a"
- **Vetores:** "vetor v", "norma de v", "v produto escalar w"
- **Matrizes:** "matriz A de dimensÃ£o m por n", "determinante de A"

**SÃ­mbolos Gregos (sempre por extenso):**
- Î± (alfa), Î² (beta), Î³ (gama), Î´ (delta), Îµ (Ã©psilon), Î¸ (teta), Î» (lambda), Î¼ (mi), Ï€ (pi), Ïƒ (sigma), Ï„ (tau), Ï† (fi), Ï‰ (Ã´mega)

**3. RESOLUÃ‡ÃƒO PASSO A PASSO:**

Se houver exercÃ­cios ou problemas, forneÃ§a:
1. Enunciado completo
2. Dados fornecidos
3. O que se pede
4. EstratÃ©gia de resoluÃ§Ã£o
5. Cada passo detalhadamente
6. Resposta final
7. VerificaÃ§Ã£o (se aplicÃ¡vel)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## âš›ï¸ ANÃLISE DE DOCUMENTOS DE FÃSICA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**1. IDENTIFICAÃ‡ÃƒO DA ÃREA DE FÃSICA:**

A) **MECÃ‚NICA CLÃSSICA:**
   - CinemÃ¡tica (MRU, MRUV)
   - DinÃ¢mica (Leis de Newton, trabalho, energia, potÃªncia)
   - EstÃ¡tica (equilÃ­brio, torque)
   - GravitaÃ§Ã£o
   - Leis de conservaÃ§Ã£o (energia, momento)

B) **TERMODINÃ‚MICA:**
   - Temperatura e calor
   - Leis da termodinÃ¢mica
   - MÃ¡quinas tÃ©rmicas
   - Entropia

C) **ELETROMAGNETISMO:**
   - EletrostÃ¡tica (Lei de Coulomb, campo elÃ©trico)
   - Corrente elÃ©trica (Lei de Ohm, circuitos)
   - Magnetismo (campo magnÃ©tico, Lei de AmpÃ¨re)
   - InduÃ§Ã£o eletromagnÃ©tica (Lei de Faraday)
   - Ondas eletromagnÃ©ticas (Maxwell)

D) **Ã“PTICA:**
   - ReflexÃ£o e refraÃ§Ã£o
   - Lentes e espelhos
   - InterferÃªncia e difraÃ§Ã£o

E) **FÃSICA MODERNA:**
   - Relatividade restrita e geral
   - MecÃ¢nica quÃ¢ntica
   - FÃ­sica de partÃ­culas
   - FÃ­sica nuclear

F) **ONDULATÃ“RIA:**
   - Movimento harmÃ´nico simples
   - Ondas mecÃ¢nicas
   - Som e acÃºstica

**2. LEITURA DE EQUAÃ‡Ã•ES FÃSICAS:**

Para cada equaÃ§Ã£o, forneÃ§a:
- **Nome da lei/princÃ­pio**
- **Leitura sÃ­mbolo a sÃ­mbolo**
- **Significado de cada variÃ¡vel com unidades SI**
- **InterpretaÃ§Ã£o fÃ­sica**
- **AplicaÃ§Ãµes prÃ¡ticas**

Exemplos:
- F = mÂ·a â†’ "forÃ§a igual a massa vezes aceleraÃ§Ã£o" â†’ Segunda Lei de Newton
- E = mcÂ² â†’ "energia igual a massa vezes velocidade da luz ao quadrado" â†’ EquivalÃªncia massa-energia de Einstein
- V = RÂ·I â†’ "tensÃ£o igual a resistÃªncia vezes corrente" â†’ Lei de Ohm

**3. UNIDADES E CONVERSÃ•ES:**

Sempre mencione as unidades no Sistema Internacional (SI):
- Comprimento: metro (m)
- Massa: quilograma (kg)
- Tempo: segundo (s)
- ForÃ§a: newton (N)
- Energia: joule (J)
- PotÃªncia: watt (W)
- Corrente: ampÃ¨re (A)
- TensÃ£o: volt (V)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## ðŸ“Š ANÃLISE DE GRÃFICOS E DIAGRAMAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Se houver grÃ¡ficos, forneÃ§a:
1. **Tipo de grÃ¡fico:** Cartesiano, polar, 3D, diagrama de forÃ§as, etc.
2. **Eixos:** O que cada eixo representa (variÃ¡vel e unidade)
3. **Curvas/linhas:** DescriÃ§Ã£o detalhada do comportamento
4. **Pontos importantes:** MÃ¡ximos, mÃ­nimos, interseÃ§Ãµes, assÃ­ntotas
5. **InterpretaÃ§Ã£o fÃ­sica/matemÃ¡tica:** O que o grÃ¡fico revela

**Exemplo de descriÃ§Ã£o:**
"GrÃ¡fico cartesiano com eixo horizontal representando tempo em segundos e eixo vertical representando velocidade em metros por segundo. A curva Ã© uma reta crescente que passa pela origem, indicando movimento retilÃ­neo uniformemente variado com aceleraÃ§Ã£o positiva constante."

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## ðŸŽ¯ FORMATO DE RESPOSTA OBRIGATÃ“RIO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**ESTRUTURA:**

1. **TIPO DE DOCUMENTO:**
   [Livro didÃ¡tico / Apostila / ExercÃ­cios / Prova / Artigo cientÃ­fico / Outro]

2. **ÃREA E SUBÃREA:**
   [MatemÃ¡tica: CÃ¡lculo, Ãlgebra, etc. / FÃ­sica: MecÃ¢nica, Eletromagnetismo, etc.]

3. **NÃVEL DE COMPLEXIDADE:**
   [Fundamental / MÃ©dio / Superior / PÃ³s-graduaÃ§Ã£o]

4. **CONTEÃšDO IDENTIFICADO:**
   [Liste todos os tÃ³picos presentes]

5. **LEITURA COMPLETA:**
   [Leia TODO o texto, TODAS as fÃ³rmulas, TODOS os exercÃ­cios, palavra por palavra, sÃ­mbolo por sÃ­mbolo]

6. **EXPLICAÃ‡Ã•ES DETALHADAS:**
   [Para cada fÃ³rmula, equaÃ§Ã£o ou conceito, forneÃ§a explicaÃ§Ã£o completa em linguagem acessÃ­vel]

7. **RESOLUÃ‡ÃƒO DE EXERCÃCIOS (se houver):**
   [Resolva passo a passo, justificando cada etapa]

8. **DICAS PEDAGÃ“GICAS:**
   [SugestÃµes para facilitar o entendimento, conceitos relacionados, aplicaÃ§Ãµes prÃ¡ticas]

9. **RESUMO FINAL:**
   [SÃ­ntese do conteÃºdo em 3-5 frases]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**DIRETRIZES CRÃTICAS:**
- ðŸ‡§ðŸ‡· SEMPRE em portuguÃªs brasileiro
- Use linguagem CLARA e ACESSÃVEL
- NÃƒO assuma que a pessoa pode "ver" algo
- SEMPRE leia sÃ­mbolos por extenso
- ForneÃ§a CONTEXTO para cada fÃ³rmula
- Seja PACIENTE e DIDÃTICO
- Exemplifique com NÃšMEROS quando possÃ­vel
- NUNCA deixe uma fÃ³rmula sem explicaÃ§Ã£o

**LEMBRE-SE:** VocÃª Ã© os OLHOS MATEMÃTICOS E FÃSICOS dessa pessoa. Sua precisÃ£o e clareza sÃ£o essenciais para o aprendizado dela.

ANALISE A IMAGEM E RESPONDA:"""

        # Process via Gemini 2.0 Flash with retry logic
        max_retries = 3
        retry_delay = 2
        response = None
        last_error = None
        
        for attempt in range(max_retries):
            try:
                chat = LlmChat(
                    api_key=GOOGLE_API_KEY,
                    session_id=f"math_physics_{uuid.uuid4()}",
                    system_message="VocÃª Ã© um professor PhD em MatemÃ¡tica e FÃ­sica especializado em educaÃ§Ã£o inclusiva para pessoas cegas. SEMPRE responda em portuguÃªs brasileiro com clareza mÃ¡xima e didÃ¡tica."
                ).with_model("gemini", "gemini-2.0-flash")
                
                response = await chat.send_message(
                    UserMessage(
                        text=math_physics_prompt,
                        file_contents=[ImageContent(image_base64=image_data)]
                    )
                )
                
                # If we got here, request succeeded
                break
                
            except Exception as e:
                last_error = e
                error_msg = str(e).lower()
                
                # Check if it's a retryable error
                if '503' in error_msg or 'overloaded' in error_msg or 'rate' in error_msg:
                    if attempt < max_retries - 1:
                        logging.warning(f"Gemini API overloaded, retrying in {retry_delay}s... (attempt {attempt + 1}/{max_retries})")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2
                        continue
                    else:
                        raise HTTPException(
                            status_code=503,
                            detail="O serviÃ§o de IA estÃ¡ temporariamente sobrecarregado. Por favor, tente novamente em alguns instantes."
                        )
                else:
                    raise
        
        if response is None:
            raise last_error or Exception("Failed to get response from Gemini")
        
        # Store the description
        detection.description = response.strip()
        
        # Auto-categorize detection
        detection.category = "math_physics"
        
        # Generate smart tags
        detection.tags = ["matemÃ¡tica", "fÃ­sica", "educaÃ§Ã£o", "acessibilidade"]
        
        # Save to database
        doc = detection.model_dump()
        doc['timestamp'] = doc['timestamp'].isoformat()
        if doc.get('geo_location') and doc['geo_location'].get('timestamp'):
            doc['geo_location']['timestamp'] = doc['geo_location']['timestamp'].isoformat()
        await db.detections.insert_one(doc)
        
        return detection
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"Error in math/physics analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# Authentication endpoints
@api_router.post("/auth/register")
async def register_user(user_data: UserRegister):
    """Register a new user"""
    try:
        # Check if user already exists
        existing_user = await db.users.find_one({"email": user_data.email})
        if existing_user:
            raise HTTPException(status_code=400, detail="Email already registered")
        
        # Hash password
        password_hash = get_password_hash(user_data.password)
        
        # Determine user type - HARDCODED ADMIN
        # Only aruanasistema@gmail.com gets admin privileges
        user_type = "admin" if user_data.email.lower() == "aruanasistema@gmail.com" else "user"
        
        # Create user
        user = User(
            name=user_data.name,
            email=user_data.email,
            password_hash=password_hash,
            user_type=user_type
        )
        
        # Save to database
        user_dict = user.model_dump()
        user_dict['created_at'] = user_dict['created_at'].isoformat()
        if user_dict.get('last_login'):
            user_dict['last_login'] = user_dict['last_login'].isoformat()
            
        await db.users.insert_one(user_dict)
        
        return {"success": True, "message": "User created successfully"}
        
    except HTTPException:
        raise  # Re-raise HTTPException as-is (preserves status code)
    except Exception as e:
        logging.error(f"Registration error: {str(e)}")
        raise HTTPException(status_code=500, detail="Registration failed")

@api_router.post("/auth/login")
async def login_user(credentials: UserLogin):
    """Login user and return JWT token"""
    try:
        # Find user
        user = await db.users.find_one({"email": credentials.email})
        if not user:
            raise HTTPException(status_code=401, detail="Invalid email or password")
        
        # Verify password
        if not verify_password(credentials.password, user["password_hash"]):
            raise HTTPException(status_code=401, detail="Invalid email or password")
        
        # Check if user is active
        if not user.get("is_active", True):
            raise HTTPException(status_code=401, detail="Account is disabled")
        
        # Update last login
        await db.users.update_one(
            {"id": user["id"]},
            {"$set": {"last_login": datetime.now(timezone.utc).isoformat()}}
        )
        
        # Create access token
        access_token = create_access_token(
            data={"sub": user["id"], "email": user["email"], "user_type": user["user_type"]}
        )
        
        return {
            "success": True,
            "access_token": access_token,
            "token_type": "bearer",
            "user": {
                "id": user["id"],
                "name": user["name"],
                "email": user["email"],
                "user_type": user["user_type"]
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"Login error: {str(e)}")
        raise HTTPException(status_code=500, detail="Login failed")

@api_router.get("/auth/me")
async def get_current_user_info(request: Request):
    """Get current user information"""
    auth_header = request.headers.get("Authorization")
    user_id = get_current_user(auth_header)
    
    if not user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    user = await db.users.find_one({"id": user_id}, {"_id": 0, "password_hash": 0, "reset_token": 0, "reset_token_expiry": 0})
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    return user

@api_router.put("/auth/profile")
async def update_profile(request: Request, profile_data: UserProfileUpdate):
    """Update user profile"""
    auth_header = request.headers.get("Authorization")
    user_id = get_current_user(auth_header)
    
    if not user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    # Build update document
    update_doc = {}
    if profile_data.name:
        update_doc["name"] = profile_data.name
    if profile_data.bio is not None:
        update_doc["bio"] = profile_data.bio
    if profile_data.phone is not None:
        update_doc["phone"] = profile_data.phone
    if profile_data.birth_date is not None:
        update_doc["birth_date"] = profile_data.birth_date
    if profile_data.profile_photo is not None:
        update_doc["profile_photo"] = profile_data.profile_photo
    
    if not update_doc:
        raise HTTPException(status_code=400, detail="No fields to update")
    
    # Update user
    result = await db.users.update_one(
        {"id": user_id},
        {"$set": update_doc}
    )
    
    if result.modified_count == 0:
        raise HTTPException(status_code=404, detail="User not found")
    
    # Return updated user
    updated_user = await db.users.find_one({"id": user_id}, {"_id": 0, "password_hash": 0, "reset_token": 0, "reset_token_expiry": 0})
    return {"success": True, "user": updated_user}

@api_router.post("/auth/forgot-password")
async def forgot_password(request_data: PasswordResetRequest):
    """Request password reset - generates token"""
    try:
        user = await db.users.find_one({"email": request_data.email})
        
        if not user:
            # Don't reveal if email exists for security
            return {"success": True, "message": "If email exists, reset instructions have been sent"}
        
        # Generate reset token
        reset_token = secrets.token_urlsafe(32)
        reset_expiry = datetime.now(timezone.utc) + timedelta(hours=1)  # 1 hour expiry
        
        # Save token to user
        await db.users.update_one(
            {"email": request_data.email},
            {"$set": {
                "reset_token": reset_token,
                "reset_token_expiry": reset_expiry.isoformat()
            }}
        )
        
        # In production, send email with token
        # For now, return token in response (ONLY FOR DEVELOPMENT)
        logging.info(f"Password reset token for {request_data.email}: {reset_token}")
        
        return {
            "success": True, 
            "message": "If email exists, reset instructions have been sent",
            "token": reset_token  # REMOVE IN PRODUCTION - should be sent via email
        }
        
    except Exception as e:
        logging.error(f"Forgot password error: {str(e)}")
        raise HTTPException(status_code=500, detail="Failed to process request")

@api_router.post("/auth/reset-password")
async def reset_password(reset_data: PasswordReset):
    """Reset password with token"""
    try:
        # Find user with valid token
        user = await db.users.find_one({
            "reset_token": reset_data.token
        })
        
        if not user:
            raise HTTPException(status_code=400, detail="Invalid or expired token")
        
        # Check if token expired
        if user.get("reset_token_expiry"):
            expiry = datetime.fromisoformat(user["reset_token_expiry"])
            if expiry < datetime.now(timezone.utc):
                raise HTTPException(status_code=400, detail="Token has expired")
        
        # Hash new password
        new_password_hash = pwd_context.hash(reset_data.new_password)
        
        # Update password and clear token
        await db.users.update_one(
            {"id": user["id"]},
            {"$set": {
                "password_hash": new_password_hash,
                "reset_token": None,
                "reset_token_expiry": None
            }}
        )
        
        return {"success": True, "message": "Password reset successfully"}
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"Reset password error: {str(e)}")
        raise HTTPException(status_code=500, detail="Failed to reset password")

# ==================== ADMIN ENDPOINTS ====================

@api_router.get("/admin/users")
async def get_all_users(request: Request):
    """Admin: Get all users"""
    auth_header = request.headers.get("Authorization")
    user_id = get_current_user(auth_header)
    
    if not user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    # Check if user is admin
    current_user = await db.users.find_one({"id": user_id})
    if not current_user or current_user.get("user_type") != "admin":
        raise HTTPException(status_code=403, detail="Admin access required")
    
    # Get all users
    users = await db.users.find(
        {},
        {"_id": 0, "password_hash": 0, "reset_token": 0, "reset_token_expiry": 0}
    ).to_list(1000)
    
    return users

@api_router.put("/admin/users/{user_id}")
async def update_user(request: Request, user_id: str, update_data: dict):
    """Admin: Update any user"""
    auth_header = request.headers.get("Authorization")
    current_user_id = get_current_user(auth_header)
    
    if not current_user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    # Check if user is admin
    current_user = await db.users.find_one({"id": current_user_id})
    if not current_user or current_user.get("user_type") != "admin":
        raise HTTPException(status_code=403, detail="Admin access required")
    
    # Remove sensitive fields from update
    update_data.pop('password_hash', None)
    update_data.pop('id', None)
    
    # Update user
    result = await db.users.update_one(
        {"id": user_id},
        {"$set": update_data}
    )
    
    if result.modified_count == 0:
        raise HTTPException(status_code=404, detail="User not found")
    
    return {"success": True, "message": "User updated"}

@api_router.delete("/admin/users/{user_id}")
async def delete_user(request: Request, user_id: str):
    """Admin: Delete user"""
    auth_header = request.headers.get("Authorization")
    current_user_id = get_current_user(auth_header)
    
    if not current_user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    # Check if user is admin
    current_user = await db.users.find_one({"id": current_user_id})
    if not current_user or current_user.get("user_type") != "admin":
        raise HTTPException(status_code=403, detail="Admin access required")
    
    # Prevent deleting self
    if user_id == current_user_id:
        raise HTTPException(status_code=400, detail="Cannot delete yourself")
    
    # Delete user
    result = await db.users.delete_one({"id": user_id})
    
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="User not found")
    
    return {"success": True, "message": "User deleted"}

@api_router.get("/admin/stats")
async def get_admin_stats(request: Request):
    """Admin: Get system statistics"""
    auth_header = request.headers.get("Authorization")
    user_id = get_current_user(auth_header)
    
    if not user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    # Check if user is admin
    current_user = await db.users.find_one({"id": user_id})
    if not current_user or current_user.get("user_type") != "admin":
        raise HTTPException(status_code=403, detail="Admin access required")
    
    # Get statistics
    total_users = await db.users.count_documents({})
    total_detections = await db.detections.count_documents({})
    total_alerts = await db.alerts.count_documents({})
    
    return {
        "total_users": total_users,
        "total_detections": total_detections,
        "total_alerts": total_alerts
    }

@api_router.get("/detections", response_model=List[Detection])
async def get_detections(
    request: Request,
    limit: int = Query(50, ge=1, le=100),
    skip: int = Query(0, ge=0)
):
    """Get detection history - filtered by user unless admin"""
    auth_header = request.headers.get("Authorization")
    user_id = get_current_user(auth_header)
    
    if not user_id:
        raise HTTPException(status_code=401, detail="Authentication required")
    
    # Get user to check if admin
    user = await db.users.find_one({"id": user_id})
    if not user:
        raise HTTPException(status_code=401, detail="User not found")
    
    # Filter detections by user unless admin
    filter_query = {}
    if user.get("user_type") != "admin":
        filter_query["user_id"] = user_id
    
    detections = await db.detections.find(
        filter_query, {"_id": 0}
    ).sort("timestamp", -1).skip(skip).limit(limit).to_list(limit)
    
    for det in detections:
        if isinstance(det['timestamp'], str):
            det['timestamp'] = datetime.fromisoformat(det['timestamp'])
    
    return detections

@api_router.delete("/detections/{detection_id}")
async def delete_detection(detection_id: str):
    """Delete a detection"""
    result = await db.detections.delete_one({"id": detection_id})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Detection not found")
    return {"message": "Detection deleted"}

@api_router.post("/alerts", response_model=Alert)
async def create_alert(input: AlertCreate):
    """Create a new alert"""
    alert = Alert(**input.model_dump())
    doc = alert.model_dump()
    doc['created_at'] = doc['created_at'].isoformat()
    await db.alerts.insert_one(doc)
    return alert

@api_router.get("/alerts", response_model=List[Alert])
async def get_alerts():
    """Get all alerts"""
    alerts = await db.alerts.find({}, {"_id": 0}).to_list(1000)
    for alert in alerts:
        if isinstance(alert['created_at'], str):
            alert['created_at'] = datetime.fromisoformat(alert['created_at'])
    return alerts

@api_router.delete("/alerts/{alert_id}")
async def delete_alert(alert_id: str):
    """Delete an alert"""
    result = await db.alerts.delete_one({"id": alert_id})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Alert not found")
    return {"message": "Alert deleted"}

@api_router.patch("/alerts/{alert_id}")
async def toggle_alert(alert_id: str, enabled: bool):
    """Toggle alert enabled status"""
    result = await db.alerts.update_one(
        {"id": alert_id},
        {"$set": {"enabled": enabled}}
    )
    if result.matched_count == 0:
        raise HTTPException(status_code=404, detail="Alert not found")
    return {"message": "Alert updated"}

@api_router.get("/reports/export")
async def export_report(format: str = Query("json", regex="^(json|csv)$")):
    """Export detections report"""
    detections = await db.detections.find({}, {"_id": 0}).sort("timestamp", -1).to_list(1000)
    
    if format == "json":
        return detections
    else:  # csv
        output = io.StringIO()
        if detections:
            fieldnames = ['id', 'timestamp', 'source', 'detection_type', 'description']
            writer = csv.DictWriter(output, fieldnames=fieldnames)
            writer.writeheader()
            for det in detections:
                writer.writerow({
                    'id': det.get('id', ''),
                    'timestamp': det.get('timestamp', ''),
                    'source': det.get('source', ''),
                    'detection_type': det.get('detection_type', ''),
                    'description': det.get('description', '')
                })
        
        output.seek(0)
        return StreamingResponse(
            iter([output.getvalue()]),
            media_type="text/csv",
            headers={"Content-Disposition": "attachment; filename=detections_report.csv"}
        )

# Scientific Records Routes
@api_router.post("/scientific-records", response_model=ScientificRecord)
async def create_scientific_record(input: ScientificRecordCreate):
    """Criar novo registro cientÃ­fico"""
    record = ScientificRecord(**input.model_dump())
    doc = record.model_dump()
    doc['created_at'] = doc['created_at'].isoformat()
    await db.scientific_records.insert_one(doc)
    return record

@api_router.get("/scientific-records", response_model=List[ScientificRecord])
async def get_scientific_records(
    record_type: Optional[str] = None,
    research_line: Optional[str] = None,
    limit: int = Query(100, ge=1, le=500)
):
    """Listar registros cientÃ­ficos"""
    query = {}
    if record_type:
        query["record_type"] = record_type
    if research_line:
        query["research_line"] = research_line
    
    records = await db.scientific_records.find(query, {"_id": 0}).sort("created_at", -1).limit(limit).to_list(limit)
    
    for rec in records:
        if isinstance(rec['created_at'], str):
            rec['created_at'] = datetime.fromisoformat(rec['created_at'])
    
    return records

@api_router.delete("/scientific-records/{record_id}")
async def delete_scientific_record(record_id: str):
    """Deletar registro cientÃ­fico"""
    result = await db.scientific_records.delete_one({"id": record_id})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Record not found")
    return {"message": "Record deleted"}

# Intelligent Reports
@api_router.post("/analyze/sentiment-deep")
async def analyze_sentiment_deep(input: DetectionCreate):
    """AnÃ¡lise profunda de sentimentos usando tÃ©cnica avanÃ§ada de IA"""
    try:
        # Decode base64 image
        image_data = input.image_data.split(',')[1] if ',' in input.image_data else input.image_data
        
        # Use Gemini Vision with advanced sentiment analysis technique
        chat = LlmChat(
            api_key=GOOGLE_API_KEY,
            session_id=f"sentiment_analysis_{uuid.uuid4()}",
            system_message="""VocÃª Ã© um especialista em anÃ¡lise de sentimentos e psicologia comportamental. 
            Use a tÃ©cnica de 'AnÃ¡lise Multimodal de Sentimentos' que combina:
            1. DetecÃ§Ã£o de microexpressÃµes faciais (FACS - Facial Action Coding System)
            2. AnÃ¡lise de linguagem corporal e postura
            3. Contexto ambiental e situacional
            4. Teoria das emoÃ§Ãµes de Ekman (6 emoÃ§Ãµes bÃ¡sicas + variaÃ§Ãµes)
            5. AnÃ¡lise de valÃªncia emocional (positivo/negativo) e arousal (ativaÃ§Ã£o)"""
        ).with_model("gemini", "gemini-2.0-flash")
        
        image_content = ImageContent(image_base64=image_data)
        
        prompt = """Realize uma ANÃLISE PROFUNDA DE SENTIMENTOS desta imagem usando a tÃ©cnica de AnÃ¡lise Multimodal:

**MÃ‰TODO CIENTÃFICO:**
1. **FACS (Facial Action Coding System)**: Identifique Action Units (AUs) nas expressÃµes faciais
2. **Teoria de Ekman**: Classifique emoÃ§Ãµes bÃ¡sicas (alegria, tristeza, raiva, medo, surpresa, nojo)
3. **ValÃªncia e Arousal**: Avalie dimensÃµes emocionais (positivo/negativo, alta/baixa ativaÃ§Ã£o)
4. **Linguagem Corporal**: Analise postura, gestos e posicionamento
5. **Contexto**: Considere ambiente, objetos e situaÃ§Ã£o

**PARA CADA PESSOA DETECTADA:**
- **MicroexpressÃµes**: Detalhe movimentos faciais especÃ­ficos
- **Estado emocional primÃ¡rio**: EmoÃ§Ã£o dominante
- **Estados secundÃ¡rios**: EmoÃ§Ãµes sutis presentes
- **Intensidade emocional**: Escala 1-10
- **CongruÃªncia**: Alinhamento entre face, corpo e contexto
- **Indicadores fisiolÃ³gicos**: TensÃ£o muscular, dilataÃ§Ã£o pupilar (se visÃ­vel)
- **InterpretaÃ§Ã£o psicolÃ³gica**: O que a pessoa pode estar sentindo/pensando

**ANÃLISE DE GRUPO** (se mÃºltiplas pessoas):
- **DinÃ¢mica emocional**: Como as emoÃ§Ãµes interagem entre pessoas
- **ContÃ¡gio emocional**: InfluÃªncia mÃºtua de sentimentos
- **Clima emocional geral**: Atmosfera do grupo

ForneÃ§a resposta em JSON em PORTUGUÃŠS com estrutura detalhada:
{
  "sentiment_analysis": {
    "methodology": "FACS + Ekman + AnÃ¡lise Multimodal",
    "people": [{
      "person_id": 1,
      "primary_emotion": "alegria",
      "emotion_intensity": 8.5,
      "secondary_emotions": ["satisfaÃ§Ã£o", "tranquilidade"],
      "facial_action_units": ["AU6 (elevaÃ§Ã£o da bochecha)", "AU12 (sorriso)"],
      "valence": "positivo",
      "arousal": "moderado",
      "body_language": "postura relaxada, braÃ§os abertos",
      "psychological_interpretation": "pessoa demonstra contentamento genuÃ­no...",
      "confidence_score": 0.92
    }],
    "group_dynamics": {
      "overall_mood": "positivo e colaborativo",
      "emotional_contagion": "alta",
      "tension_level": "baixo"
    },
    "contextual_factors": ["ambiente bem iluminado", "presenÃ§a de objetos positivos"],
    "detailed_description": "descriÃ§Ã£o narrativa completa em portuguÃªs"
  }
}"""
        
        user_message = UserMessage(
            text=prompt,
            file_contents=[image_content]
        )
        
        response = await chat.send_message(user_message)
        
        # Parse response
        try:
            response_text = response.strip()
            if '```json' in response_text:
                response_text = response_text.split('```json')[1].split('```')[0].strip()
            elif '```' in response_text:
                response_text = response_text.split('```')[1].split('```')[0].strip()
            
            result = json.loads(response_text)
            return result
        except:
            return {
                "sentiment_analysis": {
                    "methodology": "FACS + Ekman + AnÃ¡lise Multimodal",
                    "raw_analysis": response,
                    "status": "partial_parse"
                }
            }
        
    except Exception as e:
        logging.error(f"Error in deep sentiment analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/reports/intelligent")
async def generate_intelligent_report(query: ReportQuery):
    """Gerar relatÃ³rio inteligente com anÃ¡lises"""
    # Build query
    db_query = {}
    if query.start_date:
        db_query["timestamp"] = {"$gte": query.start_date}
    if query.end_date:
        if "timestamp" in db_query:
            db_query["timestamp"]["$lte"] = query.end_date
        else:
            db_query["timestamp"] = {"$lte": query.end_date}
    
    detections = await db.detections.find(db_query, {"_id": 0}).to_list(1000)
    
    # Analyze data
    total_detections = len(detections)
    webcam_count = sum(1 for d in detections if d.get('source') == 'webcam')
    upload_count = sum(1 for d in detections if d.get('source') == 'upload')
    
    # Emotion analysis
    emotions_data = {
        "sorrindo": 0,
        "serio": 0,
        "triste": 0,
        "surpreso": 0,
        "zangado": 0,
        "neutro": 0
    }
    
    sentiment_data = {
        "positivo": 0,
        "neutro": 0,
        "negativo": 0
    }
    
    objects_count = {}
    
    for detection in detections:
        # Count objects
        for obj in detection.get('objects_detected', []):
            label = obj.get('label', 'unknown')
            objects_count[label] = objects_count.get(label, 0) + 1
            
        # Extract emotions from detection-level analysis
        if 'emotion_analysis' in detection and detection['emotion_analysis']:
            emotion_data = detection['emotion_analysis']
            for emotion, count in emotion_data.items():
                if emotion in emotions_data and isinstance(count, int):
                    emotions_data[emotion] += count
                    
        # Extract sentiment from detection-level analysis  
        if 'sentiment_analysis' in detection and detection['sentiment_analysis']:
            sentiment_analysis = detection['sentiment_analysis']
            for sentiment, count in sentiment_analysis.items():
                if sentiment in sentiment_data and isinstance(count, int):
                    sentiment_data[sentiment] += count
    
    # Scientific records stats
    scientific_records = await db.scientific_records.find({}, {"_id": 0}).to_list(1000)
    records_by_type = {}
    records_by_line = {}
    
    for rec in scientific_records:
        rec_type = rec.get('record_type', 'unknown')
        records_by_type[rec_type] = records_by_type.get(rec_type, 0) + 1
        
        line = rec.get('research_line', 'unknown')
        records_by_line[line] = records_by_line.get(line, 0) + 1
    
    return {
        "report_type": query.report_type,
        "period": {
            "start": query.start_date,
            "end": query.end_date
        },
        "detections_summary": {
            "total": total_detections,
            "by_source": {
                "webcam": webcam_count,
                "upload": upload_count
            }
        },
        "emotions_analysis": emotions_data,
        "sentiment_analysis": sentiment_data,
        "objects_detected": dict(sorted(objects_count.items(), key=lambda x: x[1], reverse=True)[:10]),
        "scientific_records": {
            "total": len(scientific_records),
            "by_type": records_by_type,
            "by_research_line": records_by_line
        },
        "insights": {
            "most_detected_object": max(objects_count.items(), key=lambda x: x[1])[0] if objects_count else "N/A",
            "dominant_emotion": max(emotions_data.items(), key=lambda x: x[1])[0] if any(emotions_data.values()) else "N/A",
            "overall_sentiment": max(sentiment_data.items(), key=lambda x: x[1])[0] if any(sentiment_data.values()) else "N/A"
        }
    }

# Social Network Routes
@api_router.post("/researchers", response_model=ResearcherProfile)
async def create_researcher_profile(input: ResearcherProfileCreate):
    """Criar perfil de pesquisador"""
    profile = ResearcherProfile(**input.model_dump())
    doc = profile.model_dump()
    doc['created_at'] = doc['created_at'].isoformat()
    await db.researchers.insert_one(doc)
    return profile

@api_router.get("/researchers", response_model=List[ResearcherProfile])
async def get_researchers(limit: int = Query(50, ge=1, le=100)):
    """Listar pesquisadores"""
    researchers = await db.researchers.find({}, {"_id": 0}).sort("created_at", -1).limit(limit).to_list(limit)
    for r in researchers:
        if isinstance(r['created_at'], str):
            r['created_at'] = datetime.fromisoformat(r['created_at'])
    return researchers

@api_router.get("/researchers/{researcher_id}", response_model=ResearcherProfile)
async def get_researcher(researcher_id: str):
    """Obter perfil de pesquisador"""
    researcher = await db.researchers.find_one({"id": researcher_id}, {"_id": 0})
    if not researcher:
        raise HTTPException(status_code=404, detail="Researcher not found")
    if isinstance(researcher['created_at'], str):
        researcher['created_at'] = datetime.fromisoformat(researcher['created_at'])
    return ResearcherProfile(**researcher)

@api_router.delete("/researchers/{researcher_id}")
async def delete_researcher(researcher_id: str):
    """Deletar pesquisador"""
    result = await db.researchers.delete_one({"id": researcher_id})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Researcher not found")
    return {"message": "Researcher deleted"}

@api_router.post("/posts", response_model=Post)
async def create_post(input: PostCreate):
    """Criar post"""
    post = Post(**input.model_dump())
    doc = post.model_dump()
    doc['created_at'] = doc['created_at'].isoformat()
    await db.posts.insert_one(doc)
    return post

@api_router.get("/posts", response_model=List[Post])
async def get_posts(limit: int = Query(50, ge=1, le=100)):
    """Listar posts"""
    posts = await db.posts.find({}, {"_id": 0}).sort("created_at", -1).limit(limit).to_list(limit)
    for p in posts:
        if isinstance(p['created_at'], str):
            p['created_at'] = datetime.fromisoformat(p['created_at'])
    return posts

@api_router.post("/posts/{post_id}/like")
async def like_post(post_id: str):
    """Curtir post"""
    result = await db.posts.update_one(
        {"id": post_id},
        {"$inc": {"likes": 1}}
    )
    if result.matched_count == 0:
        raise HTTPException(status_code=404, detail="Post not found")
    return {"message": "Post liked"}

@api_router.delete("/posts/{post_id}")
async def delete_post(post_id: str):
    """Deletar post"""
    result = await db.posts.delete_one({"id": post_id})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Post not found")
    # Delete associated comments
    await db.comments.delete_many({"post_id": post_id})
    return {"message": "Post deleted"}

@api_router.post("/comments", response_model=Comment)
async def create_comment(input: CommentCreate):
    """Criar comentÃ¡rio"""
    comment = Comment(**input.model_dump())
    doc = comment.model_dump()
    doc['created_at'] = doc['created_at'].isoformat()
    await db.comments.insert_one(doc)
    
    # Increment comments count on post
    await db.posts.update_one(
        {"id": input.post_id},
        {"$inc": {"comments_count": 1}}
    )
    
    return comment

@api_router.get("/comments/{post_id}", response_model=List[Comment])
async def get_comments(post_id: str):
    """Listar comentÃ¡rios de um post"""
    comments = await db.comments.find({"post_id": post_id}, {"_id": 0}).sort("created_at", 1).to_list(1000)
    for c in comments:
        if isinstance(c['created_at'], str):
            c['created_at'] = datetime.fromisoformat(c['created_at'])
    return comments

@api_router.delete("/comments/{comment_id}")
async def delete_comment(comment_id: str):
    """Deletar comentÃ¡rio"""
    comment = await db.comments.find_one({"id": comment_id})
    if not comment:
        raise HTTPException(status_code=404, detail="Comment not found")
    
    await db.comments.delete_one({"id": comment_id})
    
    # Decrement comments count on post
    await db.posts.update_one(
        {"id": comment['post_id']},
        {"$inc": {"comments_count": -1}}
    )
    
    return {"message": "Comment deleted"}

# Sharing endpoints
@api_router.post("/detections/{detection_id}/share")
async def create_share_link(detection_id: str, request: Request):
    """Generate a public share link for a detection"""
    auth_header = request.headers.get("Authorization")
    user_id = get_current_user(auth_header)
    
    if not user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    # Get detection
    detection = await db.detections.find_one({"id": detection_id, "user_id": user_id})
    if not detection:
        raise HTTPException(status_code=404, detail="Detection not found")
    
    # Generate unique share token
    share_token = str(uuid.uuid4())
    
    # Create share entry
    share_data = {
        "id": str(uuid.uuid4()),
        "detection_id": detection_id,
        "share_token": share_token,
        "user_id": user_id,
        "created_at": datetime.now(timezone.utc).isoformat(),
        "views": 0,
        "expires_at": None  # Never expires by default
    }
    
    await db.shares.insert_one(share_data)
    
    # Generate share URL
    base_url = os.environ.get('BACKEND_URL')
    if not base_url:
        raise HTTPException(
            status_code=500, 
            detail="BACKEND_URL environment variable not configured. Please set it for share functionality."
        )
    share_url = f"{base_url}/share/{share_token}"
    
    return {
        "share_url": share_url,
        "share_token": share_token,
        "created_at": share_data["created_at"]
    }

@api_router.get("/share/{share_token}")
async def view_shared_detection(share_token: str):
    """View a shared detection (public - no auth required)"""
    # Find share
    share = await db.shares.find_one({"share_token": share_token})
    if not share:
        raise HTTPException(status_code=404, detail="Share link not found or expired")
    
    # Increment views
    await db.shares.update_one(
        {"share_token": share_token},
        {"$inc": {"views": 1}}
    )
    
    # Get detection
    detection = await db.detections.find_one(
        {"id": share['detection_id']},
        {"_id": 0, "user_id": 0}  # Hide sensitive fields
    )
    
    if not detection:
        raise HTTPException(status_code=404, detail="Detection not found")
    
    return {
        "detection": detection,
        "views": share.get('views', 0) + 1,
        "shared_at": share.get('created_at')
    }

@api_router.delete("/detections/{detection_id}/share")
async def delete_share_link(detection_id: str, request: Request):
    """Delete share link for a detection"""
    auth_header = request.headers.get("Authorization")
    user_id = get_current_user(auth_header)
    
    if not user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")
    
    # Delete share
    result = await db.shares.delete_many({
        "detection_id": detection_id,
        "user_id": user_id
    })
    
    return {"message": f"Share link deleted", "deleted_count": result.deleted_count}

# Include router
app.include_router(api_router)

app.add_middleware(
    CORSMiddleware,
    allow_credentials=True,
    allow_origins=os.environ.get('CORS_ORIGINS', '*').split(','),
    allow_methods=["*"],
    allow_headers=["*"],
)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@app.on_event("startup")
async def create_default_admin():
    """Create default admin user if not exists"""
    try:
        admin_email = "aruanasistema@gmail.com"
        admin_password = "Ricardo@2025"
        
        # Check if admin exists
        existing_admin = await db.users.find_one({"email": admin_email})
        
        if not existing_admin:
            # Create admin user
            password_hash = pwd_context.hash(admin_password)
            admin_user = {
                "id": str(uuid.uuid4()),
                "name": "Administrador ARUANÃƒ",
                "email": admin_email,
                "password_hash": password_hash,
                "user_type": "admin",
                "created_at": datetime.now(timezone.utc).isoformat(),
                "is_active": True
            }
            await db.users.insert_one(admin_user)
            logging.info(f"âœ… Default admin user created: {admin_email}")
        else:
            logging.info(f"âœ… Admin user already exists: {admin_email}")
            
    except Exception as e:
        logging.error(f"Error creating default admin: {str(e)}")

@app.on_event("shutdown")
async def shutdown_db_client():
    client.close()